1:"$Sreact.fragment"
2:I[106,["/_next/static/chunks/59d0ad1b64f8544e.js"],"RootProvider"]
3:I[53113,["/_next/static/chunks/4d80e004cf4896dd.js","/_next/static/chunks/350ee4303b732916.js"],"default"]
4:I[73211,["/_next/static/chunks/4d80e004cf4896dd.js","/_next/static/chunks/350ee4303b732916.js"],"default"]
5:I[10086,["/_next/static/chunks/59d0ad1b64f8544e.js"],""]
6:I[25838,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"TreeContextProvider"]
b:I[6998,["/_next/static/chunks/4d80e004cf4896dd.js","/_next/static/chunks/350ee4303b732916.js"],"default"]
:HL["/_next/static/chunks/f2332aac77592f9d.css","style"]
0:{"P":null,"b":"o_J3cFnAZ1mdL_cv2bxKY","c":["","docs","api","models"],"q":"","i":false,"f":[[["",{"children":["docs",{"children":[["slug","api/models","oc"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],[["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/chunks/f2332aac77592f9d.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","script","script-0",{"src":"/_next/static/chunks/59d0ad1b64f8544e.js","async":true,"nonce":"$undefined"}]],["$","html",null,{"lang":"en","className":"dark","suppressHydrationWarning":true,"children":["$","body",null,{"className":"antialiased","children":["$","$L2",null,{"children":["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","main",null,{"className":"flex min-h-screen flex-col items-center justify-center px-4 text-center","children":[["$","div",null,{"className":"mb-8 opacity-20","children":["$","svg",null,{"width":"120","height":"120","viewBox":"0 0 120 120","fill":"none","aria-hidden":"true","children":["$","circle",null,{"cx":"60","cy":"60","r":"50","stroke":"currentColor","strokeWidth":"3","strokeLinecap":"round","strokeDasharray":"280 40"}]}]}],["$","p",null,{"className":"text-xs font-mono uppercase tracking-[0.3em] text-fd-muted-foreground mb-4","children":"404"}],["$","h1",null,{"className":"text-3xl font-semibold mb-3","children":"Page not found"}],["$","p",null,{"className":"text-fd-muted-foreground max-w-sm mb-10","children":"This page doesn't exist, or it may have moved. Try the documentation or head home."}],["$","div",null,{"className":"flex flex-wrap gap-3 justify-center","children":[["$","$L5",null,{"href":"/","className":"inline-flex items-center gap-2 rounded-lg bg-fd-primary text-fd-primary-foreground px-4 py-2 text-sm font-medium hover:opacity-90 transition","children":"Go home"}],["$","$L5",null,{"href":"/docs","className":"inline-flex items-center gap-2 rounded-lg border border-fd-border bg-fd-background px-4 py-2 text-sm font-medium hover:bg-fd-muted transition","children":"Documentation"}],["$","$L5",null,{"href":"/docs/models","className":"inline-flex items-center gap-2 rounded-lg border border-fd-border bg-fd-background px-4 py-2 text-sm font-medium hover:bg-fd-muted transition","children":"Browse models"}]]}],["$","p",null,{"className":"mt-16 text-xs font-mono text-fd-muted-foreground opacity-50","children":"zenlm.org"}]]}],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]}]]}],{"children":[["$","$1","c",{"children":[[["$","script","script-0",{"src":"/_next/static/chunks/abb1f677d5bfa0d7.js","async":true,"nonce":"$undefined"}],["$","script","script-1",{"src":"/_next/static/chunks/73ee7cc830199358.js","async":true,"nonce":"$undefined"}],["$","script","script-2",{"src":"/_next/static/chunks/713c1b62d4d91e41.js","async":true,"nonce":"$undefined"}],["$","script","script-3",{"src":"/_next/static/chunks/ab3a9da172ad7619.js","async":true,"nonce":"$undefined"}]],["$","$L6",null,{"tree":{"$id":"root","name":"Documentation","children":[{"$id":"index.mdx","type":"page","name":"Introduction","description":"Zen LM by Hanzo AI -- frontier models for code, reasoning, vision, multimodal, embeddings, and safety","icon":"$undefined","url":"/docs","$ref":{"file":"index.mdx"}},{"$id":"_0","type":"separator","icon":"$undefined","name":"Getting Started"},{"type":"folder","name":"Getting started","root":"$undefined","defaultOpen":"$undefined","description":"$undefined","collapsible":"$undefined","children":[{"$id":"getting-started/installation.mdx","type":"page","name":"Installation","description":"Install dependencies for using Zen models","icon":"$undefined","url":"/docs/getting-started/installation","$ref":{"file":"getting-started/installation.mdx"}},{"$id":"getting-started/quickstart.mdx","type":"page","name":"Quickstart","description":"Get started with Zen models in minutes","icon":"$undefined","url":"/docs/getting-started/quickstart","$ref":{"file":"getting-started/quickstart.mdx"}}],"$id":"getting-started","$ref":"$undefined","icon":"$undefined"},{"$id":"_1","type":"separator","icon":"$undefined","name":"API"},{"type":"folder","name":"API Reference","root":"$undefined","defaultOpen":"$undefined","description":"$undefined","collapsible":"$undefined","children":[{"$id":"api/chat-completions.mdx","type":"page","name":"Chat Completions","description":"Generate text with any Zen model using the OpenAI-compatible chat completions endpoint","icon":"$undefined","url":"/docs/api/chat-completions","$ref":{"file":"api/chat-completions.mdx"}},{"$id":"api/embeddings.mdx","type":"page","name":"Embeddings","description":"Generate 3072-dimensional vector embeddings with zen3-embedding","icon":"$undefined","url":"/docs/api/embeddings","$ref":{"file":"api/embeddings.mdx"}},{"$id":"api/models.mdx","type":"page","name":"Models","description":"All Zen models -- capabilities, pricing, and recommended use cases","icon":"$undefined","url":"/docs/api/models","$ref":{"file":"api/models.mdx"}},{"$id":"api/pricing.mdx","type":"page","name":"Pricing","description":"Zen LM API pricing -- transparent at 3x upstream inference cost","icon":"$undefined","url":"/docs/api/pricing","$ref":{"file":"api/pricing.mdx"}}],"$id":"api","$ref":"$undefined","index":{"$id":"api/index.mdx","type":"page","name":"API Reference","description":"Zen LM Cloud API -- OpenAI-compatible endpoints for all Zen models","icon":"$undefined","url":"/docs/api","$ref":{"file":"api/index.mdx"}},"icon":"$undefined"},{"$id":"_2","type":"separator","icon":"$undefined","name":"Models"},{"type":"folder","name":"Models","root":"$undefined","defaultOpen":"$undefined","description":"$undefined","collapsible":"$undefined","children":[{"$id":"models/zen-3d.mdx","type":"page","name":"zen-3d","description":"3D generation model for text-to-3D and image-to-3D asset creation.","icon":"$undefined","url":"/docs/models/zen-3d","$ref":{"file":"models/zen-3d.mdx"}},{"$id":"models/zen-agent.mdx","type":"page","name":"zen-agent","description":"32B dense model with tool use and planning for agentic AI workflows.","icon":"$undefined","url":"/docs/models/zen-agent","$ref":{"file":"models/zen-agent.mdx"}},{"$id":"models/zen-artist-edit.mdx","type":"page","name":"zen-artist-edit","description":"Image editing model for inpainting, outpainting, and edit-by-instruction.","icon":"$undefined","url":"/docs/models/zen-artist-edit","$ref":{"file":"models/zen-artist-edit.mdx"}},{"$id":"models/zen-artist.mdx","type":"page","name":"zen-artist","description":"Image generation model supporting multiple styles and high-resolution output.","icon":"$undefined","url":"/docs/models/zen-artist","$ref":{"file":"models/zen-artist.mdx"}},{"$id":"models/zen-code.mdx","type":"page","name":"zen-code","description":"Legacy 14B dense code model for general programming tasks.","icon":"$undefined","url":"/docs/models/zen-code","$ref":{"file":"models/zen-code.mdx"}},{"$id":"models/zen-coder-flash.mdx","type":"page","name":"zen-coder-flash","description":"Lightweight 7B dense model for low-latency code completions.","icon":"$undefined","url":"/docs/models/zen-coder-flash","$ref":{"file":"models/zen-coder-flash.mdx"}},{"$id":"models/zen-coder.mdx","type":"page","name":"zen-coder","description":"32B dense code model with 131K context for multi-language development.","icon":"$undefined","url":"/docs/models/zen-coder","$ref":{"file":"models/zen-coder.mdx"}},{"$id":"models/zen-designer.mdx","type":"page","name":"zen-designer","description":"Design generation model for UI/UX, graphics, and visual layouts.","icon":"$undefined","url":"/docs/models/zen-designer","$ref":{"file":"models/zen-designer.mdx"}},{"$id":"models/zen-director.mdx","type":"page","name":"zen-director","description":"Text-to-video generation model with cinematic quality output.","icon":"$undefined","url":"/docs/models/zen-director","$ref":{"file":"models/zen-director.mdx"}},{"$id":"models/zen-dub-live.mdx","type":"page","name":"zen-dub-live","description":"Real-time voice synthesis with ultra-low latency for live applications.","icon":"$undefined","url":"/docs/models/zen-dub-live","$ref":{"file":"models/zen-dub-live.mdx"}},{"$id":"models/zen-dub.mdx","type":"page","name":"zen-dub","description":"Voice synthesis and multi-language dubbing model.","icon":"$undefined","url":"/docs/models/zen-dub","$ref":{"file":"models/zen-dub.mdx"}},{"$id":"models/zen-eco.mdx","type":"page","name":"zen-eco","description":"Efficient 4B dense model balancing capability and cost for general-purpose tasks.","icon":"$undefined","url":"/docs/models/zen-eco","$ref":{"file":"models/zen-eco.mdx"}},{"$id":"models/zen-embedding.mdx","type":"page","name":"zen-embedding","description":"Foundation embedding model for search and retrieval.","icon":"$undefined","url":"/docs/models/zen-embedding","$ref":{"file":"models/zen-embedding.mdx"}},{"$id":"models/zen-foley.mdx","type":"page","name":"zen-foley","description":"Sound effects generation model for text-to-SFX production.","icon":"$undefined","url":"/docs/models/zen-foley","$ref":{"file":"models/zen-foley.mdx"}},{"$id":"models/zen-guard-gen.mdx","type":"page","name":"zen-guard-gen","description":"8B dense model for safe text generation with built-in guardrails.","icon":"$undefined","url":"/docs/models/zen-guard-gen","$ref":{"file":"models/zen-guard-gen.mdx"}},{"$id":"models/zen-guard-stream.mdx","type":"page","name":"zen-guard-stream","description":"4B dense model for low-latency streaming content moderation.","icon":"$undefined","url":"/docs/models/zen-guard-stream","$ref":{"file":"models/zen-guard-stream.mdx"}},{"$id":"models/zen-guard.mdx","type":"page","name":"zen-guard","description":"Content safety and moderation classifier.","icon":"$undefined","url":"/docs/models/zen-guard","$ref":{"file":"models/zen-guard.mdx"}},{"$id":"models/zen-live.mdx","type":"page","name":"zen-live","description":"Real-time bidirectional speech translation with ultra-low latency.","icon":"$undefined","url":"/docs/models/zen-live","$ref":{"file":"models/zen-live.mdx"}},{"$id":"models/zen-max.mdx","type":"page","name":"zen-max","description":"Trillion-parameter 1.04T MoE open-weights frontier model. Same model as zen4-max.","icon":"$undefined","url":"/docs/models/zen-max","$ref":{"file":"models/zen-max.mdx"}},{"$id":"models/zen-musician.mdx","type":"page","name":"zen-musician","description":"Music generation model with multi-instrument composition and style control.","icon":"$undefined","url":"/docs/models/zen-musician","$ref":{"file":"models/zen-musician.mdx"}},{"$id":"models/zen-nano.mdx","type":"page","name":"zen-nano","description":"Ultra-compact 0.6B dense model for edge inference at 44K tokens/sec.","icon":"$undefined","url":"/docs/models/zen-nano","$ref":{"file":"models/zen-nano.mdx"}},{"$id":"models/zen-next.mdx","type":"page","name":"zen-next","description":"Next-generation preview model with cutting-edge capabilities.","icon":"$undefined","url":"/docs/models/zen-next","$ref":{"file":"models/zen-next.mdx"}},{"$id":"models/zen-omni.mdx","type":"page","name":"zen-omni","description":"72B dense hypermodal model supporting text, vision, audio, and code.","icon":"$undefined","url":"/docs/models/zen-omni","$ref":{"file":"models/zen-omni.mdx"}},{"$id":"models/zen-pro.mdx","type":"page","name":"zen-pro","description":"Professional-grade 32B dense model with 19K tokens/sec throughput.","icon":"$undefined","url":"/docs/models/zen-pro","$ref":{"file":"models/zen-pro.mdx"}},{"$id":"models/zen-reranker.mdx","type":"page","name":"zen-reranker","description":"568M dense cross-encoder model for search result reranking.","icon":"$undefined","url":"/docs/models/zen-reranker","$ref":{"file":"models/zen-reranker.mdx"}},{"$id":"models/zen-scribe.mdx","type":"page","name":"zen-scribe","description":"Speech-to-text transcription model with multi-language support.","icon":"$undefined","url":"/docs/models/zen-scribe","$ref":{"file":"models/zen-scribe.mdx"}},{"$id":"models/zen-translator.mdx","type":"page","name":"zen-translator","description":"Context-aware translation model supporting 100+ languages.","icon":"$undefined","url":"/docs/models/zen-translator","$ref":{"file":"models/zen-translator.mdx"}},{"$id":"models/zen-video-i2v.mdx","type":"page","name":"zen-video-i2v","description":"Image-to-video animation model that brings still images to life.","icon":"$undefined","url":"/docs/models/zen-video-i2v","$ref":{"file":"models/zen-video-i2v.mdx"}},{"$id":"models/zen-video.mdx","type":"page","name":"zen-video","description":"Video understanding model for frame analysis, captioning, and temporal reasoning.","icon":"$undefined","url":"/docs/models/zen-video","$ref":{"file":"models/zen-video.mdx"}},{"$id":"models/zen-vl.mdx","type":"page","name":"zen-vl","description":"32B dense multimodal model for vision-language understanding.","icon":"$undefined","url":"/docs/models/zen-vl","$ref":{"file":"models/zen-vl.mdx"}},{"$id":"models/zen-voyager.mdx","type":"page","name":"zen-voyager","description":"World model for spatial reasoning and 3D scene understanding.","icon":"$undefined","url":"/docs/models/zen-voyager","$ref":{"file":"models/zen-voyager.mdx"}},{"$id":"models/zen-world.mdx","type":"page","name":"zen-world","description":"World simulation model for spatial reasoning and environment generation.","icon":"$undefined","url":"/docs/models/zen-world","$ref":{"file":"models/zen-world.mdx"}},{"$id":"models/zen.mdx","type":"page","name":"zen","description":"Standard 8-32B dense foundation model for general-purpose AI tasks.","icon":"$undefined","url":"/docs/models/zen","$ref":{"file":"models/zen.mdx"}},{"$id":"models/zen3-asr-v1.mdx","type":"page","name":"zen3-asr-v1","description":"First-generation streaming ASR for legacy compatibility.","icon":"$undefined","url":"/docs/models/zen3-asr-v1","$ref":{"file":"models/zen3-asr-v1.mdx"}},{"$id":"models/zen3-asr.mdx","type":"page","name":"zen3-asr","description":"Real-time streaming speech recognition for live transcription and voice agents.","icon":"$undefined","url":"/docs/models/zen3-asr","$ref":{"file":"models/zen3-asr.mdx"}},{"$id":"models/zen3-audio-fast.mdx","type":"page","name":"zen3-audio-fast","description":"Fastest speech-to-text transcription for high-throughput workloads.","icon":"$undefined","url":"/docs/models/zen3-audio-fast","$ref":{"file":"models/zen3-audio-fast.mdx"}},{"$id":"models/zen3-audio.mdx","type":"page","name":"zen3-audio","description":"Best quality speech-to-text transcription. 100+ languages.","icon":"$undefined","url":"/docs/models/zen3-audio","$ref":{"file":"models/zen3-audio.mdx"}},{"$id":"models/zen3-embedding-medium.mdx","type":"page","name":"zen3-embedding-medium","description":"Balanced embedding model for cost-effective retrieval workloads.","icon":"$undefined","url":"/docs/models/zen3-embedding-medium","$ref":{"file":"models/zen3-embedding-medium.mdx"}},{"$id":"models/zen3-embedding-small.mdx","type":"page","name":"zen3-embedding-small","description":"Lightweight embedding model for high-throughput, low-cost applications.","icon":"$undefined","url":"/docs/models/zen3-embedding-small","$ref":{"file":"models/zen3-embedding-small.mdx"}},{"$id":"models/zen3-embedding.mdx","type":"page","name":"zen3-embedding","description":"High-quality text embedding model with 3072 dimensions and 8K context.","icon":"$undefined","url":"/docs/models/zen3-embedding","$ref":{"file":"models/zen3-embedding.mdx"}},{"$id":"models/zen3-guard.mdx","type":"page","name":"zen3-guard","description":"Content safety classifier with 4B dense architecture. 65K context.","icon":"$undefined","url":"/docs/models/zen3-guard","$ref":{"file":"models/zen3-guard.mdx"}},{"$id":"models/zen3-image-dev.mdx","type":"page","name":"zen3-image-dev","description":"Development model for experimentation and iteration.","icon":"$undefined","url":"/docs/models/zen3-image-dev","$ref":{"file":"models/zen3-image-dev.mdx"}},{"$id":"models/zen3-image-fast.mdx","type":"page","name":"zen3-image-fast","description":"Fastest image model for real-time generation.","icon":"$undefined","url":"/docs/models/zen3-image-fast","$ref":{"file":"models/zen3-image-fast.mdx"}},{"$id":"models/zen3-image-jp.mdx","type":"page","name":"zen3-image-jp","description":"Japanese-specialized image generation model.","icon":"$undefined","url":"/docs/models/zen3-image-jp","$ref":{"file":"models/zen3-image-jp.mdx"}},{"$id":"models/zen3-image-max.mdx","type":"page","name":"zen3-image-max","description":"Maximum quality image generation for professional creative work.","icon":"$undefined","url":"/docs/models/zen3-image-max","$ref":{"file":"models/zen3-image-max.mdx"}},{"$id":"models/zen3-image-playground.mdx","type":"page","name":"zen3-image-playground","description":"Aesthetic model for artistic image generation.","icon":"$undefined","url":"/docs/models/zen3-image-playground","$ref":{"file":"models/zen3-image-playground.mdx"}},{"$id":"models/zen3-image-sdxl.mdx","type":"page","name":"zen3-image-sdxl","description":"High-resolution image generation at 1024px.","icon":"$undefined","url":"/docs/models/zen3-image-sdxl","$ref":{"file":"models/zen3-image-sdxl.mdx"}},{"$id":"models/zen3-image-ssd.mdx","type":"page","name":"zen3-image-ssd","description":"Fastest diffusion model for real-time generation.","icon":"$undefined","url":"/docs/models/zen3-image-ssd","$ref":{"file":"models/zen3-image-ssd.mdx"}},{"$id":"models/zen3-image.mdx","type":"page","name":"zen3-image","description":"Best general-purpose image generation.","icon":"$undefined","url":"/docs/models/zen3-image","$ref":{"file":"models/zen3-image.mdx"}},{"$id":"models/zen3-nano.mdx","type":"page","name":"zen3-nano","description":"Ultra-lightweight 4B dense model for edge deployment. 40K context.","icon":"$undefined","url":"/docs/models/zen3-nano","$ref":{"file":"models/zen3-nano.mdx"}},{"$id":"models/zen3-omni.mdx","type":"page","name":"zen3-omni","description":"Hypermodal ~200B dense model supporting text, vision, and audio. 202K context.","icon":"$undefined","url":"/docs/models/zen3-omni","$ref":{"file":"models/zen3-omni.mdx"}},{"$id":"models/zen3-reranker-medium.mdx","type":"page","name":"zen3-reranker-medium","description":"Balanced reranker for cost-effective retrieval quality improvement.","icon":"$undefined","url":"/docs/models/zen3-reranker-medium","$ref":{"file":"models/zen3-reranker-medium.mdx"}},{"$id":"models/zen3-reranker-small.mdx","type":"page","name":"zen3-reranker-small","description":"Lightweight reranker for high-throughput reranking at minimal cost.","icon":"$undefined","url":"/docs/models/zen3-reranker-small","$ref":{"file":"models/zen3-reranker-small.mdx"}},{"$id":"models/zen3-reranker.mdx","type":"page","name":"zen3-reranker","description":"High-quality reranker for improving retrieval accuracy in RAG pipelines.","icon":"$undefined","url":"/docs/models/zen3-reranker","$ref":{"file":"models/zen3-reranker.mdx"}},{"$id":"models/zen3-tts-fast.mdx","type":"page","name":"zen3-tts-fast","description":"Low-latency text-to-speech for real-time voice agents and interactive applications.","icon":"$undefined","url":"/docs/models/zen3-tts-fast","$ref":{"file":"models/zen3-tts-fast.mdx"}},{"$id":"models/zen3-tts-hd.mdx","type":"page","name":"zen3-tts-hd","description":"Maximum fidelity text-to-speech for broadcast-quality audio production.","icon":"$undefined","url":"/docs/models/zen3-tts-hd","$ref":{"file":"models/zen3-tts-hd.mdx"}},{"$id":"models/zen3-tts.mdx","type":"page","name":"zen3-tts","description":"High-quality text-to-speech with natural prosody. 40+ voices, 8 languages.","icon":"$undefined","url":"/docs/models/zen3-tts","$ref":{"file":"models/zen3-tts.mdx"}},{"$id":"models/zen3-vl.mdx","type":"page","name":"zen3-vl","description":"Vision-language model with 30B (3B active) MoE architecture. 262K context.","icon":"$undefined","url":"/docs/models/zen3-vl","$ref":{"file":"models/zen3-vl.mdx"}},{"$id":"models/zen4-coder-flash.mdx","type":"page","name":"zen4-coder-flash","description":"Fast 30B (3B active) MoE code model with 262K context.","icon":"$undefined","url":"/docs/models/zen4-coder-flash","$ref":{"file":"models/zen4-coder-flash.mdx"}},{"$id":"models/zen4-coder-pro.mdx","type":"page","name":"zen4-coder-pro","description":"Premium 480B full-precision BF16 code model with 131K context.","icon":"$undefined","url":"/docs/models/zen4-coder-pro","$ref":{"file":"models/zen4-coder-pro.mdx"}},{"$id":"models/zen4-coder.mdx","type":"page","name":"zen4-coder","description":"Code generation model with 480B (35B active) MoE and 163K context.","icon":"$undefined","url":"/docs/models/zen4-coder","$ref":{"file":"models/zen4-coder.mdx"}},{"$id":"models/zen4-max.mdx","type":"page","name":"zen4-max","description":"Trillion-parameter frontier MoE model. 1.04T (32B active) with 163K context.","icon":"$undefined","url":"/docs/models/zen4-max","$ref":{"file":"models/zen4-max.mdx"}},{"$id":"models/zen4-mini.mdx","type":"page","name":"zen4-mini","description":"Fast and efficient 8B dense model with 40K context.","icon":"$undefined","url":"/docs/models/zen4-mini","$ref":{"file":"models/zen4-mini.mdx"}},{"$id":"models/zen4-pro.mdx","type":"page","name":"zen4-pro","description":"High capability MoE model. 80B (3B active) with 131K context.","icon":"$undefined","url":"/docs/models/zen4-pro","$ref":{"file":"models/zen4-pro.mdx"}},{"$id":"models/zen4-thinking.mdx","type":"page","name":"zen4-thinking","description":"Deep reasoning model with 80B (3B active) MoE + chain-of-thought. 131K context.","icon":"$undefined","url":"/docs/models/zen4-thinking","$ref":{"file":"models/zen4-thinking.mdx"}},{"$id":"models/zen4-ultra.mdx","type":"page","name":"zen4-ultra","description":"Maximum reasoning model with 744B MoE (40B active) + extended chain-of-thought. 262K context.","icon":"$undefined","url":"/docs/models/zen4-ultra","$ref":{"file":"models/zen4-ultra.mdx"}},{"$id":"models/zen4.1.mdx","type":"page","name":"zen4.1","description":"High-performance 1M context model for long-document analysis, large codebase reasoning, and agentic workflows. Best balance of intelligence and cost at million-token scale.","icon":"$undefined","url":"/docs/models/zen4.1","$ref":{"file":"models/zen4.1.mdx"}},{"$id":"models/zen4.mdx","type":"page","name":"zen4","description":"Flagship 744B MoE model with 40B active parameters and 202K context window.","icon":"$undefined","url":"/docs/models/zen4","$ref":{"file":"models/zen4.mdx"}},{"$id":"models/zen5-coder.mdx","type":"page","name":"zen5-coder","description":"Next-generation code model. Zen5 architecture optimized for agentic programming. Research Preview.","icon":"$undefined","url":"/docs/models/zen5-coder","$ref":{"file":"models/zen5-coder.mdx"}},{"$id":"models/zen5-max.mdx","type":"page","name":"zen5-max","description":"Maximum-scale Zen5 model. Multi-trillion parameter frontier MoE. Research Preview.","icon":"$undefined","url":"/docs/models/zen5-max","$ref":{"file":"models/zen5-max.mdx"}},{"$id":"models/zen5-mini.mdx","type":"page","name":"zen5-mini","description":"Efficient agentic model delivering zen5-class intelligence at a fraction of the cost.","icon":"$undefined","url":"/docs/models/zen5-mini","$ref":{"file":"models/zen5-mini.mdx"}},{"$id":"models/zen5-pro.mdx","type":"page","name":"zen5-pro","description":"High-throughput agentic model for demanding production workloads. Trained on real-world development patterns with deep chain-of-thought reasoning.","icon":"$undefined","url":"/docs/models/zen5-pro","$ref":{"file":"models/zen5-pro.mdx"}},{"$id":"models/zen5-ultra.mdx","type":"page","name":"zen5-ultra","description":"Deepest reasoning model in the Zen family. Multi-pass chain-of-thought with self-verification.","icon":"$undefined","url":"/docs/models/zen5-ultra","$ref":{"file":"models/zen5-ultra.mdx"}},{"$id":"models/zen5.mdx","type":"page","name":"zen5","description":"Next-generation flagship model. 2T+ MoE with on-chain training via NVIDIA TEE. Research Preview.","icon":"$undefined","url":"/docs/models/zen5","$ref":{"file":"models/zen5.mdx"}}],"$id":"models","$ref":"$undefined","icon":"$undefined"},{"type":"folder","name":"Training","root":"$undefined","defaultOpen":"$undefined","description":"$undefined","collapsible":"$undefined","children":[{"$id":"training/cloud.mdx","type":"page","name":"Cloud Training","description":"Full-scale training on 8x H200 GPUs","icon":"$undefined","url":"/docs/training/cloud","$ref":{"file":"training/cloud.mdx"}},{"$id":"training/cuda.mdx","type":"page","name":"CUDA Training","description":"Train locally with NVIDIA GPUs","icon":"$undefined","url":"/docs/training/cuda","$ref":{"file":"training/cuda.mdx"}},{"$id":"training/mlx.mdx","type":"page","name":"MLX Training","description":"Train on Apple Silicon with MLX","icon":"$undefined","url":"/docs/training/mlx","$ref":{"file":"training/mlx.mdx"}},{"$id":"training/overview.mdx","type":"page","name":"Training Overview","description":"Train Zen models with multiple backend options","icon":"$undefined","url":"/docs/training/overview","$ref":{"file":"training/overview.mdx"}}],"$id":"training","$ref":"$undefined","icon":"$undefined"},{"$id":"datasets.mdx","type":"page","name":"Zen Agentic Dataset","description":"Zen Agentic Dataset - 8.47 billion tokens of real-world agentic programming","icon":"$undefined","url":"/docs/datasets","$ref":{"file":"datasets.mdx"}}],"fallback":{"$id":"fallback:root","name":"Docs","children":[{"$id":"fallback:models.mdx","type":"page","name":"Models","description":"Complete Zen LM model family â€” 80+ models across text, code, vision, audio, image, video, 3D, embedding, safety, and agent modalities","icon":"$undefined","url":"/docs/models","$ref":{"file":"models.mdx"}},{"$id":"fallback:training.mdx","type":"page","name":"Fine-tuning Guide","description":"Fine-tune Zen4 models with MLX, Unsloth, or DeepSpeed","icon":"$undefined","url":"/docs/training","$ref":{"file":"training.mdx"}}]}},"children":"$L7"}]]}],{"children":["$L8",{"children":["$L9",{},null,false,false]},null,false,false]},null,false,false]},null,false,false],"$La",false]],"m":"$undefined","G":["$b",[]],"S":true}
c:I[99924,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"LayoutContextProvider"]
d:I[32824,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SidebarProvider"]
e:I[99924,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"LayoutBody"]
f:I[99924,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"LayoutHeader"]
10:I[48068,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js","/_next/static/chunks/458a474de5cd6865.js","/_next/static/chunks/10b41d05c80e617b.js"],"default"]
11:I[80761,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SearchToggle"]
12:I[32824,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SidebarTrigger"]
13:I[80157,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SidebarContent"]
14:I[32824,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SidebarCollapseTrigger"]
15:I[80761,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"LargeSearchToggle"]
16:I[32824,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SidebarViewport"]
17:I[80157,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SidebarLinkItem"]
18:I[80157,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SidebarPageTree"]
19:I[73332,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"ThemeToggle"]
1a:I[80157,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SidebarDrawer"]
1d:I[89923,["/_next/static/chunks/4d80e004cf4896dd.js","/_next/static/chunks/350ee4303b732916.js"],"OutletBoundary"]
1e:"$Sreact.suspense"
20:I[89923,["/_next/static/chunks/4d80e004cf4896dd.js","/_next/static/chunks/350ee4303b732916.js"],"ViewportBoundary"]
22:I[89923,["/_next/static/chunks/4d80e004cf4896dd.js","/_next/static/chunks/350ee4303b732916.js"],"MetadataBoundary"]
7:["$","$Lc",null,{"navTransparentMode":"$undefined","children":["$","$Ld",null,{"defaultOpenLevel":"$undefined","prefetch":"$undefined","children":["$","$Le",null,{"children":[["$","$Lf",null,{"id":"nd-subnav","className":"[grid-area:header] sticky top-(--fd-docs-row-1) z-30 flex items-center ps-4 pe-2.5 border-b transition-colors backdrop-blur-sm h-(--fd-header-height) md:hidden max-md:layout:[--fd-header-height:--spacing(14)] data-[transparent=false]:bg-fd-background/80","children":[["$","$L10",null,{"href":"/","className":"inline-flex items-center gap-2.5 font-semibold","children":"ðŸª· Zen LM"}],["$","div",null,{"className":"flex-1","children":"$undefined"}],["$","$L11",null,{"className":"p-2","hideIfDisabled":true}],["$","$L12",null,{"className":"inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground [&_svg]:size-4.5 p-2","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-panel-left","aria-hidden":"true","children":[["$","rect","afitv7",{"width":"18","height":"18","x":"3","y":"3","rx":"2"}],["$","path","fh3hqa",{"d":"M9 3v18"}],"$undefined"]}]}]]}],[["$","$L13",null,{"children":[["$","div",null,{"className":"flex flex-col gap-3 p-4 pb-2","children":[["$","div",null,{"className":"flex","children":[["$","$L10",null,{"href":"/","className":"inline-flex text-[0.9375rem] items-center gap-2.5 font-medium me-auto","children":"ðŸª· Zen LM"}],"$undefined",["$","$L14",null,{"className":"inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground p-1.5 [&_svg]:size-4.5 mb-auto text-fd-muted-foreground","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-panel-left","aria-hidden":"true","children":[["$","rect","afitv7",{"width":"18","height":"18","x":"3","y":"3","rx":"2"}],["$","path","fh3hqa",{"d":"M9 3v18"}],"$undefined"]}]}]]}],["$","$L15",null,{"hideIfDisabled":true}],false,["$","div",null,{"className":"p-3 rounded-lg bg-primary/10 text-sm","children":[["$","strong",null,{"children":"zen4-max"}]," â€” 1T+ MoE frontier model"]}]]}],["$","$L16",null,{"children":[[["$","$L17","0",{"item":{"text":"HuggingFace","url":"https://huggingface.co/zenlm"},"className":""}],["$","$L17","1",{"item":{"text":"GitHub","url":"https://github.com/zenlm"},"className":"mb-4"}]],["$","$L18",null,{}]]}],["$","div",null,{"className":"flex flex-col border-t p-4 pt-2 empty:hidden","children":[["$","div",null,{"className":"flex text-fd-muted-foreground items-center empty:hidden","children":[false,[],["$","$L19",null,{"className":"ms-auto p-0","mode":"$undefined"}]]}],"$undefined"]}]]}],["$","$L1a",null,{"children":[["$","div",null,{"className":"flex flex-col gap-3 p-4 pb-2","children":[["$","div",null,{"className":"flex text-fd-muted-foreground items-center gap-1.5","children":[["$","div",null,{"className":"flex flex-1","children":[]}],false,["$","$L19",null,{"className":"p-0","mode":"$undefined"}],["$","$L12",null,{"className":"inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground [&_svg]:size-4.5 p-2","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-panel-left","aria-hidden":"true","children":[["$","rect","afitv7",{"width":"18","height":"18","x":"3","y":"3","rx":"2"}],["$","path","fh3hqa",{"d":"M9 3v18"}],"$undefined"]}]}]]}],false,"$7:props:children:props:children:props:children:1:0:props:children:0:props:children:3"]}],"$7:props:children:props:children:props:children:1:0:props:children:1",["$","div",null,{"className":"flex flex-col border-t p-4 pt-2 empty:hidden","children":"$undefined"}]]}]],false,"$L1b"]}]}]}]
8:["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]
9:["$","$1","c",{"children":["$L1c",[["$","script","script-0",{"src":"/_next/static/chunks/458a474de5cd6865.js","async":true,"nonce":"$undefined"}],["$","script","script-1",{"src":"/_next/static/chunks/10b41d05c80e617b.js","async":true,"nonce":"$undefined"}]],["$","$L1d",null,{"children":["$","$1e",null,{"name":"Next.MetadataOutlet","children":"$@1f"}]}]]}]
a:["$","$1","h",{"children":[null,["$","$L20",null,{"children":"$L21"}],["$","div",null,{"hidden":true,"children":["$","$L22",null,{"children":["$","$1e",null,{"name":"Next.Metadata","children":"$L23"}]}]}],null]}]
1b:["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]
24:I[70258,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js","/_next/static/chunks/458a474de5cd6865.js","/_next/static/chunks/10b41d05c80e617b.js"],"DocsPage"]
25:I[70258,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js","/_next/static/chunks/458a474de5cd6865.js","/_next/static/chunks/10b41d05c80e617b.js"],"DocsTitle"]
26:I[70258,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js","/_next/static/chunks/458a474de5cd6865.js","/_next/static/chunks/10b41d05c80e617b.js"],"DocsDescription"]
27:I[70258,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js","/_next/static/chunks/458a474de5cd6865.js","/_next/static/chunks/10b41d05c80e617b.js"],"DocsBody"]
28:I[51504,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js","/_next/static/chunks/458a474de5cd6865.js","/_next/static/chunks/10b41d05c80e617b.js"],"CodeBlock"]
29:I[51504,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js","/_next/static/chunks/458a474de5cd6865.js","/_next/static/chunks/10b41d05c80e617b.js"],"Pre"]
2a:I[25165,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js","/_next/static/chunks/458a474de5cd6865.js","/_next/static/chunks/10b41d05c80e617b.js"],"DynamicModelTable"]
1c:["$","$L24",null,{"toc":[{"depth":1,"url":"#available-models","title":"Available Models"},{"depth":2,"url":"#list-models","title":"List Models"},{"depth":2,"url":"#zen4-generation-9-models","title":"Zen4 Generation (9 models)"},{"depth":2,"url":"#zen3-generation-5-models","title":"Zen3 Generation (5 models)"},{"depth":2,"url":"#model-selection-guide","title":"Model Selection Guide"},{"depth":3,"url":"#by-task","title":"By Task"},{"depth":3,"url":"#by-budget","title":"By Budget"},{"depth":2,"url":"#open-weights","title":"Open Weights"}],"children":[["$","$L25",null,{"children":"Models"}],["$","$L26",null,{"children":"All Zen models -- capabilities, pricing, and recommended use cases"}],["$","$L27",null,{"children":[["$","h1",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"available-models","children":[["$","a",null,{"data-card":"","href":"#available-models","className":"peer","children":"Available Models"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}],"\n",["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"list-models","children":[["$","a",null,{"data-card":"","href":"#list-models","className":"peer","children":"List Models"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}],"\n",["$","$L28",null,{"className":"shiki shiki-themes github-light github-dark","style":{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},"tabIndex":"0","icon":"<svg viewBox=\"0 0 24 24\"><path d=\"M 6,1 C 4.354992,1 3,2.354992 3,4 v 16 c 0,1.645008 1.354992,3 3,3 h 12 c 1.645008,0 3,-1.354992 3,-3 V 8 7 A 1.0001,1.0001 0 0 0 20.707031,6.2929687 l -5,-5 A 1.0001,1.0001 0 0 0 15,1 h -1 z m 0,2 h 7 v 3 c 0,1.645008 1.354992,3 3,3 h 3 v 11 c 0,0.564129 -0.435871,1 -1,1 H 6 C 5.4358712,21 5,20.564129 5,20 V 4 C 5,3.4358712 5.4358712,3 6,3 Z M 15,3.4140625 18.585937,7 H 16 C 15.435871,7 15,6.5641288 15,6 Z\" fill=\"currentColor\" /></svg>","children":["$","$L29",null,{"children":["$","code",null,{"children":["$","span",null,{"className":"line","children":["$","span",null,{"children":"GET https://api.hanzo.ai/v1/models"}]}]}]}]}],"\n",["$","p",null,{"children":"Returns all available Zen models."}],"\n",["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"zen4-generation-9-models","children":[["$","a",null,{"data-card":"","href":"#zen4-generation-9-models","className":"peer","children":"Zen4 Generation (9 models)"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}],"\n",["$","p",null,{"children":"The latest generation. Flagship, reasoning, and code models."}],"\n",["$","$L2a",null,{"generation":"zen4","showArch":true,"showContext":true}],"\n","$L2b","\n","$L2c","\n","$L2d","\n","$L2e","\n","$L2f","\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","$L30","\n","$L31","\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","$L32","\n","$L33","\n","$L34","\n","$L35","\n","$L36"]}]]}]
2b:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"zen3-generation-5-models","children":[["$","a",null,{"data-card":"","href":"#zen3-generation-5-models","className":"peer","children":"Zen3 Generation (5 models)"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
2c:["$","p",null,{"children":"Multimodal, vision, safety, and embedding models."}]
2d:["$","$L2a",null,{"generation":"zen3","showArch":true,"showContext":true}]
2e:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"model-selection-guide","children":[["$","a",null,{"data-card":"","href":"#model-selection-guide","className":"peer","children":"Model Selection Guide"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
2f:["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"by-task","children":[["$","a",null,{"data-card":"","href":"#by-task","className":"peer","children":"By Task"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
30:["$","div",null,{"className":"relative overflow-auto prose-no-margin my-6","children":["$","table",null,{"children":[["$","thead",null,{"children":["$","tr",null,{"children":[["$","th",null,{"children":"Task"}],["$","th",null,{"children":"Recommended Model"}]]}]}],["$","tbody",null,{"children":[["$","tr",null,{"children":[["$","td",null,{"children":"General chat"}],["$","td",null,{"children":"zen4"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Maximum reasoning"}],["$","td",null,{"children":"zen4-ultra"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Deep reasoning (CoT)"}],["$","td",null,{"children":"zen4-thinking"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Code generation"}],["$","td",null,{"children":"zen4-coder"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Fast code iteration"}],["$","td",null,{"children":"zen4-coder-flash"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Premium code accuracy"}],["$","td",null,{"children":"zen4-coder-pro"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Image understanding"}],["$","td",null,{"children":"zen3-vl"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Multimodal (text+vision+audio)"}],["$","td",null,{"children":"zen3-omni"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Content moderation"}],["$","td",null,{"children":"zen3-guard"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Text embeddings"}],["$","td",null,{"children":"zen3-embedding"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Edge / mobile"}],["$","td",null,{"children":"zen3-nano"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Budget-friendly"}],["$","td",null,{"children":"zen4-mini"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Extended context docs"}],["$","td",null,{"children":"zen4-max"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"High capability"}],["$","td",null,{"children":"zen4-pro"}]]}]]}]]}]}]
31:["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"by-budget","children":[["$","a",null,{"data-card":"","href":"#by-budget","className":"peer","children":"By Budget"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
32:["$","div",null,{"className":"relative overflow-auto prose-no-margin my-6","children":["$","table",null,{"children":[["$","thead",null,{"children":["$","tr",null,{"children":[["$","th",null,{"children":"Budget"}],["$","th",null,{"children":"Recommended"}]]}]}],["$","tbody",null,{"children":[["$","tr",null,{"children":[["$","td",null,{"children":"Free tier ($5)"}],["$","td",null,{"children":"zen4-mini, zen3-nano"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Low cost"}],["$","td",null,{"children":"zen4-mini, zen3-vl, zen4-coder-flash"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Standard"}],["$","td",null,{"children":"zen4-pro, zen4-coder, zen4-thinking"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"Premium"}],["$","td",null,{"children":"zen4, zen4-ultra, zen4-coder-pro"}]]}]]}]]}]}]
33:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"open-weights","children":[["$","a",null,{"data-card":"","href":"#open-weights","className":"peer","children":"Open Weights"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
34:["$","p",null,{"children":"All Zen models are also available as open weights for self-hosting:"}]
35:["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"HuggingFace"}],": ",["$","$L10",null,{"href":"https://huggingface.co/zenlm","children":"huggingface.co/zenlm"}]]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Ollama"}],": ",["$","code",null,{"children":"ollama run zen4"}]]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Formats"}],": SafeTensors, GGUF, MLX"]}],"\n"]}]
36:["$","p",null,{"children":"Cloud API via Hanzo gives you managed infrastructure, usage tracking, and pay-per-token billing without running your own GPUs."}]
21:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","2",{"name":"theme-color","media":"(prefers-color-scheme: dark)","content":"#0A0A0A"}],["$","meta","3",{"name":"theme-color","media":"(prefers-color-scheme: light)","content":"#fff"}]]
1f:null
23:[["$","title","0",{"children":"Models | Zen LM"}],["$","meta","1",{"name":"description","content":"All Zen models -- capabilities, pricing, and recommended use cases"}],["$","meta","2",{"property":"og:title","content":"Zen LM - Open Foundation Models"}],["$","meta","3",{"property":"og:description","content":"Zen AI model family by Hanzo AI. 14 frontier models from 4B to 1T+ parameters for code, reasoning, vision, and multimodal tasks."}],["$","meta","4",{"property":"og:url","content":"https://zenlm.org"}],["$","meta","5",{"property":"og:site_name","content":"Zen LM"}],["$","meta","6",{"property":"og:type","content":"website"}],["$","meta","7",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","8",{"name":"twitter:site","content":"@zenlmorg"}],["$","meta","9",{"name":"twitter:creator","content":"@zenlmorg"}],["$","meta","10",{"name":"twitter:title","content":"Zen LM - Open Foundation Models"}],["$","meta","11",{"name":"twitter:description","content":"Zen AI model family by Hanzo AI. 14 frontier models from 4B to 1T+ parameters for code, reasoning, vision, and multimodal tasks."}]]
