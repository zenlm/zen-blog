1:"$Sreact.fragment"
2:I[106,["/_next/static/chunks/59d0ad1b64f8544e.js"],"RootProvider"]
3:I[53113,["/_next/static/chunks/4d80e004cf4896dd.js","/_next/static/chunks/350ee4303b732916.js"],"default"]
4:I[73211,["/_next/static/chunks/4d80e004cf4896dd.js","/_next/static/chunks/350ee4303b732916.js"],"default"]
5:I[10086,["/_next/static/chunks/59d0ad1b64f8544e.js"],""]
6:I[25838,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"TreeContextProvider"]
b:I[6998,["/_next/static/chunks/4d80e004cf4896dd.js","/_next/static/chunks/350ee4303b732916.js"],"default"]
:HL["/_next/static/chunks/f2332aac77592f9d.css","style"]
0:{"P":null,"b":"qMVpAZcUAPsCZEMM19Q64","c":["","docs","models"],"q":"","i":false,"f":[[["",{"children":["docs",{"children":[["slug","models","oc"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],[["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/chunks/f2332aac77592f9d.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","script","script-0",{"src":"/_next/static/chunks/59d0ad1b64f8544e.js","async":true,"nonce":"$undefined"}]],["$","html",null,{"lang":"en","className":"dark","suppressHydrationWarning":true,"children":["$","body",null,{"className":"antialiased","children":["$","$L2",null,{"children":["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","main",null,{"className":"flex min-h-screen flex-col items-center justify-center px-4 text-center","children":[["$","div",null,{"className":"mb-8 opacity-20","children":["$","svg",null,{"width":"120","height":"120","viewBox":"0 0 120 120","fill":"none","aria-hidden":"true","children":["$","circle",null,{"cx":"60","cy":"60","r":"50","stroke":"currentColor","strokeWidth":"3","strokeLinecap":"round","strokeDasharray":"280 40"}]}]}],["$","p",null,{"className":"text-xs font-mono uppercase tracking-[0.3em] text-fd-muted-foreground mb-4","children":"404"}],["$","h1",null,{"className":"text-3xl font-semibold mb-3","children":"Page not found"}],["$","p",null,{"className":"text-fd-muted-foreground max-w-sm mb-10","children":"This page doesn't exist, or it may have moved. Try the documentation or head home."}],["$","div",null,{"className":"flex flex-wrap gap-3 justify-center","children":[["$","$L5",null,{"href":"/","className":"inline-flex items-center gap-2 rounded-lg bg-fd-primary text-fd-primary-foreground px-4 py-2 text-sm font-medium hover:opacity-90 transition","children":"Go home"}],["$","$L5",null,{"href":"/docs","className":"inline-flex items-center gap-2 rounded-lg border border-fd-border bg-fd-background px-4 py-2 text-sm font-medium hover:bg-fd-muted transition","children":"Documentation"}],["$","$L5",null,{"href":"/docs/models","className":"inline-flex items-center gap-2 rounded-lg border border-fd-border bg-fd-background px-4 py-2 text-sm font-medium hover:bg-fd-muted transition","children":"Browse models"}]]}],["$","p",null,{"className":"mt-16 text-xs font-mono text-fd-muted-foreground opacity-50","children":"zenlm.org"}]]}],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]}]]}],{"children":[["$","$1","c",{"children":[[["$","script","script-0",{"src":"/_next/static/chunks/abb1f677d5bfa0d7.js","async":true,"nonce":"$undefined"}],["$","script","script-1",{"src":"/_next/static/chunks/73ee7cc830199358.js","async":true,"nonce":"$undefined"}],["$","script","script-2",{"src":"/_next/static/chunks/713c1b62d4d91e41.js","async":true,"nonce":"$undefined"}],["$","script","script-3",{"src":"/_next/static/chunks/ab3a9da172ad7619.js","async":true,"nonce":"$undefined"}]],["$","$L6",null,{"tree":{"$id":"root","name":"Documentation","children":[{"$id":"index.mdx","type":"page","name":"Introduction","description":"Zen LM by Hanzo AI -- frontier models for code, reasoning, vision, multimodal, embeddings, and safety","icon":"$undefined","url":"/docs","$ref":{"file":"index.mdx"}},{"$id":"_0","type":"separator","icon":"$undefined","name":"Getting Started"},{"type":"folder","name":"Getting started","root":"$undefined","defaultOpen":"$undefined","description":"$undefined","collapsible":"$undefined","children":[{"$id":"getting-started/installation.mdx","type":"page","name":"Installation","description":"Install dependencies for using Zen models","icon":"$undefined","url":"/docs/getting-started/installation","$ref":{"file":"getting-started/installation.mdx"}},{"$id":"getting-started/quickstart.mdx","type":"page","name":"Quickstart","description":"Get started with Zen models in minutes","icon":"$undefined","url":"/docs/getting-started/quickstart","$ref":{"file":"getting-started/quickstart.mdx"}}],"$id":"getting-started","$ref":"$undefined","icon":"$undefined"},{"$id":"_1","type":"separator","icon":"$undefined","name":"API"},{"type":"folder","name":"API Reference","root":"$undefined","defaultOpen":"$undefined","description":"$undefined","collapsible":"$undefined","children":[{"$id":"api/chat-completions.mdx","type":"page","name":"Chat Completions","description":"Generate text with any Zen model using the OpenAI-compatible chat completions endpoint","icon":"$undefined","url":"/docs/api/chat-completions","$ref":{"file":"api/chat-completions.mdx"}},{"$id":"api/embeddings.mdx","type":"page","name":"Embeddings","description":"Generate 3072-dimensional vector embeddings with zen3-embedding","icon":"$undefined","url":"/docs/api/embeddings","$ref":{"file":"api/embeddings.mdx"}},{"$id":"api/models.mdx","type":"page","name":"Models","description":"All Zen models -- capabilities, pricing, and recommended use cases","icon":"$undefined","url":"/docs/api/models","$ref":{"file":"api/models.mdx"}},{"$id":"api/pricing.mdx","type":"page","name":"Pricing","description":"Zen LM API pricing -- transparent at 3x upstream inference cost","icon":"$undefined","url":"/docs/api/pricing","$ref":{"file":"api/pricing.mdx"}}],"$id":"api","$ref":"$undefined","index":{"$id":"api/index.mdx","type":"page","name":"API Reference","description":"Zen LM Cloud API -- OpenAI-compatible endpoints for all Zen models","icon":"$undefined","url":"/docs/api","$ref":{"file":"api/index.mdx"}},"icon":"$undefined"},{"$id":"_2","type":"separator","icon":"$undefined","name":"Models"},{"type":"folder","name":"Models","root":"$undefined","defaultOpen":"$undefined","description":"$undefined","collapsible":"$undefined","children":[{"$id":"models/zen-3d.mdx","type":"page","name":"zen-3d","description":"3D generation model for text-to-3D and image-to-3D asset creation.","icon":"$undefined","url":"/docs/models/zen-3d","$ref":{"file":"models/zen-3d.mdx"}},{"$id":"models/zen-agent.mdx","type":"page","name":"zen-agent","description":"32B dense model with tool use and planning for agentic AI workflows.","icon":"$undefined","url":"/docs/models/zen-agent","$ref":{"file":"models/zen-agent.mdx"}},{"$id":"models/zen-artist-edit.mdx","type":"page","name":"zen-artist-edit","description":"Image editing model for inpainting, outpainting, and edit-by-instruction.","icon":"$undefined","url":"/docs/models/zen-artist-edit","$ref":{"file":"models/zen-artist-edit.mdx"}},{"$id":"models/zen-artist.mdx","type":"page","name":"zen-artist","description":"Image generation model supporting multiple styles and high-resolution output.","icon":"$undefined","url":"/docs/models/zen-artist","$ref":{"file":"models/zen-artist.mdx"}},{"$id":"models/zen-code.mdx","type":"page","name":"zen-code","description":"Legacy 14B dense code model for general programming tasks.","icon":"$undefined","url":"/docs/models/zen-code","$ref":{"file":"models/zen-code.mdx"}},{"$id":"models/zen-coder-flash.mdx","type":"page","name":"zen-coder-flash","description":"Lightweight 7B dense model for low-latency code completions.","icon":"$undefined","url":"/docs/models/zen-coder-flash","$ref":{"file":"models/zen-coder-flash.mdx"}},{"$id":"models/zen-coder.mdx","type":"page","name":"zen-coder","description":"32B dense code model with 131K context for multi-language development.","icon":"$undefined","url":"/docs/models/zen-coder","$ref":{"file":"models/zen-coder.mdx"}},{"$id":"models/zen-designer.mdx","type":"page","name":"zen-designer","description":"Design generation model for UI/UX, graphics, and visual layouts.","icon":"$undefined","url":"/docs/models/zen-designer","$ref":{"file":"models/zen-designer.mdx"}},{"$id":"models/zen-director.mdx","type":"page","name":"zen-director","description":"Text-to-video generation model with cinematic quality output.","icon":"$undefined","url":"/docs/models/zen-director","$ref":{"file":"models/zen-director.mdx"}},{"$id":"models/zen-dub-live.mdx","type":"page","name":"zen-dub-live","description":"Real-time voice synthesis with ultra-low latency for live applications.","icon":"$undefined","url":"/docs/models/zen-dub-live","$ref":{"file":"models/zen-dub-live.mdx"}},{"$id":"models/zen-dub.mdx","type":"page","name":"zen-dub","description":"Voice synthesis and multi-language dubbing model.","icon":"$undefined","url":"/docs/models/zen-dub","$ref":{"file":"models/zen-dub.mdx"}},{"$id":"models/zen-eco.mdx","type":"page","name":"zen-eco","description":"Efficient 4B dense model balancing capability and cost for general-purpose tasks.","icon":"$undefined","url":"/docs/models/zen-eco","$ref":{"file":"models/zen-eco.mdx"}},{"$id":"models/zen-embedding.mdx","type":"page","name":"zen-embedding","description":"Foundation embedding model for search and retrieval.","icon":"$undefined","url":"/docs/models/zen-embedding","$ref":{"file":"models/zen-embedding.mdx"}},{"$id":"models/zen-foley.mdx","type":"page","name":"zen-foley","description":"Sound effects generation model for text-to-SFX production.","icon":"$undefined","url":"/docs/models/zen-foley","$ref":{"file":"models/zen-foley.mdx"}},{"$id":"models/zen-guard-gen.mdx","type":"page","name":"zen-guard-gen","description":"8B dense model for safe text generation with built-in guardrails.","icon":"$undefined","url":"/docs/models/zen-guard-gen","$ref":{"file":"models/zen-guard-gen.mdx"}},{"$id":"models/zen-guard-stream.mdx","type":"page","name":"zen-guard-stream","description":"4B dense model for low-latency streaming content moderation.","icon":"$undefined","url":"/docs/models/zen-guard-stream","$ref":{"file":"models/zen-guard-stream.mdx"}},{"$id":"models/zen-guard.mdx","type":"page","name":"zen-guard","description":"Content safety and moderation classifier.","icon":"$undefined","url":"/docs/models/zen-guard","$ref":{"file":"models/zen-guard.mdx"}},{"$id":"models/zen-live.mdx","type":"page","name":"zen-live","description":"Real-time bidirectional speech translation with ultra-low latency.","icon":"$undefined","url":"/docs/models/zen-live","$ref":{"file":"models/zen-live.mdx"}},{"$id":"models/zen-max.mdx","type":"page","name":"zen-max","description":"Trillion-parameter 1.04T MoE open-weights frontier model. Same model as zen4-max.","icon":"$undefined","url":"/docs/models/zen-max","$ref":{"file":"models/zen-max.mdx"}},{"$id":"models/zen-musician.mdx","type":"page","name":"zen-musician","description":"Music generation model with multi-instrument composition and style control.","icon":"$undefined","url":"/docs/models/zen-musician","$ref":{"file":"models/zen-musician.mdx"}},{"$id":"models/zen-nano.mdx","type":"page","name":"zen-nano","description":"Ultra-compact 0.6B dense model for edge inference at 44K tokens/sec.","icon":"$undefined","url":"/docs/models/zen-nano","$ref":{"file":"models/zen-nano.mdx"}},{"$id":"models/zen-next.mdx","type":"page","name":"zen-next","description":"Next-generation preview model with cutting-edge capabilities.","icon":"$undefined","url":"/docs/models/zen-next","$ref":{"file":"models/zen-next.mdx"}},{"$id":"models/zen-omni.mdx","type":"page","name":"zen-omni","description":"72B dense hypermodal model supporting text, vision, audio, and code.","icon":"$undefined","url":"/docs/models/zen-omni","$ref":{"file":"models/zen-omni.mdx"}},{"$id":"models/zen-pro.mdx","type":"page","name":"zen-pro","description":"Professional-grade 32B dense model with 19K tokens/sec throughput.","icon":"$undefined","url":"/docs/models/zen-pro","$ref":{"file":"models/zen-pro.mdx"}},{"$id":"models/zen-reranker.mdx","type":"page","name":"zen-reranker","description":"568M dense cross-encoder model for search result reranking.","icon":"$undefined","url":"/docs/models/zen-reranker","$ref":{"file":"models/zen-reranker.mdx"}},{"$id":"models/zen-scribe.mdx","type":"page","name":"zen-scribe","description":"Speech-to-text transcription model with multi-language support.","icon":"$undefined","url":"/docs/models/zen-scribe","$ref":{"file":"models/zen-scribe.mdx"}},{"$id":"models/zen-translator.mdx","type":"page","name":"zen-translator","description":"Context-aware translation model supporting 100+ languages.","icon":"$undefined","url":"/docs/models/zen-translator","$ref":{"file":"models/zen-translator.mdx"}},{"$id":"models/zen-video-i2v.mdx","type":"page","name":"zen-video-i2v","description":"Image-to-video animation model that brings still images to life.","icon":"$undefined","url":"/docs/models/zen-video-i2v","$ref":{"file":"models/zen-video-i2v.mdx"}},{"$id":"models/zen-video.mdx","type":"page","name":"zen-video","description":"Video understanding model for frame analysis, captioning, and temporal reasoning.","icon":"$undefined","url":"/docs/models/zen-video","$ref":{"file":"models/zen-video.mdx"}},{"$id":"models/zen-vl.mdx","type":"page","name":"zen-vl","description":"32B dense multimodal model for vision-language understanding.","icon":"$undefined","url":"/docs/models/zen-vl","$ref":{"file":"models/zen-vl.mdx"}},{"$id":"models/zen-voyager.mdx","type":"page","name":"zen-voyager","description":"World model for spatial reasoning and 3D scene understanding.","icon":"$undefined","url":"/docs/models/zen-voyager","$ref":{"file":"models/zen-voyager.mdx"}},{"$id":"models/zen-world.mdx","type":"page","name":"zen-world","description":"World simulation model for spatial reasoning and environment generation.","icon":"$undefined","url":"/docs/models/zen-world","$ref":{"file":"models/zen-world.mdx"}},{"$id":"models/zen.mdx","type":"page","name":"zen","description":"Standard 8-32B dense foundation model for general-purpose AI tasks.","icon":"$undefined","url":"/docs/models/zen","$ref":{"file":"models/zen.mdx"}},{"$id":"models/zen3-asr-v1.mdx","type":"page","name":"zen3-asr-v1","description":"First-generation streaming ASR for legacy compatibility.","icon":"$undefined","url":"/docs/models/zen3-asr-v1","$ref":{"file":"models/zen3-asr-v1.mdx"}},{"$id":"models/zen3-asr.mdx","type":"page","name":"zen3-asr","description":"Real-time streaming speech recognition for live transcription and voice agents.","icon":"$undefined","url":"/docs/models/zen3-asr","$ref":{"file":"models/zen3-asr.mdx"}},{"$id":"models/zen3-audio-fast.mdx","type":"page","name":"zen3-audio-fast","description":"Fastest speech-to-text transcription for high-throughput workloads.","icon":"$undefined","url":"/docs/models/zen3-audio-fast","$ref":{"file":"models/zen3-audio-fast.mdx"}},{"$id":"models/zen3-audio.mdx","type":"page","name":"zen3-audio","description":"Best quality speech-to-text transcription. 100+ languages.","icon":"$undefined","url":"/docs/models/zen3-audio","$ref":{"file":"models/zen3-audio.mdx"}},{"$id":"models/zen3-embedding-medium.mdx","type":"page","name":"zen3-embedding-medium","description":"Balanced embedding model for cost-effective retrieval workloads.","icon":"$undefined","url":"/docs/models/zen3-embedding-medium","$ref":{"file":"models/zen3-embedding-medium.mdx"}},{"$id":"models/zen3-embedding-small.mdx","type":"page","name":"zen3-embedding-small","description":"Lightweight embedding model for high-throughput, low-cost applications.","icon":"$undefined","url":"/docs/models/zen3-embedding-small","$ref":{"file":"models/zen3-embedding-small.mdx"}},{"$id":"models/zen3-embedding.mdx","type":"page","name":"zen3-embedding","description":"High-quality text embedding model with 3072 dimensions and 8K context.","icon":"$undefined","url":"/docs/models/zen3-embedding","$ref":{"file":"models/zen3-embedding.mdx"}},{"$id":"models/zen3-guard.mdx","type":"page","name":"zen3-guard","description":"Content safety classifier with 4B dense architecture. 65K context.","icon":"$undefined","url":"/docs/models/zen3-guard","$ref":{"file":"models/zen3-guard.mdx"}},{"$id":"models/zen3-image-dev.mdx","type":"page","name":"zen3-image-dev","description":"Development model for experimentation and iteration.","icon":"$undefined","url":"/docs/models/zen3-image-dev","$ref":{"file":"models/zen3-image-dev.mdx"}},{"$id":"models/zen3-image-fast.mdx","type":"page","name":"zen3-image-fast","description":"Fastest image model for real-time generation.","icon":"$undefined","url":"/docs/models/zen3-image-fast","$ref":{"file":"models/zen3-image-fast.mdx"}},{"$id":"models/zen3-image-jp.mdx","type":"page","name":"zen3-image-jp","description":"Japanese-specialized image generation model.","icon":"$undefined","url":"/docs/models/zen3-image-jp","$ref":{"file":"models/zen3-image-jp.mdx"}},{"$id":"models/zen3-image-max.mdx","type":"page","name":"zen3-image-max","description":"Maximum quality image generation for professional creative work.","icon":"$undefined","url":"/docs/models/zen3-image-max","$ref":{"file":"models/zen3-image-max.mdx"}},{"$id":"models/zen3-image-playground.mdx","type":"page","name":"zen3-image-playground","description":"Aesthetic model for artistic image generation.","icon":"$undefined","url":"/docs/models/zen3-image-playground","$ref":{"file":"models/zen3-image-playground.mdx"}},{"$id":"models/zen3-image-sdxl.mdx","type":"page","name":"zen3-image-sdxl","description":"High-resolution image generation at 1024px.","icon":"$undefined","url":"/docs/models/zen3-image-sdxl","$ref":{"file":"models/zen3-image-sdxl.mdx"}},{"$id":"models/zen3-image-ssd.mdx","type":"page","name":"zen3-image-ssd","description":"Fastest diffusion model for real-time generation.","icon":"$undefined","url":"/docs/models/zen3-image-ssd","$ref":{"file":"models/zen3-image-ssd.mdx"}},{"$id":"models/zen3-image.mdx","type":"page","name":"zen3-image","description":"Best general-purpose image generation.","icon":"$undefined","url":"/docs/models/zen3-image","$ref":{"file":"models/zen3-image.mdx"}},{"$id":"models/zen3-nano.mdx","type":"page","name":"zen3-nano","description":"Ultra-lightweight 4B dense model for edge deployment. 40K context.","icon":"$undefined","url":"/docs/models/zen3-nano","$ref":{"file":"models/zen3-nano.mdx"}},{"$id":"models/zen3-omni.mdx","type":"page","name":"zen3-omni","description":"Hypermodal ~200B dense model supporting text, vision, and audio. 202K context.","icon":"$undefined","url":"/docs/models/zen3-omni","$ref":{"file":"models/zen3-omni.mdx"}},{"$id":"models/zen3-reranker-medium.mdx","type":"page","name":"zen3-reranker-medium","description":"Balanced reranker for cost-effective retrieval quality improvement.","icon":"$undefined","url":"/docs/models/zen3-reranker-medium","$ref":{"file":"models/zen3-reranker-medium.mdx"}},{"$id":"models/zen3-reranker-small.mdx","type":"page","name":"zen3-reranker-small","description":"Lightweight reranker for high-throughput reranking at minimal cost.","icon":"$undefined","url":"/docs/models/zen3-reranker-small","$ref":{"file":"models/zen3-reranker-small.mdx"}},{"$id":"models/zen3-reranker.mdx","type":"page","name":"zen3-reranker","description":"High-quality reranker for improving retrieval accuracy in RAG pipelines.","icon":"$undefined","url":"/docs/models/zen3-reranker","$ref":{"file":"models/zen3-reranker.mdx"}},{"$id":"models/zen3-tts-fast.mdx","type":"page","name":"zen3-tts-fast","description":"Low-latency text-to-speech for real-time voice agents and interactive applications.","icon":"$undefined","url":"/docs/models/zen3-tts-fast","$ref":{"file":"models/zen3-tts-fast.mdx"}},{"$id":"models/zen3-tts-hd.mdx","type":"page","name":"zen3-tts-hd","description":"Maximum fidelity text-to-speech for broadcast-quality audio production.","icon":"$undefined","url":"/docs/models/zen3-tts-hd","$ref":{"file":"models/zen3-tts-hd.mdx"}},{"$id":"models/zen3-tts.mdx","type":"page","name":"zen3-tts","description":"High-quality text-to-speech with natural prosody. 40+ voices, 8 languages.","icon":"$undefined","url":"/docs/models/zen3-tts","$ref":{"file":"models/zen3-tts.mdx"}},{"$id":"models/zen3-vl.mdx","type":"page","name":"zen3-vl","description":"Vision-language model with 30B (3B active) MoE architecture. 262K context.","icon":"$undefined","url":"/docs/models/zen3-vl","$ref":{"file":"models/zen3-vl.mdx"}},{"$id":"models/zen4-coder-flash.mdx","type":"page","name":"zen4-coder-flash","description":"Fast 30B (3B active) MoE code model with 262K context.","icon":"$undefined","url":"/docs/models/zen4-coder-flash","$ref":{"file":"models/zen4-coder-flash.mdx"}},{"$id":"models/zen4-coder-pro.mdx","type":"page","name":"zen4-coder-pro","description":"Premium 480B full-precision BF16 code model with 131K context.","icon":"$undefined","url":"/docs/models/zen4-coder-pro","$ref":{"file":"models/zen4-coder-pro.mdx"}},{"$id":"models/zen4-coder.mdx","type":"page","name":"zen4-coder","description":"Code generation model with 480B (35B active) MoE and 163K context.","icon":"$undefined","url":"/docs/models/zen4-coder","$ref":{"file":"models/zen4-coder.mdx"}},{"$id":"models/zen4-max.mdx","type":"page","name":"zen4-max","description":"Trillion-parameter frontier MoE model. 1.04T (32B active) with 163K context.","icon":"$undefined","url":"/docs/models/zen4-max","$ref":{"file":"models/zen4-max.mdx"}},{"$id":"models/zen4-mini.mdx","type":"page","name":"zen4-mini","description":"Fast and efficient 8B dense model with 40K context.","icon":"$undefined","url":"/docs/models/zen4-mini","$ref":{"file":"models/zen4-mini.mdx"}},{"$id":"models/zen4-pro.mdx","type":"page","name":"zen4-pro","description":"High capability MoE model. 80B (3B active) with 131K context.","icon":"$undefined","url":"/docs/models/zen4-pro","$ref":{"file":"models/zen4-pro.mdx"}},{"$id":"models/zen4-thinking.mdx","type":"page","name":"zen4-thinking","description":"Deep reasoning model with 80B (3B active) MoE + chain-of-thought. 131K context.","icon":"$undefined","url":"/docs/models/zen4-thinking","$ref":{"file":"models/zen4-thinking.mdx"}},{"$id":"models/zen4-ultra.mdx","type":"page","name":"zen4-ultra","description":"Maximum reasoning model with 744B MoE (40B active) + extended chain-of-thought. 262K context.","icon":"$undefined","url":"/docs/models/zen4-ultra","$ref":{"file":"models/zen4-ultra.mdx"}},{"$id":"models/zen4.1.mdx","type":"page","name":"zen4.1","description":"High-performance 1M context model for long-document analysis, large codebase reasoning, and agentic workflows. Best balance of intelligence and cost at million-token scale.","icon":"$undefined","url":"/docs/models/zen4.1","$ref":{"file":"models/zen4.1.mdx"}},{"$id":"models/zen4.mdx","type":"page","name":"zen4","description":"Flagship 744B MoE model with 40B active parameters and 202K context window.","icon":"$undefined","url":"/docs/models/zen4","$ref":{"file":"models/zen4.mdx"}},{"$id":"models/zen5-coder.mdx","type":"page","name":"zen5-coder","description":"Next-generation code model. Zen5 architecture optimized for agentic programming. Research Preview.","icon":"$undefined","url":"/docs/models/zen5-coder","$ref":{"file":"models/zen5-coder.mdx"}},{"$id":"models/zen5-max.mdx","type":"page","name":"zen5-max","description":"Maximum-scale Zen5 model. Multi-trillion parameter frontier MoE. Research Preview.","icon":"$undefined","url":"/docs/models/zen5-max","$ref":{"file":"models/zen5-max.mdx"}},{"$id":"models/zen5-mini.mdx","type":"page","name":"zen5-mini","description":"Efficient agentic model delivering zen5-class intelligence at a fraction of the cost.","icon":"$undefined","url":"/docs/models/zen5-mini","$ref":{"file":"models/zen5-mini.mdx"}},{"$id":"models/zen5-pro.mdx","type":"page","name":"zen5-pro","description":"High-throughput agentic model for demanding production workloads. Trained on real-world development patterns with deep chain-of-thought reasoning.","icon":"$undefined","url":"/docs/models/zen5-pro","$ref":{"file":"models/zen5-pro.mdx"}},{"$id":"models/zen5-ultra.mdx","type":"page","name":"zen5-ultra","description":"Deepest reasoning model in the Zen family. Multi-pass chain-of-thought with self-verification.","icon":"$undefined","url":"/docs/models/zen5-ultra","$ref":{"file":"models/zen5-ultra.mdx"}},{"$id":"models/zen5.mdx","type":"page","name":"zen5","description":"Next-generation flagship model. 2T+ MoE with on-chain training via NVIDIA TEE. Research Preview.","icon":"$undefined","url":"/docs/models/zen5","$ref":{"file":"models/zen5.mdx"}}],"$id":"models","$ref":"$undefined","icon":"$undefined"},{"type":"folder","name":"Training","root":"$undefined","defaultOpen":"$undefined","description":"$undefined","collapsible":"$undefined","children":[{"$id":"training/cloud.mdx","type":"page","name":"Cloud Training","description":"Full-scale training on 8x H200 GPUs","icon":"$undefined","url":"/docs/training/cloud","$ref":{"file":"training/cloud.mdx"}},{"$id":"training/cuda.mdx","type":"page","name":"CUDA Training","description":"Train locally with NVIDIA GPUs","icon":"$undefined","url":"/docs/training/cuda","$ref":{"file":"training/cuda.mdx"}},{"$id":"training/mlx.mdx","type":"page","name":"MLX Training","description":"Train on Apple Silicon with MLX","icon":"$undefined","url":"/docs/training/mlx","$ref":{"file":"training/mlx.mdx"}},{"$id":"training/overview.mdx","type":"page","name":"Training Overview","description":"Train Zen models with multiple backend options","icon":"$undefined","url":"/docs/training/overview","$ref":{"file":"training/overview.mdx"}}],"$id":"training","$ref":"$undefined","icon":"$undefined"},{"$id":"datasets.mdx","type":"page","name":"Zen Agentic Dataset","description":"Zen Agentic Dataset - 8.47 billion tokens of real-world agentic programming","icon":"$undefined","url":"/docs/datasets","$ref":{"file":"datasets.mdx"}}],"fallback":{"$id":"fallback:root","name":"Docs","children":[{"$id":"fallback:models.mdx","type":"page","name":"Models","description":"Complete Zen LM model family â€” 80+ models across text, code, vision, audio, image, video, 3D, embedding, safety, and agent modalities","icon":"$undefined","url":"/docs/models","$ref":{"file":"models.mdx"}},{"$id":"fallback:training.mdx","type":"page","name":"Fine-tuning Guide","description":"Fine-tune Zen4 models with MLX, Unsloth, or DeepSpeed","icon":"$undefined","url":"/docs/training","$ref":{"file":"training.mdx"}}]}},"children":"$L7"}]]}],{"children":["$L8",{"children":["$L9",{},null,false,false]},null,false,false]},null,false,false]},null,false,false],"$La",false]],"m":"$undefined","G":["$b",[]],"S":true}
c:I[99924,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"LayoutContextProvider"]
d:I[32824,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SidebarProvider"]
e:I[99924,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"LayoutBody"]
f:I[99924,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"LayoutHeader"]
10:I[48068,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js","/_next/static/chunks/458a474de5cd6865.js","/_next/static/chunks/10b41d05c80e617b.js"],"default"]
11:I[80761,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SearchToggle"]
12:I[32824,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SidebarTrigger"]
13:I[80157,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SidebarContent"]
14:I[32824,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SidebarCollapseTrigger"]
15:I[80761,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"LargeSearchToggle"]
16:I[32824,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SidebarViewport"]
17:I[80157,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SidebarLinkItem"]
18:I[80157,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SidebarPageTree"]
19:I[73332,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"ThemeToggle"]
1a:I[80157,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js"],"SidebarDrawer"]
1d:I[89923,["/_next/static/chunks/4d80e004cf4896dd.js","/_next/static/chunks/350ee4303b732916.js"],"OutletBoundary"]
1e:"$Sreact.suspense"
20:I[89923,["/_next/static/chunks/4d80e004cf4896dd.js","/_next/static/chunks/350ee4303b732916.js"],"ViewportBoundary"]
22:I[89923,["/_next/static/chunks/4d80e004cf4896dd.js","/_next/static/chunks/350ee4303b732916.js"],"MetadataBoundary"]
7:["$","$Lc",null,{"navTransparentMode":"$undefined","children":["$","$Ld",null,{"defaultOpenLevel":"$undefined","prefetch":"$undefined","children":["$","$Le",null,{"children":[["$","$Lf",null,{"id":"nd-subnav","className":"[grid-area:header] sticky top-(--fd-docs-row-1) z-30 flex items-center ps-4 pe-2.5 border-b transition-colors backdrop-blur-sm h-(--fd-header-height) md:hidden max-md:layout:[--fd-header-height:--spacing(14)] data-[transparent=false]:bg-fd-background/80","children":[["$","$L10",null,{"href":"/","className":"inline-flex items-center gap-2.5 font-semibold","children":"ðŸª· Zen LM"}],["$","div",null,{"className":"flex-1","children":"$undefined"}],["$","$L11",null,{"className":"p-2","hideIfDisabled":true}],["$","$L12",null,{"className":"inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground [&_svg]:size-4.5 p-2","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-panel-left","aria-hidden":"true","children":[["$","rect","afitv7",{"width":"18","height":"18","x":"3","y":"3","rx":"2"}],["$","path","fh3hqa",{"d":"M9 3v18"}],"$undefined"]}]}]]}],[["$","$L13",null,{"children":[["$","div",null,{"className":"flex flex-col gap-3 p-4 pb-2","children":[["$","div",null,{"className":"flex","children":[["$","$L10",null,{"href":"/","className":"inline-flex text-[0.9375rem] items-center gap-2.5 font-medium me-auto","children":"ðŸª· Zen LM"}],"$undefined",["$","$L14",null,{"className":"inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground p-1.5 [&_svg]:size-4.5 mb-auto text-fd-muted-foreground","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-panel-left","aria-hidden":"true","children":[["$","rect","afitv7",{"width":"18","height":"18","x":"3","y":"3","rx":"2"}],["$","path","fh3hqa",{"d":"M9 3v18"}],"$undefined"]}]}]]}],["$","$L15",null,{"hideIfDisabled":true}],false,["$","div",null,{"className":"p-3 rounded-lg bg-primary/10 text-sm","children":[["$","strong",null,{"children":"zen4-max"}]," â€” 1T+ MoE frontier model"]}]]}],["$","$L16",null,{"children":[[["$","$L17","0",{"item":{"text":"HuggingFace","url":"https://huggingface.co/zenlm"},"className":""}],["$","$L17","1",{"item":{"text":"GitHub","url":"https://github.com/zenlm"},"className":"mb-4"}]],["$","$L18",null,{}]]}],["$","div",null,{"className":"flex flex-col border-t p-4 pt-2 empty:hidden","children":[["$","div",null,{"className":"flex text-fd-muted-foreground items-center empty:hidden","children":[false,[],["$","$L19",null,{"className":"ms-auto p-0","mode":"$undefined"}]]}],"$undefined"]}]]}],["$","$L1a",null,{"children":[["$","div",null,{"className":"flex flex-col gap-3 p-4 pb-2","children":[["$","div",null,{"className":"flex text-fd-muted-foreground items-center gap-1.5","children":[["$","div",null,{"className":"flex flex-1","children":[]}],false,["$","$L19",null,{"className":"p-0","mode":"$undefined"}],["$","$L12",null,{"className":"inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-fd-ring hover:bg-fd-accent hover:text-fd-accent-foreground [&_svg]:size-4.5 p-2","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-panel-left","aria-hidden":"true","children":[["$","rect","afitv7",{"width":"18","height":"18","x":"3","y":"3","rx":"2"}],["$","path","fh3hqa",{"d":"M9 3v18"}],"$undefined"]}]}]]}],false,"$7:props:children:props:children:props:children:1:0:props:children:0:props:children:3"]}],"$7:props:children:props:children:props:children:1:0:props:children:1",["$","div",null,{"className":"flex flex-col border-t p-4 pt-2 empty:hidden","children":"$undefined"}]]}]],false,"$L1b"]}]}]}]
8:["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]
9:["$","$1","c",{"children":["$L1c",[["$","script","script-0",{"src":"/_next/static/chunks/458a474de5cd6865.js","async":true,"nonce":"$undefined"}],["$","script","script-1",{"src":"/_next/static/chunks/10b41d05c80e617b.js","async":true,"nonce":"$undefined"}]],["$","$L1d",null,{"children":["$","$1e",null,{"name":"Next.MetadataOutlet","children":"$@1f"}]}]]}]
a:["$","$1","h",{"children":[null,["$","$L20",null,{"children":"$L21"}],["$","div",null,{"hidden":true,"children":["$","$L22",null,{"children":["$","$1e",null,{"name":"Next.Metadata","children":"$L23"}]}]}],null]}]
1b:["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]
24:I[70258,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js","/_next/static/chunks/458a474de5cd6865.js","/_next/static/chunks/10b41d05c80e617b.js"],"DocsPage"]
25:I[70258,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js","/_next/static/chunks/458a474de5cd6865.js","/_next/static/chunks/10b41d05c80e617b.js"],"DocsTitle"]
26:I[70258,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js","/_next/static/chunks/458a474de5cd6865.js","/_next/static/chunks/10b41d05c80e617b.js"],"DocsDescription"]
27:I[70258,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js","/_next/static/chunks/458a474de5cd6865.js","/_next/static/chunks/10b41d05c80e617b.js"],"DocsBody"]
28:I[25165,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js","/_next/static/chunks/458a474de5cd6865.js","/_next/static/chunks/10b41d05c80e617b.js"],"ModelTable"]
1c:["$","$L24",null,{"toc":[{"depth":1,"url":"#zen-models","title":"Zen Models"},{"depth":2,"url":"#zen-5--next-generation","title":"Zen 5 â€” Next Generation"},{"depth":2,"url":"#zen-4--production-api","title":"Zen 4 â€” Production API"},{"depth":2,"url":"#code","title":"Code"},{"depth":2,"url":"#zen-3--previous-generation-api","title":"Zen 3 â€” Previous Generation API"},{"depth":2,"url":"#embedding--retrieval","title":"Embedding & Retrieval"},{"depth":2,"url":"#image-generation","title":"Image Generation"},{"depth":2,"url":"#audio--speech","title":"Audio & Speech"},{"depth":2,"url":"#foundation--open-weights","title":"Foundation â€” Open Weights"},{"depth":2,"url":"#vision--open-weights","title":"Vision â€” Open Weights"},{"depth":2,"url":"#safety--guardrails","title":"Safety & Guardrails"},{"depth":2,"url":"#agents","title":"Agents"},{"depth":2,"url":"#video-coming-soon","title":"Video (Coming Soon)"},{"depth":2,"url":"#audio-creative-coming-soon","title":"Audio Creative (Coming Soon)"},{"depth":2,"url":"#3d--spatial-coming-soon","title":"3D & Spatial (Coming Soon)"},{"depth":2,"url":"#api-usage","title":"API Usage"},{"depth":2,"url":"#open-weights-formats","title":"Open Weights Formats"}],"children":[["$","$L25",null,{"children":"Models"}],["$","$L26",null,{"children":"Complete Zen LM model family â€” 80+ models across text, code, vision, audio, image, video, 3D, embedding, safety, and agent modalities"}],["$","$L27",null,{"children":[["$","h1",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"zen-models","children":[["$","a",null,{"data-card":"","href":"#zen-models","className":"peer","children":"Zen Models"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}],"\n",["$","p",null,{"children":["Zen LM by Hanzo AI is a comprehensive model family built using ",["$","strong",null,{"children":"Zen MoDE (Mixture of Distilled Experts)"}]," â€” curating the best open-source foundations and fusing them into a unified, high-performance family."]}],"\n",["$","p",null,{"children":["All API models are accessed at ",["$","code",null,{"children":"api.hanzo.ai"}],". API key prefix: ",["$","code",null,{"children":"hk-"}],". Open-weight models are available on ",["$","$L10",null,{"href":"https://huggingface.co/zenlm","children":"HuggingFace"}],"."]}],"\n",["$","hr",null,{}],"\n",["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"zen-5--next-generation","children":[["$","a",null,{"data-card":"","href":"#zen-5--next-generation","className":"peer","children":"Zen 5 â€” Next Generation"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}],"\n",["$","p",null,{"children":["Next-generation agentic models with native chain-of-thought, currently in preview. Training on-chain via NVIDIA TEE on ",["$","$L10",null,{"href":"https://hanzo.network","children":"hanzo.network"}],"."]}],"\n",["$","$L28",null,{"ids":["zen5","zen5-pro","zen5-max","zen5-ultra","zen5-mini"]}],"\n",["$","p",null,{"children":["Request early access: ",["$","$L10",null,{"href":"mailto:z@hanzo.ai","children":"z@hanzo.ai"}]]}],"\n",["$","hr",null,{}],"\n",["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"zen-4--production-api","children":[["$","a",null,{"data-card":"","href":"#zen-4--production-api","className":"peer","children":"Zen 4 â€” Production API"}],"$L29"]}],"\n","$L2a","\n","$L2b","\n","$L2c","\n","$L2d","\n","$L2e","\n","$L2f","\n","$L30","\n","$L31","\n","$L32","\n","$L33","\n","$L34","\n","$L35","\n","$L36","\n","$L37","\n","$L38","\n","$L39","\n","$L3a","\n","$L3b","\n","$L3c","\n","$L3d","\n","$L3e","\n","$L3f","\n","$L40","\n","$L41","\n","$L42","\n","$L43","\n","$L44","\n","$L45","\n","$L46","\n","$L47","\n","$L48","\n","$L49","\n","$L4a","\n","$L4b","\n","$L4c","\n","$L4d","\n","$L4e","\n","$L4f","\n","$L50","\n","$L51","\n","$L52","\n","$L53","\n","$L54","\n","$L55","\n","$L56","\n","$L57","\n","$L58","\n","$L59","\n","$L5a","\n","$L5b","\n","$L5c","\n","$L5d","\n","$L5e","\n","$L5f","\n","$L60","\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","$L61"]}]]}]
62:I[51504,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js","/_next/static/chunks/458a474de5cd6865.js","/_next/static/chunks/10b41d05c80e617b.js"],"CodeBlock"]
64:I[51504,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/abb1f677d5bfa0d7.js","/_next/static/chunks/73ee7cc830199358.js","/_next/static/chunks/713c1b62d4d91e41.js","/_next/static/chunks/ab3a9da172ad7619.js","/_next/static/chunks/458a474de5cd6865.js","/_next/static/chunks/10b41d05c80e617b.js"],"Pre"]
29:["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]
2a:["$","p",null,{"children":"Latest generation production models with MoDE architecture. The recommended choice for all new applications."}]
2b:["$","$L28",null,{"ids":["zen4-max","zen4.1","zen4","zen4-ultra","zen4-pro","zen4-thinking","zen4-mini"],"showArch":true}]
2c:["$","hr",null,{}]
2d:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"code","children":[["$","a",null,{"data-card":"","href":"#code","className":"peer","children":"Code"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
2e:["$","p",null,{"children":"Specialized models for code generation, review, debugging, and agentic programming."}]
2f:["$","$L28",null,{"ids":["zen4-coder","zen4-coder-flash","zen4-coder-pro","zen-coder","zen-coder-flash","zen-code"],"showArch":true}]
30:["$","hr",null,{}]
31:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"zen-3--previous-generation-api","children":[["$","a",null,{"data-card":"","href":"#zen-3--previous-generation-api","className":"peer","children":"Zen 3 â€” Previous Generation API"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
32:["$","p",null,{"children":"Earlier generation API models â€” language, vision, multimodal, and safety. Still production-ready and widely deployed."}]
33:["$","$L28",null,{"ids":["zen3-omni","zen3-vl","zen3-nano","zen3-guard"],"showArch":true}]
34:["$","hr",null,{}]
35:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"embedding--retrieval","children":[["$","a",null,{"data-card":"","href":"#embedding--retrieval","className":"peer","children":"Embedding & Retrieval"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
36:["$","p",null,{"children":["Text embeddings and search reranking via ",["$","code",null,{"children":"/v1/embeddings"}]," and ",["$","code",null,{"children":"/v1/rerank"}],"."]}]
37:["$","$L28",null,{"ids":["zen3-embedding","zen3-embedding-medium","zen3-embedding-small","zen3-reranker","zen3-reranker-medium","zen3-reranker-small","zen-embedding","zen-reranker"],"showParams":false,"showArch":true}]
38:["$","hr",null,{}]
39:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"image-generation","children":[["$","a",null,{"data-card":"","href":"#image-generation","className":"peer","children":"Image Generation"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
3a:["$","p",null,{"children":["Text-to-image generation via ",["$","code",null,{"children":"/v1/images/generations"}],"."]}]
3b:["$","$L28",null,{"ids":["zen3-image","zen3-image-max","zen3-image-dev","zen3-image-fast","zen3-image-sdxl","zen3-image-playground","zen3-image-ssd","zen3-image-jp"],"showParams":false,"showContext":false}]
3c:["$","hr",null,{}]
3d:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"audio--speech","children":[["$","a",null,{"data-card":"","href":"#audio--speech","className":"peer","children":"Audio & Speech"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
3e:["$","p",null,{"children":["Speech-to-text, text-to-speech, and streaming ASR via ",["$","code",null,{"children":"/v1/audio/"}],"."]}]
3f:["$","$L28",null,{"ids":["zen3-audio","zen3-audio-fast","zen3-asr","zen3-asr-v1","zen3-tts","zen3-tts-hd","zen3-tts-fast"],"showParams":false,"showContext":false}]
40:["$","hr",null,{}]
41:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"foundation--open-weights","children":[["$","a",null,{"data-card":"","href":"#foundation--open-weights","className":"peer","children":"Foundation â€” Open Weights"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
42:["$","p",null,{"children":["General-purpose open-weight models available on ",["$","$L10",null,{"href":"https://huggingface.co/zenlm","children":"HuggingFace"}]," in GGUF, SafeTensors, MLX, and ONNX formats."]}]
43:["$","$L28",null,{"ids":["zen-nano","zen-eco","zen","zen-pro","zen-max","zen-next"],"showPricing":false}]
44:["$","hr",null,{}]
45:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"vision--open-weights","children":[["$","a",null,{"data-card":"","href":"#vision--open-weights","className":"peer","children":"Vision â€” Open Weights"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
46:["$","p",null,{"children":"Vision-language and multimodal open-weight models."}]
47:["$","$L28",null,{"ids":["zen-vl","zen-omni"],"showPricing":false}]
48:["$","hr",null,{}]
49:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"safety--guardrails","children":[["$","a",null,{"data-card":"","href":"#safety--guardrails","className":"peer","children":"Safety & Guardrails"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
4a:["$","p",null,{"children":"Content moderation and safety guardrail models."}]
4b:["$","$L28",null,{"ids":["zen-guard","zen3-guard","zen-guard-gen","zen-guard-stream"]}]
4c:["$","hr",null,{}]
4d:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"agents","children":[["$","a",null,{"data-card":"","href":"#agents","className":"peer","children":"Agents"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
4e:["$","p",null,{"children":"Agent-optimized models for tool use, planning, and autonomous workflows."}]
4f:["$","$L28",null,{"ids":["zen-agent"]}]
50:["$","hr",null,{}]
51:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"video-coming-soon","children":[["$","a",null,{"data-card":"","href":"#video-coming-soon","className":"peer","children":"Video (Coming Soon)"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
52:["$","$L28",null,{"ids":["zen-director","zen-video","zen-video-i2v","zen-voyager"],"showPricing":false,"showContext":false}]
53:["$","hr",null,{}]
54:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"audio-creative-coming-soon","children":[["$","a",null,{"data-card":"","href":"#audio-creative-coming-soon","className":"peer","children":"Audio Creative (Coming Soon)"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
55:["$","$L28",null,{"ids":["zen-dub","zen-dub-live","zen-musician","zen-foley","zen-live"],"showPricing":false,"showContext":false}]
56:["$","hr",null,{}]
57:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"3d--spatial-coming-soon","children":[["$","a",null,{"data-card":"","href":"#3d--spatial-coming-soon","className":"peer","children":"3D & Spatial (Coming Soon)"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
58:["$","$L28",null,{"ids":["zen-3d","zen-world"],"showPricing":false,"showContext":false}]
59:["$","hr",null,{}]
5a:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"api-usage","children":[["$","a",null,{"data-card":"","href":"#api-usage","className":"peer","children":"API Usage"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
63:T5c0,<svg viewBox="0 0 24 24"><path d="M14.25.18l.9.2.73.26.59.3.45.32.34.34.25.34.16.33.1.3.04.26.02.2-.01.13V8.5l-.05.63-.13.55-.21.46-.26.38-.3.31-.33.25-.35.19-.35.14-.33.1-.3.07-.26.04-.21.02H8.77l-.69.05-.59.14-.5.22-.41.27-.33.32-.27.35-.2.36-.15.37-.1.35-.07.32-.04.27-.02.21v3.06H3.17l-.21-.03-.28-.07-.32-.12-.35-.18-.36-.26-.36-.36-.35-.46-.32-.59-.28-.73-.21-.88-.14-1.05-.05-1.23.06-1.22.16-1.04.24-.87.32-.71.36-.57.4-.44.42-.33.42-.24.4-.16.36-.1.32-.05.24-.01h.16l.06.01h8.16v-.83H6.18l-.01-2.75-.02-.37.05-.34.11-.31.17-.28.25-.26.31-.23.38-.2.44-.18.51-.15.58-.12.64-.1.71-.06.77-.04.84-.02 1.27.05zm-6.3 1.98l-.23.33-.08.41.08.41.23.34.33.22.41.09.41-.09.33-.22.23-.34.08-.41-.08-.41-.23-.33-.33-.22-.41-.09-.41.09zm13.09 3.95l.28.06.32.12.35.18.36.27.36.35.35.47.32.59.28.73.21.88.14 1.04.05 1.23-.06 1.23-.16 1.04-.24.86-.32.71-.36.57-.4.45-.42.33-.42.24-.4.16-.36.09-.32.05-.24.02-.16-.01h-8.22v.82h5.84l.01 2.76.02.36-.05.34-.11.31-.17.29-.25.25-.31.24-.38.2-.44.17-.51.15-.58.13-.64.09-.71.07-.77.04-.84.01-1.27-.04-1.07-.14-.9-.2-.73-.25-.59-.3-.45-.33-.34-.34-.25-.34-.16-.33-.1-.3-.04-.25-.02-.2.01-.13v-5.34l.05-.64.13-.54.21-.46.26-.38.3-.32.33-.24.35-.2.35-.14.33-.1.3-.06.26-.04.21-.02.13-.01h5.84l.69-.05.59-.14.5-.21.41-.28.33-.32.27-.35.2-.36.15-.36.1-.35.07-.32.04-.28.02-.21V6.07h2.09l.14.01zm-6.47 14.25l-.23.33-.08.41.08.41.23.33.33.23.41.08.41-.08.33-.23.23-.33.08-.41-.08-.41-.23-.33-.33-.23-.41-.08-.41.08z" fill="currentColor" /></svg>5b:["$","$L62",null,{"className":"shiki shiki-themes github-light github-dark","style":{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},"tabIndex":"0","icon":"$63","children":["$","$L64",null,{"children":["$","code",null,{"children":[["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"from"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" hanzoai "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"import"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" Hanzo"}]]}],"\n",["$","span",null,{"className":"line"}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"client "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" Hanzo("}],["$","span",null,{"style":{"--shiki-light":"#E36209","--shiki-dark":"#FFAB70"},"children":"api_key"}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"\"hk-your-api-key\""}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":")"}]]}],"\n",["$","span",null,{"className":"line"}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"response "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" client.chat.completions.create("}]]}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#E36209","--shiki-dark":"#FFAB70"},"children":"    model"}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"\"zen4\""}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":","}]]}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#E36209","--shiki-dark":"#FFAB70"},"children":"    messages"}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],"$L65","$L66","$L67","$L68","$L69","$L6a","$L6b","$L6c","$L6d"]}],"\n","$L6e","\n","$L6f"]}]}]}]
70:T4dc,<svg viewBox="0 0 24 24"><path d="M1.125 0C.502 0 0 .502 0 1.125v21.75C0 23.498.502 24 1.125 24h21.75c.623 0 1.125-.502 1.125-1.125V1.125C24 .502 23.498 0 22.875 0zm17.363 9.75c.612 0 1.154.037 1.627.111a6.38 6.38 0 0 1 1.306.34v2.458a3.95 3.95 0 0 0-.643-.361 5.093 5.093 0 0 0-.717-.26 5.453 5.453 0 0 0-1.426-.2c-.3 0-.573.028-.819.086a2.1 2.1 0 0 0-.623.242c-.17.104-.3.229-.393.374a.888.888 0 0 0-.14.49c0 .196.053.373.156.529.104.156.252.304.443.444s.423.276.696.41c.273.135.582.274.926.416.47.197.892.407 1.266.628.374.222.695.473.963.753.268.279.472.598.614.957.142.359.214.776.214 1.253 0 .657-.125 1.21-.373 1.656a3.033 3.033 0 0 1-1.012 1.085 4.38 4.38 0 0 1-1.487.596c-.566.12-1.163.18-1.79.18a9.916 9.916 0 0 1-1.84-.164 5.544 5.544 0 0 1-1.512-.493v-2.63a5.033 5.033 0 0 0 3.237 1.2c.333 0 .624-.03.872-.09.249-.06.456-.144.623-.25.166-.108.29-.234.373-.38a1.023 1.023 0 0 0-.074-1.089 2.12 2.12 0 0 0-.537-.5 5.597 5.597 0 0 0-.807-.444 27.72 27.72 0 0 0-1.007-.436c-.918-.383-1.602-.852-2.053-1.405-.45-.553-.676-1.222-.676-2.005 0-.614.123-1.141.369-1.582.246-.441.58-.804 1.004-1.089a4.494 4.494 0 0 1 1.47-.629 7.536 7.536 0 0 1 1.77-.201zm-15.113.188h9.563v2.166H9.506v9.646H6.789v-9.646H3.375z" fill="currentColor" /></svg>5c:["$","$L62",null,{"className":"shiki shiki-themes github-light github-dark","style":{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},"tabIndex":"0","icon":"$70","children":["$","$L64",null,{"children":["$","code",null,{"children":[["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"import"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" Hanzo "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"from"}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":" '@hanzo/ai'"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":";"}]]}],"\n",["$","span",null,{"className":"line"}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"const"}],["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":" client"}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":" ="}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":" new"}],["$","span",null,{"style":{"--shiki-light":"#6F42C1","--shiki-dark":"#B392F0"},"children":" Hanzo"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"({ apiKey: "}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"'hk-your-api-key'"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" });"}]]}],"\n",["$","span",null,{"className":"line"}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"const"}],["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":" response"}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":" ="}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":" await"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" client.chat.completions."}],["$","span",null,{"style":{"--shiki-light":"#6F42C1","--shiki-dark":"#B392F0"},"children":"create"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"({"}]]}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"  model: "}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"'zen4'"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":","}]]}],"\n",["$","span",null,{"className":"line","children":["$L71","$L72","$L73","$L74","$L75"]}],"\n","$L76","\n","$L77"]}]}]}]
5d:["$","p",null,{"children":["See ",["$","$L10",null,{"href":"/docs/api","children":"API Reference"}]," for full documentation."]}]
5e:["$","hr",null,{}]
5f:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"open-weights-formats","children":[["$","a",null,{"data-card":"","href":"#open-weights-formats","className":"peer","children":"Open Weights Formats"}],["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
60:["$","p",null,{"children":"All locally-runnable models are available in multiple formats:"}]
61:["$","div",null,{"className":"relative overflow-auto prose-no-margin my-6","children":["$","table",null,{"children":[["$","thead",null,{"children":["$","tr",null,{"children":[["$","th",null,{"children":"Format"}],["$","th",null,{"children":"Use Case"}],["$","th",null,{"children":"Platform"}]]}]}],["$","tbody",null,{"children":[["$","tr",null,{"children":[["$","td",null,{"children":["$","strong",null,{"children":"SafeTensors"}]}],["$","td",null,{"children":"Full precision, transformers"}],["$","td",null,{"children":"All"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":["$","strong",null,{"children":"GGUF"}]}],["$","td",null,{"children":"Quantized, llama.cpp / Ollama"}],["$","td",null,{"children":"All"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":["$","strong",null,{"children":"MLX"}]}],["$","td",null,{"children":"Apple Silicon optimized"}],["$","td",null,{"children":"macOS"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":["$","strong",null,{"children":"ONNX"}]}],["$","td",null,{"children":"Cross-platform inference"}],["$","td",null,{"children":"All"}]]}]]}]]}]}]
65:["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"[{"}]
66:["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"\"role\""}]
67:["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":": "}]
68:["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"\"user\""}]
69:["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":", "}]
6a:["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"\"content\""}]
6b:["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":": "}]
6c:["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"\"Hello!\""}]
6d:["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"}],"}]
6e:["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":")"}]}]
6f:["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":"print"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"(response.choices["}],["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":"0"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"].message.content)"}]]}]
71:["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"  messages: [{ role: "}]
72:["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"'user'"}]
73:["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":", content: "}]
74:["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"'Hello!'"}]
75:["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" }],"}]
76:["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"});"}]}]
77:["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"console."}],["$","span",null,{"style":{"--shiki-light":"#6F42C1","--shiki-dark":"#B392F0"},"children":"log"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"(response.choices["}],["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":"0"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"].message.content);"}]]}]
21:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","2",{"name":"theme-color","media":"(prefers-color-scheme: dark)","content":"#0A0A0A"}],["$","meta","3",{"name":"theme-color","media":"(prefers-color-scheme: light)","content":"#fff"}]]
1f:null
23:[["$","title","0",{"children":"Models | Zen LM"}],["$","meta","1",{"name":"description","content":"Complete Zen LM model family â€” 80+ models across text, code, vision, audio, image, video, 3D, embedding, safety, and agent modalities"}],["$","meta","2",{"property":"og:title","content":"Zen LM - Open Foundation Models"}],["$","meta","3",{"property":"og:description","content":"Zen AI model family by Hanzo AI. 14 frontier models from 4B to 1T+ parameters for code, reasoning, vision, and multimodal tasks."}],["$","meta","4",{"property":"og:url","content":"https://zenlm.org"}],["$","meta","5",{"property":"og:site_name","content":"Zen LM"}],["$","meta","6",{"property":"og:type","content":"website"}],["$","meta","7",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","8",{"name":"twitter:site","content":"@zenlmorg"}],["$","meta","9",{"name":"twitter:creator","content":"@zenlmorg"}],["$","meta","10",{"name":"twitter:title","content":"Zen LM - Open Foundation Models"}],["$","meta","11",{"name":"twitter:description","content":"Zen AI model family by Hanzo AI. 14 frontier models from 4B to 1T+ parameters for code, reasoning, vision, and multimodal tasks."}]]
