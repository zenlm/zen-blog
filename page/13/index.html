<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.106.0"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Zen LM</title><meta name=keywords content="Zen LM,Zen MoDE,open weights,large language models,machine learning,AI"><meta name=description content="Open frontier models from Hanzo AI and Zoo Labs Foundation."><meta name=author content="Zen LM Team"><link rel=canonical href=https://zenlm.org/><link crossorigin=anonymous href=/assets/css/stylesheet.6c0865a4bc8dbcbd27d78777eb33b404568f7fbf3185cca7b978e5275a4dd049.css integrity="sha256-bAhlpLyNvL0n14d36zO0BFaPf78xhcynuXjlJ1pN0Ek=" rel="preload stylesheet" as=style><link rel=icon href=https://zenlm.org/favicon.png><link rel=apple-touch-icon href=https://zenlm.org/favicon.png><link rel=manifest href=https://zenlm.org/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate type=application/json href=https://zenlm.org/index.json><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script><meta property="og:title" content="Zen LM"><meta property="og:description" content="Open frontier models from Hanzo AI and Zoo Labs Foundation."><meta property="og:type" content="website"><meta property="og:url" content="https://zenlm.org/"><meta property="og:image" content="https://zenlm.org/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Zen LM"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://zenlm.org/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Zen LM"><meta name=twitter:description content="Open frontier models from Hanzo AI and Zoo Labs Foundation."><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Zen LM","url":"https://zenlm.org/","description":"Zen LM — Frontier open models from Hanzo AI and Zoo Labs Foundation","thumbnailUrl":"https://zenlm.org/favicon.png","sameAs":[]}</script></head><body class=list id=top><script>const hasHeaderBg=!0</script><header class=header><div class="nav-container nav-background"><nav class=nav><div class=logo><a href=/ accesskey=h title="Zen LM (Alt + H)"><img src=https://zenlm.org/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://zeekay.blog title=zeekay><span>zeekay</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://hanzo.blog title=hanzo.blog><span>hanzo.blog</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://hanzo.ai/chat title="Try Zen Chat"><span>Try Zen Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://blog.zoo.ngo title="zoo blog"><span>zoo blog</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container style=min-height:100vh;display:flex;justify-content:center;background-color:#000><img class=hero-background style=opacity:0 onload="this.style.opacity=1" src=https://cdn.jsdelivr.net/gh/hanzoai/zen-blog@main/static/img/background.webp width=100%><div class=hero-gradient></div><div class=hero-blur></div><div class=mouse-hint><div class=mouse-point></div></div><style>body{-ms-overflow-style:none;scrollbar-width:none}body::-webkit-scrollbar{display:none}.mouse-hint{position:absolute;height:36px;width:24px;border:1px solid #fff;border-radius:12px;bottom:20%;left:50% - calc(12px);opacity:1;transition:opacity .3s;animation:1s ease-out 0s 1 slideBelow}.mouse-hint .mouse-point{height:4px;width:4px;background-color:#fff;position:absolute;left:50%;bottom:40%;border-radius:4px;transform-origin:50% 100%;transform:translate(-50%);animation:2.2s ease-in-out infinite jump;will-change:transform}@keyframes slideBelow{0%{transform:translateY(50px);opacity:0}100%{transform:translateX(0);opacity:1}}@keyframes jump{0%,20%,60%,to{transform:translate(-50%)translateY(0);height:4px;animation-timing-function:ease-in}40%,80%{transform:translate(-50%)translateY(8px);height:8px;animation-timing-function:ease-out}}</style><div class="hero text-light text-fade-in"><div class=hero-header><h1>Zen LM</h1></div><div class=hero-content>Open frontier models from Hanzo AI and Zoo Labs Foundation.</div><div class=hero-footer><div class=social-icons></div></div></div></div><main class="main home"><article class=post-entry><header class=entry-header><h2>7680-Dimensional Embeddings: More Dimensions, Better Retrieval</h2></header><div class=entry-content><p>Embedding dimensions have standardized around powers of two: 768, 1536, occasionally 4096. We asked a simple question: what happens if we go bigger? The answer surprised us.
Background: Why Dimensions Matter Text embeddings map variable-length sequences to fixed-dimensional vectors. These vectors enable semantic similarity search, clustering, and retrieval. The dimension count determines the vector space’s capacity.
Lower dimensions mean:
Smaller storage requirements Faster similarity computations Potential information loss Higher dimensions mean:...</p></div><footer class=entry-footer><span title='2022-12-05 10:00:00 -0800 -0800'>December 5, 2022</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;507 words&nbsp;·&nbsp;Zach Kelling</footer><a class=entry-link aria-label="post link to 7680-Dimensional Embeddings: More Dimensions, Better Retrieval" href=https://zenlm.org/blog/7680-dim-embeddings/></a></article><article class=post-entry><header class=entry-header><h2>Embedding Spaces at 7680 Dimensions</h2></header><div class=entry-content><p>The Dimension Question How many dimensions does a text embedding need?
The field has settled on conventions: 768 for BERT-scale models, 1536 for OpenAI’s ada-002, 4096 for some recent models. But these choices reflect architectural constraints, not fundamental requirements.
We investigate what happens when we scale embedding dimensions to 7680—ten times the BERT baseline.
Why Higher Dimensions? Capacity Arguments A $d$-dimensional embedding space can represent $\mathcal{O}(e^d)$ nearly-orthogonal vectors. For semantic search, we want documents with different meanings to map to different regions....</p></div><footer class=entry-footer><span title='2022-12-05 00:00:00 +0000 UTC'>December 5, 2022</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;647 words&nbsp;·&nbsp;Zach Kelling</footer><a class=entry-link aria-label="post link to Embedding Spaces at 7680 Dimensions" href=https://zenlm.org/blog/embedding-spaces-7680-dimensions/></a></article><article class=post-entry><header class=entry-header><h2>GRPO: Group Relative Policy Optimization</h2></header><div class=entry-content><p>Reinforcement learning from human feedback (RLHF) has become central to aligning language models with human preferences. But current methods like PPO are sample-inefficient and unstable. Today we introduce Group Relative Policy Optimization (GRPO), a new approach that addresses these limitations.
The RLHF Challenge Standard RLHF follows three steps:
Train a reward model on human preference data Use the reward model to provide training signal Optimize the policy with reinforcement learning (typically PPO) Step 3 is problematic....</p></div><footer class=entry-footer><span title='2022-09-19 09:00:00 -0800 -0800'>September 19, 2022</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;522 words&nbsp;·&nbsp;Zach Kelling</footer><a class=entry-link aria-label="post link to GRPO: Group Relative Policy Optimization" href=https://zenlm.org/blog/grpo/></a></article><article class=post-entry><header class=entry-header><h2>GRPO: Group Relative Policy Optimization</h2></header><div class=entry-content><p>Beyond PPO Proximal Policy Optimization (PPO) has become the de facto algorithm for reinforcement learning from human feedback. Yet PPO has fundamental limitations when applied to language models:
Absolute reward dependence: PPO optimizes absolute reward values, which are noisy and poorly calibrated KL divergence sensitivity: The KL penalty requires careful tuning to avoid collapse or divergence Sample inefficiency: Each prompt generates one response for learning Reward hacking: Models exploit reward model weaknesses Group Relative Policy Optimization (GRPO) addresses these issues through a simple insight: relative comparisons are more informative than absolute scores....</p></div><footer class=entry-footer><span title='2022-09-18 00:00:00 +0000 UTC'>September 18, 2022</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;674 words&nbsp;·&nbsp;Zach Kelling</footer><a class=entry-link aria-label="post link to GRPO: Group Relative Policy Optimization" href=https://zenlm.org/blog/grpo-group-relative-policy-optimization/></a></article><article class=post-entry><header class=entry-header><h2>Federated Learning Without Compromise</h2></header><div class=entry-content><p>The Privacy-Utility Tradeoff Federated learning promises to train models on distributed data without centralizing sensitive information. In practice, existing approaches force uncomfortable tradeoffs:
Differential privacy adds noise that degrades model quality Secure aggregation increases communication costs Data heterogeneity causes convergence problems Byzantine participants can poison the model We present techniques that mitigate these tradeoffs.
Our Approach Adaptive Clipping Standard gradient clipping uses a fixed threshold $C$:
$$g_i^{clipped} = g_i \cdot \min\left(1, \frac{C}{|g_i|}\right)$$...</p></div><footer class=entry-footer><span title='2022-05-30 00:00:00 +0000 UTC'>May 30, 2022</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;438 words&nbsp;·&nbsp;Zach Kelling</footer><a class=entry-link aria-label="post link to Federated Learning Without Compromise" href=https://zenlm.org/blog/federated-learning-without-compromise/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://zenlm.org/page/12/>«&nbsp;Prev&nbsp;</a>
<a class=next href=https://zenlm.org/page/14/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2026 <a href=https://zenlm.org/>Zen LM</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script></body></html>