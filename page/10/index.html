<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.106.0"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Zen LM</title><meta name=keywords content="Zen LM,Zen MoDE,open weights,large language models,machine learning,AI"><meta name=description content="Open frontier models from Hanzo AI and Zoo Labs Foundation."><meta name=author content="Zen LM Team"><link rel=canonical href=https://zenlm.org/><link crossorigin=anonymous href=/assets/css/stylesheet.6c0865a4bc8dbcbd27d78777eb33b404568f7fbf3185cca7b978e5275a4dd049.css integrity="sha256-bAhlpLyNvL0n14d36zO0BFaPf78xhcynuXjlJ1pN0Ek=" rel="preload stylesheet" as=style><link rel=icon href=https://zenlm.org/favicon.png><link rel=apple-touch-icon href=https://zenlm.org/favicon.png><link rel=manifest href=https://zenlm.org/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate type=application/json href=https://zenlm.org/index.json><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script><meta property="og:title" content="Zen LM"><meta property="og:description" content="Open frontier models from Hanzo AI and Zoo Labs Foundation."><meta property="og:type" content="website"><meta property="og:url" content="https://zenlm.org/"><meta property="og:image" content="https://zenlm.org/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Zen LM"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://zenlm.org/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Zen LM"><meta name=twitter:description content="Open frontier models from Hanzo AI and Zoo Labs Foundation."><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Zen LM","url":"https://zenlm.org/","description":"Zen LM — Frontier open models from Hanzo AI and Zoo Labs Foundation","thumbnailUrl":"https://zenlm.org/favicon.png","sameAs":[]}</script></head><body class=list id=top><script>const hasHeaderBg=!0</script><header class=header><div class="nav-container nav-background"><nav class=nav><div class=logo><a href=/ accesskey=h title="Zen LM (Alt + H)"><img src=https://zenlm.org/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://zeekay.blog title=zeekay><span>zeekay</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://hanzo.blog title=hanzo.blog><span>hanzo.blog</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://hanzo.ai/chat title="Try Zen Chat"><span>Try Zen Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://blog.zoo.ngo title="zoo blog"><span>zoo blog</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container style=min-height:100vh;display:flex;justify-content:center;background-color:#000><img class=hero-background style=opacity:0 onload="this.style.opacity=1" src=https://cdn.jsdelivr.net/gh/hanzoai/zen-blog@main/static/img/background.webp width=100%><div class=hero-gradient></div><div class=hero-blur></div><div class=mouse-hint><div class=mouse-point></div></div><style>body{-ms-overflow-style:none;scrollbar-width:none}body::-webkit-scrollbar{display:none}.mouse-hint{position:absolute;height:36px;width:24px;border:1px solid #fff;border-radius:12px;bottom:20%;left:50% - calc(12px);opacity:1;transition:opacity .3s;animation:1s ease-out 0s 1 slideBelow}.mouse-hint .mouse-point{height:4px;width:4px;background-color:#fff;position:absolute;left:50%;bottom:40%;border-radius:4px;transform-origin:50% 100%;transform:translate(-50%);animation:2.2s ease-in-out infinite jump;will-change:transform}@keyframes slideBelow{0%{transform:translateY(50px);opacity:0}100%{transform:translateX(0);opacity:1}}@keyframes jump{0%,20%,60%,to{transform:translate(-50%)translateY(0);height:4px;animation-timing-function:ease-in}40%,80%{transform:translate(-50%)translateY(8px);height:8px;animation-timing-function:ease-out}}</style><div class="hero text-light text-fade-in"><div class=hero-header><h1>Zen LM</h1></div><div class=hero-content>Open frontier models from Hanzo AI and Zoo Labs Foundation.</div><div class=hero-footer><div class=social-icons></div></div></div></div><main class="main home"><article class=post-entry><header class=entry-header><h2>Introducing Qwen1.5</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
Introduction In recent months, our focus has been on developing a “good” model while optimizing the developer experience. As we progress towards Qwen1.5, the next iteration in our Qwen series, this update arrives just before the Chinese New Year.
With Qwen1.5, we are open-sourcing base and chat models across six sizes: 0.5B, 1.8B, 4B, 7B, 14B, 32B, 72B, and 110B, and also an MoE model (see blog for more information)....</p></div><footer class=entry-footer><span title='2024-02-04 13:33:00 +0800 +0800'>February 4, 2024</span>&nbsp;·&nbsp;14 min&nbsp;·&nbsp;2895 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to Introducing Qwen1.5" href=https://zenlm.org/blog/qwen1.5/></a></article><article class=post-entry><header class=entry-header><h2>Introducing Qwen-VL</h2></header><div class=entry-content><p>Along with the rapid development of our large language model Qwen, we leveraged Qwen’s capabilities and unified multimodal pretraining to address the limitations of multimodal models in generalization, and we opensourced multimodal model Qwen-VL in Sep. 2023. Recently, the Qwen-VL series has undergone a significant upgrade with the launch of two enhanced versions, Qwen-VL-Plus and Qwen-VL-Max. The key technical advancements in these versions include:
Substantially boost in image-related reasoning capabilities; Considerable enhancement in recognizing, extracting, and analyzing details within images and texts contained therein; Support for high-definition images with resolutions above one million pixels and images of various aspect ratios....</p></div><footer class=entry-footer><span title='2024-01-25 13:33:00 +0800 +0800'>January 25, 2024</span>&nbsp;·&nbsp;12 min&nbsp;·&nbsp;2505 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to Introducing Qwen-VL" href=https://zenlm.org/blog/qwen-vl/></a></article><article class=post-entry><header class=entry-header><h2>Introducing Qwen</h2></header><div class=entry-content><p>4 months after our first release of Qwen-7B, which is the starting point of our opensource journey of large language models (LLM), we now provide an introduction to the Qwen series to give you a whole picture of our work as well as our objectives. Below are important links to our opensource projects and community.
PAPER GITHUB HUGGING FACE MODELSCOPE DISCORD
Additionally, we have WeChat groups for chatting and we invite you to join the groups through the provided link in our GitHub readme....</p></div><footer class=entry-footer><span title='2024-01-23 22:13:29 +0800 +0800'>January 23, 2024</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1115 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to Introducing Qwen" href=https://zenlm.org/blog/qwen/></a></article><article class=post-entry><header class=entry-header><h2>OFA: Towards Building a One-For-All Model</h2></header><div class=entry-content><p>2022 is a year of generalist models! With the bloom of multimodal pretraining, especially the unified model, we have witnessed the opportunity to building a generalist model that is capable of processing tasks of different modalities or multi-modalities! Thus, we propose OFA1, namely One-For-All, a unified multimodal pretrained model that unifies understanding and generation tasks concerning modalities into a single framework, and we pretrain OFA with the instruction-based multitask-pretraining that endows it with multiple capabilities....</p></div><footer class=entry-footer><span title='2022-11-14 16:01:41 +0800 +0800'>November 14, 2022</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;1876 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to OFA: Towards Building a One-For-All Model" href=https://zenlm.org/blog/ofa/></a></article><article class=post-entry><header class=entry-header><h2>Zen 3.0: The Next Generation of Open AI</h2></header><div class=entry-content><p>Today we release Zen 3.0, our third-generation language model family. Zen 3 represents a step change in what open models can do.
Model Family Zen 3 comes in several sizes:
Model Parameters Context Training Tokens Zen-3-8B 8.1B 128K 15T Zen-3-32B 32.5B 128K 12T Zen-3-72B 72.3B 128K 10T Zen-3-MoE 141B (24B active) 128K 14T All models use the same architecture with scaled dimensions. All are released under Apache 2.0.
Architecture Highlights Extended Context All Zen 3 models support 128K token context natively:...</p></div><footer class=entry-footer><span title='2025-01-13 09:00:00 -0800 -0800'>January 13, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;787 words&nbsp;·&nbsp;Zach Kelling</footer><a class=entry-link aria-label="post link to Zen 3.0: The Next Generation of Open AI" href=https://zenlm.org/blog/zen-3/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://zenlm.org/page/9/>«&nbsp;Prev&nbsp;</a>
<a class=next href=https://zenlm.org/page/11/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2026 <a href=https://zenlm.org/>Zen LM</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script></body></html>