(globalThis.TURBOPACK||(globalThis.TURBOPACK=[])).push(["object"==typeof document?document.currentScript:void 0,804,45382,40670,e=>{"use strict";let a=[{id:"zen4",name:"Zen4",fullName:"Zen4 — Flagship",description:"Flagship MoE model for complex reasoning and multi-domain tasks.",generation:"zen4",tier:"ultra max",category:"flagship",modalities:["text","code","math"],spec:{params:"744B",activeParams:"40B",context:202e3,arch:"MoE"},pricing:{input:3,output:9.6,cacheRead:null,cacheWrite:null},features:["202K context window","Flagship intelligence","100+ languages"],status:"available",huggingface:"https://huggingface.co/zenlm/zen4",github:"https://github.com/zenlm/zen4",aliases:[]},{id:"zen4-pro",name:"Zen4 Pro",fullName:"Zen4 Pro — High Capability",description:"Efficient MoE model for demanding workloads with strong reasoning at production-grade cost.",generation:"zen4",tier:"ultra",category:"flagship",modalities:["text","code","math"],spec:{params:"80B",activeParams:"3B",context:131e3,arch:"MoE"},pricing:{input:2.7,output:2.7,cacheRead:null,cacheWrite:null},features:["131K context window","MoE architecture"],status:"available",huggingface:"https://huggingface.co/zenlm/zen4-pro",github:"https://github.com/zenlm/zen4-pro",aliases:[]},{id:"zen4-max",name:"Zen4 Max",fullName:"Zen4 Max — Maximum Intelligence",description:"Most capable model for complex reasoning, analysis, and agentic tasks. 1M token context window.",generation:"zen4",tier:"ultra max",category:"flagship",modalities:["text","code","math"],spec:{params:"N/A",activeParams:null,context:1e6,arch:"Dense"},pricing:{input:3.6,output:3.6,cacheRead:null,cacheWrite:null},features:["1M context window","Maximum intelligence","Agentic coding"],status:"available",huggingface:null,github:null,aliases:["zen-max"]},{id:"zen4.1",name:"Zen4.1",fullName:"Zen4.1 — Extended Context",description:"High-performance 1M context model for long-document analysis, large codebase reasoning, and agentic workflows. Best balance of intelligence and cost at million-token scale.",generation:"zen4",tier:"ultra",category:"flagship",modalities:["text","code","math"],spec:{params:"N/A",activeParams:null,context:1e6,arch:"Dense"},pricing:{input:3.6,output:3.6,cacheRead:null,cacheWrite:null},features:["1M context window","Agentic coding","Long-document analysis","Cost efficient"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen4-mini",name:"Zen4 Mini",fullName:"Zen4 Mini — Fast & Efficient",description:"Ultra-fast lightweight model optimized for speed and cost efficiency. Ideal for free tier.",generation:"zen4",tier:"pro",category:"flagship",modalities:["text","code"],spec:{params:"N/A",activeParams:null,context:128e3,arch:"Dense"},pricing:{input:.6,output:.6,cacheRead:null,cacheWrite:null},features:["128K context window","Ultra-fast inference","Free tier"],status:"available",huggingface:"https://huggingface.co/zenlm/zen4-mini",github:"https://github.com/zenlm/zen4-mini",aliases:[]},{id:"zen4-ultra",name:"Zen4 Ultra",fullName:"Zen4 Ultra — Maximum Reasoning",description:"Maximum reasoning capability with extended chain-of-thought on MoE architecture.",generation:"zen4",tier:"ultra max",category:"flagship",modalities:["text","code","math"],spec:{params:"744B",activeParams:"40B",context:262e3,arch:"MoE + CoT"},pricing:{input:3,output:9.6,cacheRead:null,cacheWrite:null},features:["262K context window","Deep reasoning","Chain-of-thought"],status:"available",huggingface:"https://huggingface.co/zenlm/zen4-ultra",github:"https://github.com/zenlm/zen4-ultra",aliases:[]},{id:"zen4-thinking",name:"Zen4 Thinking",fullName:"Zen4 Thinking — Deep Reasoning",description:"Dedicated reasoning model with explicit chain-of-thought capabilities.",generation:"zen4",tier:"pro max",category:"flagship",modalities:["text","code","math"],spec:{params:"80B",activeParams:"3B",context:131e3,arch:"MoE + CoT"},pricing:{input:2.7,output:2.7,cacheRead:null,cacheWrite:null},features:["131K context window","Chain-of-thought"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen4-coder",name:"Zen4 Coder",fullName:"Zen4 Coder — Code Generation",description:"Code-specialized MoE model for generation, review, debugging, and agentic programming.",generation:"zen4",tier:"ultra",category:"code",modalities:["text","code"],spec:{params:"480B",activeParams:"35B",context:163e3,arch:"MoE"},pricing:{input:3.6,output:3.6,cacheRead:null,cacheWrite:null},features:["163K context window","All major languages"],status:"available",huggingface:"https://huggingface.co/zenlm/zen4-coder",github:"https://github.com/zenlm/zen4-coder",aliases:[]},{id:"zen4-coder-flash",name:"Zen4 Coder Flash",fullName:"Zen4 Coder Flash — Fast Code",description:"Lightweight code model optimized for speed and inline completions.",generation:"zen4",tier:"pro max",category:"code",modalities:["text","code"],spec:{params:"30B",activeParams:"3B",context:262e3,arch:"MoE"},pricing:{input:1.5,output:1.5,cacheRead:null,cacheWrite:null},features:["262K context window","Fast inference"],status:"available",huggingface:"https://huggingface.co/zenlm/zen4-coder-flash",github:"https://github.com/zenlm/zen4-coder-flash",aliases:[]},{id:"zen4-coder-pro",name:"Zen4 Coder Pro",fullName:"Zen4 Coder Pro — Premium Code",description:"Full-precision BF16 code model for maximum accuracy on complex codebases.",generation:"zen4",tier:"ultra max",category:"code",modalities:["text","code"],spec:{params:"480B",activeParams:null,context:131e3,arch:"Dense BF16"},pricing:{input:4.5,output:4.5,cacheRead:null,cacheWrite:null},features:["131K context window","BF16 full precision"],status:"available",huggingface:"https://huggingface.co/zenlm/zen4-coder-pro",github:"https://github.com/zenlm/zen4-coder-pro",aliases:[]},{id:"zen3-omni",name:"Zen3 Omni",fullName:"Zen3 Omni — Hypermodal",description:"Multimodal model supporting text, vision, audio, and structured output.",generation:"zen3",tier:"pro max",category:"vision",modalities:["text","vision","code"],spec:{params:"~200B",activeParams:null,context:202e3,arch:"Dense Multimodal"},pricing:{input:1.8,output:6.6,cacheRead:null,cacheWrite:null},features:["202K context window","Text + Vision + Audio"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-vl",name:"Zen3 VL",fullName:"Zen3 VL — Vision-Language",description:"Vision-language model for image understanding and visual reasoning.",generation:"zen3",tier:"pro max",category:"vision",modalities:["text","vision"],spec:{params:"30B",activeParams:"3B",context:262e3,arch:"MoE Vision-Language"},pricing:{input:.45,output:1.8,cacheRead:null,cacheWrite:null},features:["262K context window","Vision + Language"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-nano",name:"Zen3 Nano",fullName:"Zen3 Nano — Edge",description:"Ultra-lightweight model for edge deployment and low-latency tasks. Available on free tier.",generation:"zen3",tier:"pro",category:"flagship",modalities:["text","code"],spec:{params:"8B",activeParams:null,context:128e3,arch:"Dense"},pricing:{input:.3,output:.3,cacheRead:null,cacheWrite:null},features:["128K context window","8B parameters","Free tier"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-guard",name:"Zen3 Guard",fullName:"Zen3 Guard — Content Safety",description:"Content safety classifier for moderation and guardrails. 9 safety categories, 119 languages.",generation:"zen3",tier:"pro",category:"safety",modalities:["text","safety"],spec:{params:"4B",activeParams:null,context:65e3,arch:"Dense"},pricing:{input:.3,output:.3,cacheRead:null,cacheWrite:null},features:["65K context window","Safety classifier","119 languages"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-embedding",name:"Zen3 Embedding",fullName:"Zen3 Embedding — Text Embeddings",description:"High-quality text embeddings for RAG, search, and classification.",generation:"zen3",tier:"pro max",category:"embedding",modalities:["text","embedding"],spec:{params:"3072 dimensions",activeParams:null,context:8e3,arch:"Embedding"},pricing:{input:.39,output:.39,cacheRead:null,cacheWrite:null},features:["8K context window","3072 dimensions"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-embedding-medium",name:"Zen3 Embedding Medium",fullName:"Zen3 Embedding Medium",description:"Balanced embedding model for cost-effective retrieval workloads.",generation:"zen3",tier:"pro",category:"embedding",modalities:["text","embedding"],spec:{params:"4B",activeParams:null,context:4e4,arch:"Embedding"},pricing:null,features:["40K context window","4B parameters"],status:"available",huggingface:"https://huggingface.co/zenlm/zen3-embedding-medium",github:null,aliases:[]},{id:"zen3-embedding-small",name:"Zen3 Embedding Small",fullName:"Zen3 Embedding Small",description:"Lightweight embedding model for high-throughput, low-cost applications.",generation:"zen3",tier:"pro",category:"embedding",modalities:["text","embedding"],spec:{params:"0.6B",activeParams:null,context:32e3,arch:"Embedding"},pricing:null,features:["32K context window","0.6B parameters"],status:"available",huggingface:"https://huggingface.co/zenlm/zen3-embedding-small",github:null,aliases:[]},{id:"zen3-reranker",name:"Zen3 Reranker",fullName:"Zen3 Reranker",description:"High-quality reranker for improving retrieval accuracy in RAG pipelines.",generation:"zen3",tier:"pro max",category:"embedding",modalities:["text","embedding"],spec:{params:"8B",activeParams:null,context:4e4,arch:"Reranker"},pricing:null,features:["40K context window","8B parameters"],status:"available",huggingface:"https://huggingface.co/zenlm/zen3-reranker",github:null,aliases:[]},{id:"zen3-reranker-medium",name:"Zen3 Reranker Medium",fullName:"Zen3 Reranker Medium",description:"Balanced reranker for cost-effective retrieval quality improvement.",generation:"zen3",tier:"pro",category:"embedding",modalities:["text","embedding"],spec:{params:"4B",activeParams:null,context:4e4,arch:"Reranker"},pricing:null,features:["40K context window","4B parameters"],status:"available",huggingface:"https://huggingface.co/zenlm/zen3-reranker-medium",github:null,aliases:[]},{id:"zen3-reranker-small",name:"Zen3 Reranker Small",fullName:"Zen3 Reranker Small",description:"Lightweight reranker for high-throughput reranking at minimal cost.",generation:"zen3",tier:"pro",category:"embedding",modalities:["text","embedding"],spec:{params:"0.6B",activeParams:null,context:4e4,arch:"Reranker"},pricing:null,features:["40K context window","0.6B parameters"],status:"available",huggingface:"https://huggingface.co/zenlm/zen3-reranker-small",github:null,aliases:[]},{id:"zen3-image",name:"Zen3 Image",fullName:"Zen3 Image",description:"Best general-purpose image generation.",generation:"zen3",tier:"pro max",category:"vision",modalities:["vision"],spec:{params:"N/A",activeParams:null,context:0,arch:"Diffusion"},pricing:null,features:["Text-to-image","Image editing"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-image-max",name:"Zen3 Image Max",fullName:"Zen3 Image Max",description:"Maximum quality image generation for professional creative work.",generation:"zen3",tier:"ultra max",category:"vision",modalities:["vision"],spec:{params:"N/A",activeParams:null,context:0,arch:"Diffusion"},pricing:null,features:["Text-to-image","Maximum quality"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-image-dev",name:"Zen3 Image Dev",fullName:"Zen3 Image Dev",description:"Development model for experimentation and iteration.",generation:"zen3",tier:"pro",category:"vision",modalities:["vision"],spec:{params:"N/A",activeParams:null,context:0,arch:"Diffusion"},pricing:null,features:["Text-to-image","Development"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-image-fast",name:"Zen3 Image Fast",fullName:"Zen3 Image Fast",description:"Fastest image model for real-time generation.",generation:"zen3",tier:"pro",category:"vision",modalities:["vision"],spec:{params:"N/A",activeParams:null,context:0,arch:"Diffusion"},pricing:null,features:["Text-to-image","Ultra-fast"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-image-sdxl",name:"Zen3 Image SDXL",fullName:"Zen3 Image SDXL",description:"High-resolution image generation at 1024px.",generation:"zen3",tier:"pro",category:"vision",modalities:["vision"],spec:{params:"N/A",activeParams:null,context:0,arch:"Diffusion"},pricing:null,features:["Text-to-image","1024px"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-image-playground",name:"Zen3 Image Playground",fullName:"Zen3 Image Playground",description:"Aesthetic model for artistic image generation.",generation:"zen3",tier:"pro",category:"vision",modalities:["vision"],spec:{params:"N/A",activeParams:null,context:0,arch:"Diffusion"},pricing:null,features:["Text-to-image","Aesthetic"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-image-ssd",name:"Zen3 Image SSD",fullName:"Zen3 Image SSD",description:"Fastest diffusion model for real-time generation.",generation:"zen3",tier:"pro",category:"vision",modalities:["vision"],spec:{params:"1B",activeParams:null,context:0,arch:"Diffusion"},pricing:null,features:["Text-to-image","Fastest"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-image-jp",name:"Zen3 Image JP",fullName:"Zen3 Image JP",description:"Japanese-specialized image generation model.",generation:"zen3",tier:"pro",category:"vision",modalities:["vision"],spec:{params:"N/A",activeParams:null,context:0,arch:"Diffusion"},pricing:null,features:["Text-to-image","Japanese"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-audio",name:"Zen3 Audio",fullName:"Zen3 Audio",description:"Best quality speech-to-text transcription. 100+ languages.",generation:"zen3",tier:"pro max",category:"audio",modalities:["audio","text"],spec:{params:"1.5B",activeParams:null,context:0,arch:"ASR"},pricing:null,features:["Multi-language","Best accuracy","100+ languages"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-audio-fast",name:"Zen3 Audio Fast",fullName:"Zen3 Audio Fast",description:"Fastest speech-to-text transcription for high-throughput workloads.",generation:"zen3",tier:"pro",category:"audio",modalities:["audio","text"],spec:{params:"809M",activeParams:null,context:0,arch:"ASR"},pricing:null,features:["Multi-language","Fastest","Batch optimized"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-asr",name:"Zen3 ASR",fullName:"Zen3 ASR",description:"Real-time streaming speech recognition for live transcription and voice agents.",generation:"zen3",tier:"pro max",category:"audio",modalities:["audio","text"],spec:{params:"N/A",activeParams:null,context:0,arch:"Streaming ASR"},pricing:null,features:["Streaming","Real-time","Sub-500ms latency"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-asr-v1",name:"Zen3 ASR v1",fullName:"Zen3 ASR v1",description:"First-generation streaming ASR for legacy compatibility.",generation:"zen3",tier:"pro",category:"audio",modalities:["audio","text"],spec:{params:"N/A",activeParams:null,context:0,arch:"Streaming ASR"},pricing:null,features:["Streaming","Legacy"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-tts",name:"Zen3 TTS",fullName:"Zen3 TTS",description:"High-quality text-to-speech with natural prosody. 40+ voices, 8 languages.",generation:"zen3",tier:"pro max",category:"audio",modalities:["audio","text"],spec:{params:"82M",activeParams:null,context:0,arch:"TTS"},pricing:null,features:["40+ voices","8 languages","Natural prosody"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-tts-hd",name:"Zen3 TTS HD",fullName:"Zen3 TTS HD",description:"Maximum fidelity text-to-speech for broadcast-quality audio production.",generation:"zen3",tier:"ultra max",category:"audio",modalities:["audio","text"],spec:{params:"N/A",activeParams:null,context:0,arch:"TTS HD"},pricing:null,features:["HD quality","Broadcast-grade","48kHz output"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-tts-fast",name:"Zen3 TTS Fast",fullName:"Zen3 TTS Fast",description:"Low-latency text-to-speech for real-time voice agents and interactive applications.",generation:"zen3",tier:"pro",category:"audio",modalities:["audio","text"],spec:{params:"82M",activeParams:null,context:0,arch:"TTS"},pricing:null,features:["Low latency","Real-time","Voice agents"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen5",name:"Zen5",fullName:"Zen5 — Next Generation",description:"Next-generation agentic frontier model trained on 10B+ tokens of real-world tool use, multi-step reasoning, and production workflows. 1M+ token context with native chain-of-thought.",generation:"zen5",tier:"ultra max",category:"flagship",modalities:["text","code","math"],spec:{params:"TBA",activeParams:null,context:1048576,arch:"MoDE + CoT"},pricing:null,features:["1M+ context window","Agentic-trained","Native CoT","Tool use","Multimodal native"],status:"contact-sales",huggingface:null,github:null,aliases:[]},{id:"zen5-pro",name:"Zen5 Pro",fullName:"Zen5 Pro — Advanced",description:"High-throughput agentic model for demanding production workloads. Trained on real-world development patterns with deep chain-of-thought reasoning.",generation:"zen5",tier:"ultra",category:"flagship",modalities:["text","code","math"],spec:{params:"TBA",activeParams:null,context:524288,arch:"MoDE + CoT"},pricing:null,features:["512K context window","Agentic-trained","Native CoT","Production optimized"],status:"contact-sales",huggingface:null,github:null,aliases:[]},{id:"zen5-max",name:"Zen5 Max",fullName:"Zen5 Max — Extended",description:"Maximum context agentic model for document-scale analysis. Trained on 10B+ tokens of real-world workflows with extended chain-of-thought.",generation:"zen5",tier:"ultra max",category:"flagship",modalities:["text","code","math"],spec:{params:"TBA",activeParams:null,context:2097152,arch:"MoDE + CoT"},pricing:null,features:["2M context window","Agentic-trained","Extended CoT","Document-scale"],status:"contact-sales",huggingface:null,github:null,aliases:[]},{id:"zen5-ultra",name:"Zen5 Ultra",fullName:"Zen5 Ultra — Deep Reasoning",description:"Deepest reasoning model in the Zen family. Multi-pass chain-of-thought with self-verification.",generation:"zen5",tier:"ultra max",category:"flagship",modalities:["text","code","math"],spec:{params:"TBA",activeParams:null,context:1048576,arch:"MoDE + Deep CoT"},pricing:null,features:["1M context window","Agentic-trained","Deep CoT","Self-verification"],status:"contact-sales",huggingface:null,github:null,aliases:[]},{id:"zen5-mini",name:"Zen5 Mini",fullName:"Zen5 Mini — Efficient",description:"Efficient agentic model delivering zen5-class intelligence at a fraction of the cost.",generation:"zen5",tier:"pro",category:"flagship",modalities:["text","code","math"],spec:{params:"TBA",activeParams:null,context:262144,arch:"MoDE + CoT"},pricing:null,features:["256K context window","Agentic-trained","Native CoT","Cost efficient"],status:"contact-sales",huggingface:null,github:null,aliases:[]},{id:"zen-nano",name:"Zen Nano",fullName:"Zen Nano — 0.6B Edge",description:"Ultra-lightweight LLM for edge and mobile deployment.",generation:"foundation",tier:"pro",category:"foundation",modalities:["text","code","math"],spec:{params:"0.6B",activeParams:null,context:32e3,arch:"Dense"},pricing:null,features:["32K context","44K tokens/sec","0.4–1.2GB memory"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-nano-0.6b",github:null,aliases:[]},{id:"zen-eco",name:"Zen Eco",fullName:"Zen Eco — 4B Efficient",description:"Efficient 4B model for general-purpose tasks.",generation:"foundation",tier:"pro",category:"foundation",modalities:["text","code","math"],spec:{params:"4B",activeParams:null,context:32e3,arch:"Dense"},pricing:null,features:["32K context","33K tokens/sec","2–8GB memory"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-eco-4b",github:null,aliases:[]},{id:"zen",name:"Zen",fullName:"Zen — 8-32B Standard",description:"Standard model available in 8B and 32B variants.",generation:"foundation",tier:"pro",category:"foundation",modalities:["text","code","math"],spec:{params:"8–32B",activeParams:null,context:32e3,arch:"Dense"},pricing:null,features:["32K context","28K tokens/sec","4–64GB memory"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-8b",github:null,aliases:[]},{id:"zen-pro",name:"Zen Pro",fullName:"Zen Pro — 32B Professional",description:"Professional-grade 32B dense model for demanding workloads.",generation:"foundation",tier:"pro max",category:"foundation",modalities:["text","code","math"],spec:{params:"32B",activeParams:null,context:32e3,arch:"Dense"},pricing:null,features:["32K context","19K tokens/sec","16–64GB memory"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-pro-32b",github:null,aliases:[]},{id:"zen-max",name:"Zen Max",fullName:"Zen Max — 235B MoE",description:"High-capability MoE model with 235B parameters.",generation:"foundation",tier:"ultra",category:"foundation",modalities:["text","code","math"],spec:{params:"235B",activeParams:"22B",context:131e3,arch:"MoE"},pricing:null,features:["131K context","14K tokens/sec","48–128GB memory"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-max",github:"https://github.com/zenlm/zen-max",aliases:[]},{id:"zen-next",name:"Zen Next",fullName:"Zen Next — Preview",description:"Next-generation preview model with cutting-edge capabilities.",generation:"foundation",tier:"ultra max",category:"foundation",modalities:["text","code","math"],spec:{params:"TBD",activeParams:null,context:256e3,arch:"Dense"},pricing:null,features:["256K context","Preview"],status:"preview",huggingface:null,github:null,aliases:[]},{id:"zen-coder",name:"Zen Coder",fullName:"Zen Coder — Code Generation",description:"Baseline code model for generation and completions.",generation:"foundation",tier:"pro max",category:"code",modalities:["text","code"],spec:{params:"32B",activeParams:null,context:131e3,arch:"Dense"},pricing:null,features:["131K context","Multi-language"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-coder",github:null,aliases:[]},{id:"zen-coder-flash",name:"Zen Coder Flash",fullName:"Zen Coder Flash — Fast Code",description:"Fast code model for inline completions and suggestions.",generation:"foundation",tier:"pro",category:"code",modalities:["text","code"],spec:{params:"7B",activeParams:null,context:32e3,arch:"Dense"},pricing:null,features:["32K context","Low latency"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-coder-flash",github:null,aliases:[]},{id:"zen-code",name:"Zen Code",fullName:"Zen Code — Legacy Code",description:"Legacy code model (superseded by Zen4 Coder series).",generation:"foundation",tier:"pro",category:"code",modalities:["text","code"],spec:{params:"14B",activeParams:null,context:32e3,arch:"Dense"},pricing:null,features:["32K context"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-code",github:null,aliases:[]},{id:"zen-vl",name:"Zen VL",fullName:"Zen VL — Vision-Language",description:"Multi-modal vision-language model for image understanding.",generation:"foundation",tier:"pro max",category:"vision",modalities:["text","vision"],spec:{params:"32B",activeParams:null,context:32e3,arch:"Dense Multimodal"},pricing:null,features:["32K context","Image understanding"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-vl",github:null,aliases:[]},{id:"zen-omni",name:"Zen Omni",fullName:"Zen Omni — Multimodal",description:"Hypermodal model combining text, vision, audio, and code.",generation:"foundation",tier:"ultra",category:"vision",modalities:["text","vision","audio","code"],spec:{params:"72B",activeParams:null,context:131e3,arch:"Dense Multimodal"},pricing:null,features:["131K context","Multimodal"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-omni",github:null,aliases:[]},{id:"zen-guard",name:"Zen Guard",fullName:"Zen Guard — Content Safety",description:"Content safety and moderation classifier.",generation:"foundation",tier:"pro",category:"safety",modalities:["text","safety"],spec:{params:"8B",activeParams:null,context:32e3,arch:"Dense"},pricing:null,features:["Content moderation","Guardrails"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-guard",github:null,aliases:[]},{id:"zen-embedding",name:"Zen Embedding",fullName:"Zen Embedding — Text Embeddings",description:"Foundation embedding model for search and retrieval.",generation:"foundation",tier:"pro",category:"embedding",modalities:["text","embedding"],spec:{params:"3072 dimensions",activeParams:null,context:8e3,arch:"Embedding"},pricing:null,features:["3072 dimensions","Cosine similarity"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-embedding",github:null,aliases:[]},{id:"zen-reranker",name:"Zen Reranker",fullName:"Zen Reranker — Search Reranking",description:"Cross-encoder reranker for search result quality.",generation:"foundation",tier:"pro",category:"embedding",modalities:["text","embedding"],spec:{params:"568M",activeParams:null,context:8e3,arch:"Reranker"},pricing:null,features:["Cross-encoder","Search reranking"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-reranker",github:null,aliases:[]},{id:"zen-agent",name:"Zen Agent",fullName:"Zen Agent — Agentic AI",description:"Agent-optimized model for multi-step tool use and planning.",generation:"foundation",tier:"ultra",category:"agents",modalities:["text","code","agents"],spec:{params:"32B",activeParams:null,context:131e3,arch:"Dense"},pricing:null,features:["Tool use","Multi-step planning"],status:"preview",huggingface:null,github:null,aliases:[]}];a.filter(e=>null!==e.pricing),a.filter(e=>null!==e.huggingface),a.filter(e=>"zen4"===e.generation),a.filter(e=>"zen3"===e.generation),a.filter(e=>"zen5"===e.generation),a.filter(e=>"foundation"===e.generation),a.flatMap(e=>[[e.id,e],...e.aliases.map(a=>[a,e])]),e.s(["allModels",0,a],45382),e.s(["families",0,[{id:"zen5",name:"Zen 5",description:"Next-generation agentic models with native chain-of-thought.",icon:"Rocket",models:["zen5","zen5-pro","zen5-max","zen5-ultra","zen5-mini"]},{id:"zen4",name:"Zen 4",description:"Latest generation production models with MoDE architecture.",icon:"Sparkles",models:["zen4-max","zen4.1","zen4","zen4-ultra","zen4-pro","zen4-thinking","zen4-mini"]},{id:"code",name:"Code",description:"Specialized models for code generation, review, and debugging.",icon:"Code",models:["zen4-coder","zen4-coder-flash","zen4-coder-pro","zen-coder","zen-coder-flash","zen-code"]},{id:"zen3",name:"Zen 3",description:"Previous generation API models — language, vision, multimodal, and safety.",icon:"Eye",models:["zen3-omni","zen3-vl","zen3-nano","zen3-guard"]},{id:"embedding",name:"Embedding & Retrieval",description:"Text embeddings and search reranking via API.",icon:"Search",models:["zen3-embedding","zen3-embedding-medium","zen3-embedding-small","zen3-reranker","zen3-reranker-medium","zen3-reranker-small","zen-embedding","zen-reranker"]},{id:"image",name:"Image Generation",description:"Text-to-image generation via API.",icon:"Image",models:["zen3-image","zen3-image-max","zen3-image-dev","zen3-image-fast","zen3-image-sdxl","zen3-image-playground","zen3-image-ssd","zen3-image-jp"]},{id:"audio",name:"Audio & Speech",description:"Speech-to-text, text-to-speech, and streaming ASR.",icon:"Mic",models:["zen3-audio","zen3-audio-fast","zen3-asr","zen3-asr-v1","zen3-tts","zen3-tts-hd","zen3-tts-fast"]},{id:"foundation",name:"Foundation",description:"General-purpose open-weight models from 0.6B to 235B parameters.",icon:"Brain",models:["zen-nano","zen-eco","zen","zen-pro","zen-max","zen-next"]},{id:"vision",name:"Vision (Open Weights)",description:"Vision-language and multimodal open-weight models.",icon:"Eye",models:["zen-vl","zen-omni"]},{id:"safety",name:"Safety",description:"Content moderation and safety guardrail models.",icon:"Shield",models:["zen3-guard","zen-guard"]},{id:"agents",name:"Agents",description:"Agent-optimized models for tool use and planning.",icon:"Network",models:["zen-agent"]}]],40670),e.s([],804)},53514,e=>{"use strict";var a=e.i(40854);let t=e=>{let a=e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,a,t)=>t?t.toUpperCase():a.toLowerCase());return a.charAt(0).toUpperCase()+a.slice(1)},n=(...e)=>e.filter((e,a,t)=>!!e&&""!==e.trim()&&t.indexOf(e)===a).join(" ").trim();var i={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let r=(0,a.forwardRef)(({color:e="currentColor",size:t=24,strokeWidth:r=2,absoluteStrokeWidth:l,className:o="",children:s,iconNode:d,...c},m)=>(0,a.createElement)("svg",{ref:m,...i,width:t,height:t,stroke:e,strokeWidth:l?24*Number(r)/Number(t):r,className:n("lucide",o),...!s&&!(e=>{for(let a in e)if(a.startsWith("aria-")||"role"===a||"title"===a)return!0})(c)&&{"aria-hidden":"true"},...c},[...d.map(([e,t])=>(0,a.createElement)(e,t)),...Array.isArray(s)?s:[s]])),l=(e,i)=>{let l=(0,a.forwardRef)(({className:l,...o},s)=>(0,a.createElement)(r,{ref:s,iconNode:i,className:n(`lucide-${t(e).replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,l),...o}));return l.displayName=t(e),l};e.s(["default",()=>l],53514)},8303,e=>{"use strict";var a=e.i(52540),t=e.i(40854),n=e.i(78609),i=e.i(53514);let r=(0,i.default)("atom",[["circle",{cx:"12",cy:"12",r:"1",key:"41hilf"}],["path",{d:"M20.2 20.2c2.04-2.03.02-7.36-4.5-11.9-4.54-4.52-9.87-6.54-11.9-4.5-2.04 2.03-.02 7.36 4.5 11.9 4.54 4.52 9.87 6.54 11.9 4.5Z",key:"1l2ple"}],["path",{d:"M15.7 15.7c4.52-4.54 6.54-9.87 4.5-11.9-2.03-2.04-7.36-.02-11.9 4.5-4.52 4.54-6.54 9.87-4.5 11.9 2.03 2.04 7.36.02 11.9-4.5Z",key:"1wam0m"}]]),l=(0,i.default)("code",[["path",{d:"m16 18 6-6-6-6",key:"eg8j8"}],["path",{d:"m8 6-6 6 6 6",key:"ppft3o"}]]),o=(0,i.default)("zap",[["path",{d:"M4 14a1 1 0 0 1-.78-1.63l9.9-10.2a.5.5 0 0 1 .86.46l-1.92 6.02A1 1 0 0 0 13 10h7a1 1 0 0 1 .78 1.63l-9.9 10.2a.5.5 0 0 1-.86-.46l1.92-6.02A1 1 0 0 0 11 14z",key:"1xq2db"}]]),s=(0,i.default)("cpu",[["path",{d:"M12 20v2",key:"1lh1kg"}],["path",{d:"M12 2v2",key:"tus03m"}],["path",{d:"M17 20v2",key:"1rnc9c"}],["path",{d:"M17 2v2",key:"11trls"}],["path",{d:"M2 12h2",key:"1t8f8n"}],["path",{d:"M2 17h2",key:"7oei6x"}],["path",{d:"M2 7h2",key:"asdhe0"}],["path",{d:"M20 12h2",key:"1q8mjw"}],["path",{d:"M20 17h2",key:"1fpfkl"}],["path",{d:"M20 7h2",key:"1o8tra"}],["path",{d:"M7 20v2",key:"4gnj0m"}],["path",{d:"M7 2v2",key:"1i4yhu"}],["rect",{x:"4",y:"4",width:"16",height:"16",rx:"2",key:"1vbyd7"}],["rect",{x:"8",y:"8",width:"8",height:"8",rx:"1",key:"z9xiuo"}]]),d=(0,i.default)("eye",[["path",{d:"M2.062 12.348a1 1 0 0 1 0-.696 10.75 10.75 0 0 1 19.876 0 1 1 0 0 1 0 .696 10.75 10.75 0 0 1-19.876 0",key:"1nclc0"}],["circle",{cx:"12",cy:"12",r:"3",key:"1v7zrd"}]]),c=(0,i.default)("shield",[["path",{d:"M20 13c0 5-3.5 7.5-7.66 8.95a1 1 0 0 1-.67-.01C7.5 20.5 4 18 4 13V6a1 1 0 0 1 1-1c2 0 4.5-1.2 6.24-2.72a1.17 1.17 0 0 1 1.52 0C14.51 3.81 17 5 19 5a1 1 0 0 1 1 1z",key:"oel41y"}]]),m=(0,i.default)("search",[["path",{d:"m21 21-4.34-4.34",key:"14j7rj"}],["circle",{cx:"11",cy:"11",r:"8",key:"4ej97u"}]]),u=(0,i.default)("network",[["rect",{x:"16",y:"16",width:"6",height:"6",rx:"1",key:"4q2zg0"}],["rect",{x:"2",y:"16",width:"6",height:"6",rx:"1",key:"8cvhb9"}],["rect",{x:"9",y:"2",width:"6",height:"6",rx:"1",key:"1egb70"}],["path",{d:"M5 16v-3a1 1 0 0 1 1-1h12a1 1 0 0 1 1 1v3",key:"1jsf9p"}],["path",{d:"M12 12V8",key:"2874zd"}]]),g=(0,i.default)("mic",[["path",{d:"M12 19v3",key:"npa21l"}],["path",{d:"M19 10v2a7 7 0 0 1-14 0v-2",key:"1vc78b"}],["rect",{x:"9",y:"2",width:"6",height:"13",rx:"3",key:"s6n7sd"}]]),p=(0,i.default)("video",[["path",{d:"m16 13 5.223 3.482a.5.5 0 0 0 .777-.416V7.87a.5.5 0 0 0-.752-.432L16 10.5",key:"ftymec"}],["rect",{x:"2",y:"6",width:"14",height:"12",rx:"2",key:"158x01"}]]),h=(0,i.default)("box",[["path",{d:"M21 8a2 2 0 0 0-1-1.73l-7-4a2 2 0 0 0-2 0l-7 4A2 2 0 0 0 3 8v8a2 2 0 0 0 1 1.73l7 4a2 2 0 0 0 2 0l7-4A2 2 0 0 0 21 16Z",key:"hh9hay"}],["path",{d:"m3.3 7 8.7 5 8.7-5",key:"g66t2b"}],["path",{d:"M12 22V12",key:"d0xqtd"}]]),f=(0,i.default)("sparkles",[["path",{d:"M11.017 2.814a1 1 0 0 1 1.966 0l1.051 5.558a2 2 0 0 0 1.594 1.594l5.558 1.051a1 1 0 0 1 0 1.966l-5.558 1.051a2 2 0 0 0-1.594 1.594l-1.051 5.558a1 1 0 0 1-1.966 0l-1.051-5.558a2 2 0 0 0-1.594-1.594l-5.558-1.051a1 1 0 0 1 0-1.966l5.558-1.051a2 2 0 0 0 1.594-1.594z",key:"1s2grr"}],["path",{d:"M20 2v4",key:"1rf3ol"}],["path",{d:"M22 4h-4",key:"gwowj6"}],["circle",{cx:"4",cy:"20",r:"2",key:"6kqj1y"}]]),x=(0,i.default)("external-link",[["path",{d:"M15 3h6v6",key:"1q9fwt"}],["path",{d:"M10 14 21 3",key:"gplh6r"}],["path",{d:"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6",key:"a6xqqp"}]]),b=(0,i.default)("funnel",[["path",{d:"M10 20a1 1 0 0 0 .553.895l2 1A1 1 0 0 0 14 21v-7a2 2 0 0 1 .517-1.341L21.74 4.67A1 1 0 0 0 21 3H3a1 1 0 0 0-.742 1.67l7.225 7.989A2 2 0 0 1 10 14z",key:"sc7q7i"}]]),z=(0,i.default)("image",[["rect",{width:"18",height:"18",x:"3",y:"3",rx:"2",ry:"2",key:"1m3agn"}],["circle",{cx:"9",cy:"9",r:"2",key:"af1f0g"}],["path",{d:"m21 15-3.086-3.086a2 2 0 0 0-2.828 0L6 21",key:"1xmnt7"}]]),v=(0,i.default)("brain",[["path",{d:"M12 18V5",key:"adv99a"}],["path",{d:"M15 13a4.17 4.17 0 0 1-3-4 4.17 4.17 0 0 1-3 4",key:"1e3is1"}],["path",{d:"M17.598 6.5A3 3 0 1 0 12 5a3 3 0 1 0-5.598 1.5",key:"1gqd8o"}],["path",{d:"M17.997 5.125a4 4 0 0 1 2.526 5.77",key:"iwvgf7"}],["path",{d:"M18 18a4 4 0 0 0 2-7.464",key:"efp6ie"}],["path",{d:"M19.967 17.483A4 4 0 1 1 12 18a4 4 0 1 1-7.967-.517",key:"1gq6am"}],["path",{d:"M6 18a4 4 0 0 1-2-7.464",key:"k1g0md"}],["path",{d:"M6.003 5.125a4 4 0 0 0-2.526 5.77",key:"q97ue3"}]]),y=(0,i.default)("rocket",[["path",{d:"M4.5 16.5c-1.5 1.26-2 5-2 5s3.74-.5 5-2c.71-.84.7-2.13-.09-2.91a2.18 2.18 0 0 0-2.91-.09z",key:"m3kijz"}],["path",{d:"m12 15-3-3a22 22 0 0 1 2-3.95A12.88 12.88 0 0 1 22 2c0 2.72-.78 7.5-6 11a22.35 22.35 0 0 1-4 2z",key:"1fmvmk"}],["path",{d:"M9 12H4s.55-3.03 2-4c1.62-1.08 5 0 5 0",key:"1f8sc4"}],["path",{d:"M12 15v5s3.03-.55 4-2c1.08-1.62 0-5 0-5",key:"qeys4"}]]),k=(0,i.default)("message-square",[["path",{d:"M22 17a2 2 0 0 1-2 2H6.828a2 2 0 0 0-1.414.586l-2.202 2.202A.71.71 0 0 1 2 21.286V5a2 2 0 0 1 2-2h16a2 2 0 0 1 2 2z",key:"18887p"}]]),w=(0,i.default)("github",[["path",{d:"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4",key:"tonef"}],["path",{d:"M9 18c-4.51 2-5-2-7-2",key:"9comsn"}]]),N=(0,i.default)("file-text",[["path",{d:"M6 22a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.704.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2z",key:"1oefj6"}],["path",{d:"M14 2v5a1 1 0 0 0 1 1h5",key:"wfsgrz"}],["path",{d:"M10 9H8",key:"b1mrlr"}],["path",{d:"M16 13H8",key:"t4e002"}],["path",{d:"M16 17H8",key:"z1uh3a"}]]);e.i(804);var M=e.i(45382),Z=e.i(40670);let j={Sparkles:(0,a.jsx)(f,{className:"h-5 w-5"}),Rocket:(0,a.jsx)(y,{className:"h-5 w-5"}),Eye:(0,a.jsx)(d,{className:"h-5 w-5"}),Code:(0,a.jsx)(l,{className:"h-5 w-5"}),Search:(0,a.jsx)(m,{className:"h-5 w-5"}),Image:(0,a.jsx)(z,{className:"h-5 w-5"}),Mic:(0,a.jsx)(g,{className:"h-5 w-5"}),Brain:(0,a.jsx)(v,{className:"h-5 w-5"}),Shield:(0,a.jsx)(c,{className:"h-5 w-5"}),Network:(0,a.jsx)(u,{className:"h-5 w-5"}),Box:(0,a.jsx)(h,{className:"h-5 w-5"}),Video:(0,a.jsx)(p,{className:"h-5 w-5"}),Atom:(0,a.jsx)(r,{className:"h-5 w-5"}),Cpu:(0,a.jsx)(s,{className:"h-5 w-5"}),Zap:(0,a.jsx)(o,{className:"h-5 w-5"})},B=new Map(M.allModels.map(e=>[e.id,e]));function A(e){return"contact-sales"===e.status?"contact-sales":"preview"===e.status?"preview":"coming-soon"===e.status?"coming-soon":"active"}function P(){let[e,n]=(0,t.useState)(!1),i=Z.families.map(a=>{let t=a.models.map(e=>B.get(e)).filter(e=>void 0!==e).filter(a=>e||"active"===A(a)||"contact-sales"===A(a));return{...a,resolvedModels:t}}).filter(e=>e.resolvedModels.length>0),r=M.allModels.filter(e=>"active"===A(e)||"contact-sales"===A(e)).length,l=M.allModels.length,o=l-r;return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)("div",{className:"flex items-center justify-between mb-8",children:[(0,a.jsx)("div",{children:(0,a.jsxs)("p",{className:"text-sm text-fd-muted-foreground",children:["Showing ",(0,a.jsx)("strong",{children:e?l:r})," models",!e&&o>0&&(0,a.jsxs)(a.Fragment,{children:[" · ",o," legacy/upcoming hidden"]})]})}),(0,a.jsxs)("button",{onClick:()=>n(!e),className:"inline-flex items-center gap-2 rounded-lg border border-fd-border bg-fd-background px-3 py-1.5 text-sm font-medium hover:bg-fd-muted transition",children:[(0,a.jsx)(b,{className:"h-3.5 w-3.5"}),e?"Show Current Only":"Show All Models"]})]}),i.map(e=>(0,a.jsx)(C,{family:e,models:e.resolvedModels},e.id))]})}function C({family:e,models:t}){let n=j[e.icon]||(0,a.jsx)(r,{className:"h-5 w-5"});return(0,a.jsxs)("div",{className:"mb-12",children:[(0,a.jsxs)("div",{className:"flex items-center gap-3 mb-2",children:[(0,a.jsx)("div",{className:"rounded-lg bg-fd-muted p-2 text-fd-primary",children:n}),(0,a.jsxs)("div",{children:[(0,a.jsx)("h3",{className:"text-xl font-semibold",children:e.name}),(0,a.jsx)("p",{className:"text-sm text-fd-muted-foreground",children:e.description})]}),(0,a.jsxs)("span",{className:"ml-auto text-xs text-fd-muted-foreground bg-fd-muted px-2 py-1 rounded-full",children:[t.length," model",1!==t.length?"s":""]})]}),(0,a.jsx)("div",{className:"grid sm:grid-cols-2 lg:grid-cols-3 gap-3 mt-4",children:t.map(e=>(0,a.jsx)(S,{m:e},e.id))})]})}function S({m:e}){var t;let i=A(e),r="zen4-max"===e.id||"zen-max"===e.id||"zen5"===e.id,l=(0,n.useRouter)(),o=()=>{l.push(`/docs/models/${e.id}`)},s=["N/A"!==e.spec.params&&"TBA"!==e.spec.params&&"TBD"!==e.spec.params?e.spec.params:null,e.spec.activeParams?`(${e.spec.activeParams} active)`:null,e.spec.arch].filter(Boolean).join(" ");return(0,a.jsxs)("div",{role:"link",tabIndex:0,onClick:o,onKeyDown:e=>"Enter"===e.key&&o(),className:`rounded-lg border p-4 cursor-pointer transition hover:border-fd-primary/40 ${r?"border-fd-primary/30 bg-fd-primary/5":"coming-soon"===i?"border-fd-border bg-fd-muted/30 opacity-75":"contact-sales"===i?"border-purple-500/20 bg-purple-500/5":"border-fd-border bg-fd-background"}`,children:[(0,a.jsxs)("div",{className:"flex items-center gap-2 mb-1",children:[(0,a.jsx)("span",{className:"font-semibold text-sm",children:e.id}),(()=>{switch(i){case"preview":return(0,a.jsx)("span",{className:"text-[9px] font-semibold tracking-wider uppercase bg-amber-500/20 text-amber-600 dark:text-amber-400 px-1.5 py-0.5 rounded-full",children:"PREVIEW"});case"coming-soon":return(0,a.jsx)("span",{className:"text-[9px] font-semibold tracking-wider uppercase bg-fd-muted text-fd-muted-foreground px-1.5 py-0.5 rounded-full",children:"SOON"});case"contact-sales":return(0,a.jsx)("span",{className:"text-[9px] font-semibold tracking-wider uppercase bg-purple-500/20 text-purple-600 dark:text-purple-400 px-1.5 py-0.5 rounded-full",children:"EARLY ACCESS"});default:return null}})()]}),(0,a.jsxs)("div",{className:"text-xs font-mono text-fd-muted-foreground mb-2",children:[s,e.spec.context>0?` \xb7 ${!(t=e.spec.context)?"—":t>=1e6?`${(t/1e6).toFixed(+(t%1e6!=0))}M`:t>=1e3?`${Math.round(t/1e3)}K`:`${t}`} ctx`:""]}),(0,a.jsx)("p",{className:"text-xs text-fd-muted-foreground mb-2",children:e.description}),(0,a.jsxs)("div",{className:"flex flex-wrap gap-1.5 mt-auto",children:["contact-sales"===i&&(0,a.jsxs)("a",{href:"https://hanzo.industries/contact",target:"_blank",rel:"noopener noreferrer",onClick:e=>e.stopPropagation(),className:"inline-flex items-center gap-1 text-xs bg-purple-500/20 text-purple-400 border border-purple-500/30 px-2 py-0.5 rounded hover:bg-purple-500/30 transition",children:[(0,a.jsx)(x,{className:"h-2.5 w-2.5"})," Request Access"]}),("active"===i||"preview"===i)&&(0,a.jsxs)("a",{href:`https://hanzo.chat?model=${e.id}`,target:"_blank",rel:"noopener noreferrer",onClick:e=>e.stopPropagation(),className:"inline-flex items-center gap-1 text-xs bg-fd-primary text-fd-primary-foreground px-2 py-0.5 rounded hover:opacity-90 transition",children:[(0,a.jsx)(k,{className:"h-2.5 w-2.5"})," Chat"]}),e.huggingface&&(0,a.jsxs)("a",{href:e.huggingface,target:"_blank",rel:"noopener noreferrer",onClick:e=>e.stopPropagation(),className:"inline-flex items-center gap-1 text-xs text-fd-primary hover:underline",children:[(0,a.jsx)(x,{className:"h-2.5 w-2.5"})," Weights"]}),e.github&&(0,a.jsxs)("a",{href:e.github,target:"_blank",rel:"noopener noreferrer",onClick:e=>e.stopPropagation(),className:"inline-flex items-center gap-1 text-xs text-fd-muted-foreground hover:underline",children:[(0,a.jsx)(w,{className:"h-2.5 w-2.5"})," Repo"]}),e.paper&&(0,a.jsxs)("a",{href:e.paper,target:"_blank",rel:"noopener noreferrer",onClick:e=>e.stopPropagation(),className:"inline-flex items-center gap-1 text-xs text-fd-muted-foreground hover:underline",children:[(0,a.jsx)(N,{className:"h-2.5 w-2.5"})," Paper"]})]})]})}e.s(["default",()=>P],8303)},66845,e=>{"use strict";var a=e.i(52540),t=e.i(40854),n=e.i(53514);let i=(0,n.default)("check",[["path",{d:"M20 6 9 17l-5-5",key:"1gmf2c"}]]),r=(0,n.default)("copy",[["rect",{width:"14",height:"14",x:"8",y:"8",rx:"2",ry:"2",key:"17jyea"}],["path",{d:"M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2",key:"zix9uf"}]]),l=[{id:"zen-nano",name:"Zen Nano",size:"0.6B",ram:"~1 GB RAM",hf:"zenlm/zen-nano-0.6b",ollama:"ollama run hf.co/zenlm/zen-nano-0.6b",lmstudio:"zenlm/zen-nano-0.6b",gguf:"https://huggingface.co/zenlm/zen-nano-0.6b"},{id:"zen-eco",name:"Zen Eco",size:"4B",ram:"~3 GB RAM",hf:"zenlm/zen-eco-4b",ollama:"ollama run hf.co/zenlm/zen-eco-4b",lmstudio:"zenlm/zen-eco-4b",gguf:"https://huggingface.co/zenlm/zen-eco-4b"},{id:"zen",name:"Zen (8B)",size:"8B",ram:"~5 GB RAM",hf:"zenlm/zen-8b",ollama:"ollama run hf.co/zenlm/zen-8b",lmstudio:"zenlm/zen-8b",gguf:"https://huggingface.co/zenlm/zen-8b"},{id:"zen-pro",name:"Zen Pro",size:"32B",ram:"~20 GB RAM",hf:"zenlm/zen-pro-32b",ollama:"ollama run hf.co/zenlm/zen-pro-32b",lmstudio:"zenlm/zen-pro-32b",gguf:"https://huggingface.co/zenlm/zen-pro-32b"},{id:"zen-coder",name:"Zen Coder",size:"32B",ram:"~20 GB RAM",hf:"zenlm/zen-coder",ollama:"ollama run hf.co/zenlm/zen-coder",lmstudio:"zenlm/zen-coder",gguf:"https://huggingface.co/zenlm/zen-coder"},{id:"zen-max",name:"Zen Max",size:"235B MoE",ram:"~48 GB RAM",hf:"zenlm/zen-max",ollama:"ollama run hf.co/zenlm/zen-max",lmstudio:"zenlm/zen-max",gguf:"https://huggingface.co/zenlm/zen-max"}];function o({text:e}){let[n,l]=(0,t.useState)(!1);return(0,a.jsx)("button",{onClick:()=>{navigator.clipboard.writeText(e),l(!0),setTimeout(()=>l(!1),2e3)},className:"shrink-0 rounded-lg p-1.5 text-fd-muted-foreground hover:text-fd-foreground hover:bg-fd-border transition","aria-label":"Copy",children:n?(0,a.jsx)(i,{className:"h-3.5 w-3.5 text-green-500"}):(0,a.jsx)(r,{className:"h-3.5 w-3.5"})})}function s(){let[e,n]=(0,t.useState)("ollama"),[i,r]=(0,t.useState)(l[0]);return(0,a.jsxs)("div",{className:"rounded-2xl border border-fd-border bg-fd-background overflow-hidden",children:[(0,a.jsxs)("div",{className:"flex items-center gap-1 border-b border-fd-border px-4 py-3 bg-fd-muted/50",children:[[{id:"ollama",label:"Ollama"},{id:"lmstudio",label:"LM Studio"},{id:"gguf",label:"GGUF / Direct"}].map(t=>(0,a.jsx)("button",{onClick:()=>n(t.id),className:`px-4 py-1.5 rounded-lg text-sm font-medium transition ${e===t.id?"bg-fd-background text-fd-foreground shadow-sm border border-fd-border":"text-fd-muted-foreground hover:text-fd-foreground"}`,children:t.label},t.id)),(0,a.jsx)("span",{className:"ml-auto text-xs text-fd-muted-foreground hidden sm:block",children:"Pick a model →"})]}),(0,a.jsxs)("div",{className:"grid md:grid-cols-[280px_1fr]",children:[(0,a.jsx)("div",{className:"border-b md:border-b-0 md:border-r border-fd-border p-3 flex md:flex-col gap-2",children:l.map(e=>(0,a.jsxs)("button",{onClick:()=>r(e),className:`text-left rounded-xl px-3 py-2.5 transition flex-1 md:flex-none ${i.id===e.id?"bg-fd-muted border border-fd-border":"hover:bg-fd-muted/50"}`,children:[(0,a.jsx)("div",{className:"font-medium text-sm",children:e.name}),(0,a.jsxs)("div",{className:"text-xs text-fd-muted-foreground",children:[e.size," · ",e.ram]})]},e.id))}),(0,a.jsxs)("div",{className:"p-6 md:p-8",children:["ollama"===e&&(0,a.jsxs)("div",{className:"space-y-6",children:[(0,a.jsxs)("div",{children:[(0,a.jsx)("p",{className:"text-sm text-fd-muted-foreground mb-1",children:"1. Install Ollama"}),(0,a.jsx)("a",{href:"https://ollama.com/download",target:"_blank",rel:"noopener noreferrer",className:"text-sm font-medium text-fd-primary hover:underline",children:"Download Ollama from ollama.com →"})]}),(0,a.jsxs)("div",{children:[(0,a.jsxs)("p",{className:"text-sm text-fd-muted-foreground mb-2",children:["2. Run ",i.name]}),(0,a.jsxs)("div",{className:"flex items-center gap-2 rounded-xl bg-fd-muted border border-fd-border px-4 py-3",children:[(0,a.jsx)("code",{className:"text-sm font-mono flex-1 overflow-x-auto",children:i.ollama}),(0,a.jsx)(o,{text:i.ollama})]})]}),(0,a.jsxs)("p",{className:"text-xs text-fd-muted-foreground",children:["Ollama will download the model from HuggingFace automatically on first run. Requires ",i.ram,"."]})]}),"lmstudio"===e&&(0,a.jsxs)("div",{className:"space-y-6",children:[(0,a.jsxs)("div",{children:[(0,a.jsx)("p",{className:"text-sm text-fd-muted-foreground mb-1",children:"1. Install LM Studio"}),(0,a.jsx)("a",{href:"https://lmstudio.ai",target:"_blank",rel:"noopener noreferrer",className:"text-sm font-medium text-fd-primary hover:underline",children:"Download LM Studio from lmstudio.ai →"})]}),(0,a.jsxs)("div",{children:[(0,a.jsx)("p",{className:"text-sm text-fd-muted-foreground mb-2",children:"2. Search for model in the Discover tab"}),(0,a.jsxs)("div",{className:"flex items-center gap-2 rounded-xl bg-fd-muted border border-fd-border px-4 py-3",children:[(0,a.jsx)("code",{className:"text-sm font-mono flex-1",children:i.lmstudio}),(0,a.jsx)(o,{text:i.lmstudio})]})]}),(0,a.jsxs)("div",{children:[(0,a.jsx)("p",{className:"text-sm text-fd-muted-foreground mb-2",children:"3. Or open directly on HuggingFace"}),(0,a.jsxs)("a",{href:`https://huggingface.co/${i.hf}`,target:"_blank",rel:"noopener noreferrer",className:"text-sm font-medium text-fd-primary hover:underline break-all",children:["huggingface.co/",i.hf," →"]})]}),(0,a.jsxs)("p",{className:"text-xs text-fd-muted-foreground",children:["LM Studio has a built-in model browser. Search for the model ID above in the Discover tab. Requires ",i.ram,"."]})]}),"gguf"===e&&(0,a.jsxs)("div",{className:"space-y-6",children:[(0,a.jsxs)("div",{children:[(0,a.jsx)("p",{className:"text-sm text-fd-muted-foreground mb-2",children:"HuggingFace repository"}),(0,a.jsxs)("a",{href:i.gguf,target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center gap-2 rounded-xl bg-fd-muted border border-fd-border px-4 py-3 text-sm font-medium hover:bg-fd-border transition w-full",children:["huggingface.co/",i.hf," →"]})]}),(0,a.jsxs)("div",{children:[(0,a.jsx)("p",{className:"text-sm text-fd-muted-foreground mb-2",children:"Available formats"}),(0,a.jsx)("div",{className:"grid grid-cols-2 gap-2",children:["Q4_K_M (recommended)","Q5_K_M","Q8_0","F16 (full)"].map(e=>(0,a.jsx)("div",{className:"rounded-lg bg-fd-muted border border-fd-border px-3 py-2 text-xs font-mono",children:e},e))})]}),(0,a.jsxs)("div",{children:[(0,a.jsx)("p",{className:"text-sm text-fd-muted-foreground mb-2",children:"Run with llama.cpp"}),(0,a.jsxs)("div",{className:"flex items-center gap-2 rounded-xl bg-fd-muted border border-fd-border px-4 py-3",children:[(0,a.jsx)("code",{className:"text-sm font-mono flex-1 overflow-x-auto",children:`./llama-cli -m ${i.id}-q4_k_m.gguf -p "Hello"`}),(0,a.jsx)(o,{text:`./llama-cli -m ${i.id}-q4_k_m.gguf -p "Hello"`})]})]}),(0,a.jsx)("p",{className:"text-xs text-fd-muted-foreground",children:"Download the GGUF file from the HuggingFace repo above. Works with llama.cpp, Ollama, LM Studio, Jan, and any other GGUF-compatible runtime."})]})]})]})]})}e.s(["default",()=>s],66845)}]);