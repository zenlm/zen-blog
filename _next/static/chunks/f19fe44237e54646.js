(globalThis.TURBOPACK||(globalThis.TURBOPACK=[])).push(["object"==typeof document?document.currentScript:void 0,5337,e=>{"use strict";var a=e.i(40854);let t=(...e)=>e.filter((e,a,t)=>!!e&&t.indexOf(e)===a).join(" ");var n={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let i=(0,a.forwardRef)(({color:e="currentColor",size:i=24,strokeWidth:r=2,absoluteStrokeWidth:l,className:s="",children:o,iconNode:c,...d},u)=>(0,a.createElement)("svg",{ref:u,...n,width:i,height:i,stroke:e,strokeWidth:l?24*Number(r)/Number(i):r,className:t("lucide",s),...d},[...c.map(([e,t])=>(0,a.createElement)(e,t)),...Array.isArray(o)?o:[o]])),r=(e,n)=>{let r=(0,a.forwardRef)(({className:r,...l},s)=>(0,a.createElement)(i,{ref:s,iconNode:n,className:t(`lucide-${e.replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,r),...l}));return r.displayName=`${e}`,r},l=r("ExternalLink",[["path",{d:"M15 3h6v6",key:"1q9fwt"}],["path",{d:"M10 14 21 3",key:"gplh6r"}],["path",{d:"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6",key:"a6xqqp"}]]),s=r("MessageSquare",[["path",{d:"M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z",key:"1lielz"}]]),o=r("Github",[["path",{d:"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4",key:"tonef"}],["path",{d:"M9 18c-4.51 2-5-2-7-2",key:"9comsn"}]]),c=r("FileText",[["path",{d:"M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z",key:"1rqfz7"}],["path",{d:"M14 2v4a2 2 0 0 0 2 2h4",key:"tnqrlb"}],["path",{d:"M10 9H8",key:"b1mrlr"}],["path",{d:"M16 13H8",key:"t4e002"}],["path",{d:"M16 17H8",key:"z1uh3a"}]]),d=r("Atom",[["circle",{cx:"12",cy:"12",r:"1",key:"41hilf"}],["path",{d:"M20.2 20.2c2.04-2.03.02-7.36-4.5-11.9-4.54-4.52-9.87-6.54-11.9-4.5-2.04 2.03-.02 7.36 4.5 11.9 4.54 4.52 9.87 6.54 11.9 4.5Z",key:"1l2ple"}],["path",{d:"M15.7 15.7c4.52-4.54 6.54-9.87 4.5-11.9-2.03-2.04-7.36-.02-11.9 4.5-4.52 4.54-6.54 9.87-4.5 11.9 2.03 2.04 7.36.02 11.9-4.5Z",key:"1wam0m"}]]),u=r("Filter",[["polygon",{points:"22 3 2 3 10 12.46 10 19 14 21 14 12.46 22 3",key:"1yg77f"}]]),g=r("Zap",[["path",{d:"M4 14a1 1 0 0 1-.78-1.63l9.9-10.2a.5.5 0 0 1 .86.46l-1.92 6.02A1 1 0 0 0 13 10h7a1 1 0 0 1 .78 1.63l-9.9 10.2a.5.5 0 0 1-.86-.46l1.92-6.02A1 1 0 0 0 11 14z",key:"1xq2db"}]]),m=r("Cpu",[["rect",{width:"16",height:"16",x:"4",y:"4",rx:"2",key:"14l7u7"}],["rect",{width:"6",height:"6",x:"9",y:"9",rx:"1",key:"5aljv4"}],["path",{d:"M15 2v2",key:"13l42r"}],["path",{d:"M15 20v2",key:"15mkzm"}],["path",{d:"M2 15h2",key:"1gxd5l"}],["path",{d:"M2 9h2",key:"1bbxkp"}],["path",{d:"M20 15h2",key:"19e6y8"}],["path",{d:"M20 9h2",key:"19tzq7"}],["path",{d:"M9 2v2",key:"165o2o"}],["path",{d:"M9 20v2",key:"i2bqo8"}]]),p=r("Video",[["path",{d:"m16 13 5.223 3.482a.5.5 0 0 0 .777-.416V7.87a.5.5 0 0 0-.752-.432L16 10.5",key:"ftymec"}],["rect",{x:"2",y:"6",width:"14",height:"12",rx:"2",key:"158x01"}]]),h=r("Box",[["path",{d:"M21 8a2 2 0 0 0-1-1.73l-7-4a2 2 0 0 0-2 0l-7 4A2 2 0 0 0 3 8v8a2 2 0 0 0 1 1.73l7 4a2 2 0 0 0 2 0l7-4A2 2 0 0 0 21 16Z",key:"hh9hay"}],["path",{d:"m3.3 7 8.7 5 8.7-5",key:"g66t2b"}],["path",{d:"M12 22V12",key:"d0xqtd"}]]),f=r("Network",[["rect",{x:"16",y:"16",width:"6",height:"6",rx:"1",key:"4q2zg0"}],["rect",{x:"2",y:"16",width:"6",height:"6",rx:"1",key:"8cvhb9"}],["rect",{x:"9",y:"2",width:"6",height:"6",rx:"1",key:"1egb70"}],["path",{d:"M5 16v-3a1 1 0 0 1 1-1h12a1 1 0 0 1 1 1v3",key:"1jsf9p"}],["path",{d:"M12 12V8",key:"2874zd"}]]),x=r("Shield",[["path",{d:"M20 13c0 5-3.5 7.5-7.66 8.95a1 1 0 0 1-.67-.01C7.5 20.5 4 18 4 13V6a1 1 0 0 1 1-1c2 0 4.5-1.2 6.24-2.72a1.17 1.17 0 0 1 1.52 0C14.51 3.81 17 5 19 5a1 1 0 0 1 1 1z",key:"oel41y"}]]),b=r("Brain",[["path",{d:"M12 5a3 3 0 1 0-5.997.125 4 4 0 0 0-2.526 5.77 4 4 0 0 0 .556 6.588A4 4 0 1 0 12 18Z",key:"l5xja"}],["path",{d:"M12 5a3 3 0 1 1 5.997.125 4 4 0 0 1 2.526 5.77 4 4 0 0 1-.556 6.588A4 4 0 1 1 12 18Z",key:"ep3f8r"}],["path",{d:"M15 13a4.5 4.5 0 0 1-3-4 4.5 4.5 0 0 1-3 4",key:"1p4c4q"}],["path",{d:"M17.599 6.5a3 3 0 0 0 .399-1.375",key:"tmeiqw"}],["path",{d:"M6.003 5.125A3 3 0 0 0 6.401 6.5",key:"105sqy"}],["path",{d:"M3.477 10.896a4 4 0 0 1 .585-.396",key:"ql3yin"}],["path",{d:"M19.938 10.5a4 4 0 0 1 .585.396",key:"1qfode"}],["path",{d:"M6 18a4 4 0 0 1-1.967-.516",key:"2e4loj"}],["path",{d:"M19.967 17.484A4 4 0 0 1 18 18",key:"159ez6"}]]),v=r("Mic",[["path",{d:"M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3Z",key:"131961"}],["path",{d:"M19 10v2a7 7 0 0 1-14 0v-2",key:"1vc78b"}],["line",{x1:"12",x2:"12",y1:"19",y2:"22",key:"x3vr5v"}]]),z=r("Image",[["rect",{width:"18",height:"18",x:"3",y:"3",rx:"2",ry:"2",key:"1m3agn"}],["circle",{cx:"9",cy:"9",r:"2",key:"af1f0g"}],["path",{d:"m21 15-3.086-3.086a2 2 0 0 0-2.828 0L6 21",key:"1xmnt7"}]]),y=r("Search",[["circle",{cx:"11",cy:"11",r:"8",key:"4ej97u"}],["path",{d:"m21 21-4.3-4.3",key:"1qie3q"}]]),k=r("Code",[["polyline",{points:"16 18 22 12 16 6",key:"z7tu5w"}],["polyline",{points:"8 6 2 12 8 18",key:"1eg1df"}]]),w=r("Eye",[["path",{d:"M2 12s3-7 10-7 10 7 10 7-3 7-10 7-10-7-10-7Z",key:"rwhkz3"}],["circle",{cx:"12",cy:"12",r:"3",key:"1v7zrd"}]]),N=r("Rocket",[["path",{d:"M4.5 16.5c-1.5 1.26-2 5-2 5s3.74-.5 5-2c.71-.84.7-2.13-.09-2.91a2.18 2.18 0 0 0-2.91-.09z",key:"m3kijz"}],["path",{d:"m12 15-3-3a22 22 0 0 1 2-3.95A12.88 12.88 0 0 1 22 2c0 2.72-.78 7.5-6 11a22.35 22.35 0 0 1-4 2z",key:"1fmvmk"}],["path",{d:"M9 12H4s.55-3.03 2-4c1.62-1.08 5 0 5 0",key:"1f8sc4"}],["path",{d:"M12 15v5s3.03-.55 4-2c1.08-1.62 0-5 0-5",key:"qeys4"}]]),M=r("Sparkles",[["path",{d:"M9.937 15.5A2 2 0 0 0 8.5 14.063l-6.135-1.582a.5.5 0 0 1 0-.962L8.5 9.936A2 2 0 0 0 9.937 8.5l1.582-6.135a.5.5 0 0 1 .963 0L14.063 8.5A2 2 0 0 0 15.5 9.937l6.135 1.581a.5.5 0 0 1 0 .964L15.5 14.063a2 2 0 0 0-1.437 1.437l-1.582 6.135a.5.5 0 0 1-.963 0z",key:"4pj2yx"}],["path",{d:"M20 3v4",key:"1olli1"}],["path",{d:"M22 5h-4",key:"1gvqau"}],["path",{d:"M4 17v2",key:"vumght"}],["path",{d:"M5 18H3",key:"zchphs"}]]);var Z=e.i(52540);function B({model:e,onNavigate:a,linkPrefix:t="/docs/models/",chatBaseUrl:n="https://hanzo.chat",requestAccessUrl:i="https://hanzo.ai/contact",featuredIds:r}){var d,u;let g=e.status,m=(d=e.id,r?r.includes(d):["zen4-max","zen-max","zen5","zen4"].includes(d)),p=function(e){switch(e){case"preview":return{label:"PREVIEW",className:"bg-amber-500/20 text-amber-600 dark:text-amber-400"};case"coming-soon":return{label:"SOON",className:"bg-muted text-muted-foreground"};case"contact-sales":return{label:"EARLY ACCESS",className:"bg-purple-500/20 text-purple-600 dark:text-purple-400"};default:return null}}(g),h=[[e.spec.params&&"N/A"!==e.spec.params&&"TBA"!==e.spec.params&&"TBD"!==e.spec.params?e.spec.params:null,e.spec.activeParams?`(${e.spec.activeParams} active)`:null,e.spec.arch??null].filter(Boolean).join(" "),!(u=e.spec.context)?"":u>=1e6?`${(u/1e6).toFixed(+(u%1e6!=0))}M ctx`:u>=1e3?`${Math.round(u/1e3)}K ctx`:`${u} ctx`].filter(Boolean).join(" · "),f=m?"border-primary/30 bg-primary/5":"coming-soon"===g?"border-border bg-muted/30 opacity-75":"contact-sales"===g?"border-purple-500/20 bg-purple-500/5":"border-border bg-background",x=!!a,b=()=>a?.(e.id);return(0,Z.jsxs)("div",{role:x?"link":void 0,tabIndex:x?0:void 0,onClick:x?b:void 0,onKeyDown:x?e=>{("Enter"===e.key||" "===e.key)&&b()}:void 0,className:`rounded-lg border p-4 transition hover:border-primary/40 ${f} ${x?"cursor-pointer":""}`,children:[(0,Z.jsxs)("div",{className:"flex items-center gap-2 mb-1",children:[(0,Z.jsx)("span",{className:"font-semibold text-sm",children:e.id}),p&&(0,Z.jsx)("span",{className:`text-[9px] font-semibold tracking-wider uppercase px-1.5 py-0.5 rounded-full ${p.className}`,children:p.label})]}),h&&(0,Z.jsx)("div",{className:"text-xs font-mono text-muted-foreground mb-2",children:h}),(0,Z.jsx)("p",{className:"text-xs text-muted-foreground mb-3",children:e.description}),(0,Z.jsxs)("div",{className:"flex flex-wrap gap-1.5 mt-auto",children:["contact-sales"===g&&(0,Z.jsxs)("a",{href:i,target:"_blank",rel:"noopener noreferrer",onClick:e=>{e.stopPropagation()},className:"inline-flex items-center gap-1 text-xs bg-purple-500/20 text-purple-400 border border-purple-500/30 px-2 py-0.5 rounded hover:bg-purple-500/30 transition",children:[(0,Z.jsx)(l,{className:"h-2.5 w-2.5"})," Request Access"]}),("available"===g||"preview"===g||"cloud-only"===g)&&(0,Z.jsxs)("a",{href:`${n}?model=${e.id}`,target:"_blank",rel:"noopener noreferrer",onClick:e=>{e.stopPropagation()},className:"inline-flex items-center gap-1 text-xs bg-primary text-primary-foreground px-2 py-0.5 rounded hover:opacity-90 transition",children:[(0,Z.jsx)(s,{className:"h-2.5 w-2.5"})," Chat"]}),e.huggingface&&(0,Z.jsxs)("a",{href:e.huggingface,target:"_blank",rel:"noopener noreferrer",onClick:e=>{e.stopPropagation()},className:"inline-flex items-center gap-1 text-xs text-primary hover:underline",children:[(0,Z.jsx)(l,{className:"h-2.5 w-2.5"})," Weights"]}),e.github&&(0,Z.jsxs)("a",{href:e.github,target:"_blank",rel:"noopener noreferrer",onClick:e=>{e.stopPropagation()},className:"inline-flex items-center gap-1 text-xs text-muted-foreground hover:underline",children:[(0,Z.jsx)(o,{className:"h-2.5 w-2.5"})," Repo"]}),e.paper&&(0,Z.jsxs)("a",{href:e.paper,target:"_blank",rel:"noopener noreferrer",onClick:e=>{e.stopPropagation()},className:"inline-flex items-center gap-1 text-xs text-muted-foreground hover:underline",children:[(0,Z.jsx)(c,{className:"h-2.5 w-2.5"})," Paper"]})]})]})}function j(e){return null==e?"—":`$${e.toFixed(2)}`}function P({status:e}){return"preview"===e||"coming-soon"===e?(0,Z.jsx)("span",{className:"ml-1 text-[9px] font-semibold tracking-wider uppercase bg-amber-500/20 text-amber-600 dark:text-amber-400 px-1.5 py-0.5 rounded-full align-middle",children:"preview"===e?"PREVIEW":"SOON"}):"contact-sales"===e?(0,Z.jsx)("span",{className:"ml-1 text-[9px] font-semibold tracking-wider uppercase bg-purple-500/20 text-purple-600 dark:text-purple-400 px-1.5 py-0.5 rounded-full align-middle",children:"EARLY ACCESS"}):null}function A({models:e,linkPrefix:a="/docs/models/",showParams:t=!0,showArch:n=!1,showContext:i=!0,showPricing:r=!0}){return(0,Z.jsx)("div",{className:"overflow-x-auto my-4",children:(0,Z.jsxs)("table",{className:"w-full text-sm",children:[(0,Z.jsx)("thead",{children:(0,Z.jsxs)("tr",{className:"border-b border-border text-left",children:[(0,Z.jsx)("th",{className:"pb-2 pr-4 font-medium",children:"Model"}),t&&(0,Z.jsx)("th",{className:"pb-2 pr-4 font-medium",children:"Parameters"}),n&&(0,Z.jsx)("th",{className:"pb-2 pr-4 font-medium",children:"Architecture"}),i&&(0,Z.jsx)("th",{className:"pb-2 pr-4 font-medium",children:"Context"}),r&&(0,Z.jsx)("th",{className:"pb-2 pr-4 font-medium text-right",children:"Input $/1M"}),r&&(0,Z.jsx)("th",{className:"pb-2 font-medium text-right",children:"Output $/1M"})]})}),(0,Z.jsx)("tbody",{className:"divide-y divide-border",children:e.map(e=>{var l;return(0,Z.jsxs)("tr",{children:[(0,Z.jsxs)("td",{className:"py-2 pr-4",children:[(0,Z.jsx)("a",{href:`${a}${e.id}`,className:"font-mono text-primary hover:underline text-sm",children:e.id}),(0,Z.jsx)(P,{status:e.status})]}),t&&(0,Z.jsxs)("td",{className:"py-2 pr-4 text-sm text-muted-foreground",children:[e.spec.params&&!["N/A","TBA","TBD"].includes(e.spec.params)?e.spec.params:"—",e.spec.activeParams?` (${e.spec.activeParams} active)`:""]}),n&&(0,Z.jsx)("td",{className:"py-2 pr-4 text-sm text-muted-foreground",children:e.spec.arch??"—"}),i&&(0,Z.jsx)("td",{className:"py-2 pr-4 text-sm text-muted-foreground",children:(l=e.spec.context)?l>=1e6?`${(l/1e6).toFixed(+(l%1e6!=0))}M`:l>=1e3?`${Math.round(l/1e3)}K`:`${l}`:"—"}),r&&(0,Z.jsx)("td",{className:"py-2 pr-4 text-sm text-right font-mono",children:j(e.pricing?.input)}),r&&(0,Z.jsx)("td",{className:"py-2 text-sm text-right font-mono",children:j(e.pricing?.output)})]},e.id)})})]})})}var C={Sparkles:(0,Z.jsx)(M,{className:"h-5 w-5"}),Rocket:(0,Z.jsx)(N,{className:"h-5 w-5"}),Eye:(0,Z.jsx)(w,{className:"h-5 w-5"}),Code:(0,Z.jsx)(k,{className:"h-5 w-5"}),Search:(0,Z.jsx)(y,{className:"h-5 w-5"}),Image:(0,Z.jsx)(z,{className:"h-5 w-5"}),Mic:(0,Z.jsx)(v,{className:"h-5 w-5"}),Brain:(0,Z.jsx)(b,{className:"h-5 w-5"}),Shield:(0,Z.jsx)(x,{className:"h-5 w-5"}),Network:(0,Z.jsx)(f,{className:"h-5 w-5"}),Box:(0,Z.jsx)(h,{className:"h-5 w-5"}),Video:(0,Z.jsx)(p,{className:"h-5 w-5"}),Atom:(0,Z.jsx)(d,{className:"h-5 w-5"}),Cpu:(0,Z.jsx)(m,{className:"h-5 w-5"}),Zap:(0,Z.jsx)(g,{className:"h-5 w-5"})};function E(e){return"available"===e||"contact-sales"===e||"cloud-only"===e}function S({family:e,models:a,onNavigate:t,chatBaseUrl:n,requestAccessUrl:i,featuredIds:r}){let l=(e.icon&&C[e.icon])??(0,Z.jsx)(d,{className:"h-5 w-5"});return(0,Z.jsxs)("div",{className:"mb-12",children:[(0,Z.jsxs)("div",{className:"flex items-center gap-3 mb-2",children:[(0,Z.jsx)("div",{className:"rounded-lg bg-muted p-2 text-primary",children:l}),(0,Z.jsxs)("div",{children:[(0,Z.jsx)("h3",{className:"text-xl font-semibold",children:e.name}),(0,Z.jsx)("p",{className:"text-sm text-muted-foreground",children:e.description})]}),(0,Z.jsxs)("span",{className:"ml-auto text-xs text-muted-foreground bg-muted px-2 py-1 rounded-full",children:[a.length," model",1!==a.length?"s":""]})]}),(0,Z.jsx)("div",{className:"grid sm:grid-cols-2 lg:grid-cols-3 gap-3 mt-4",children:a.map(e=>(0,Z.jsx)(B,{model:e,onNavigate:t,chatBaseUrl:n,requestAccessUrl:i,featuredIds:r},e.id))})]})}function T({families:e,allModels:t,linkPrefix:n="/docs/models/",chatBaseUrl:i="https://hanzo.chat",requestAccessUrl:r="https://hanzo.ai/contact",featuredIds:l,showAllLabel:s="Show All Models",showCurrentLabel:o="Show Current Only",onNavigate:c}){let[d,g]=(0,a.useState)(!1),m=new Map(t.map(e=>[e.id,e])),p=e=>{c?c(e):window.location.href=`${n}${e}`},h=e.map(e=>{let a=e.models.map(e=>m.get(e)).filter(e=>void 0!==e).filter(e=>d||E(e.status));return{...e,resolvedModels:a}}).filter(e=>e.resolvedModels.length>0),f=t.filter(e=>E(e.status)).length,x=t.length,b=x-f;return(0,Z.jsxs)(Z.Fragment,{children:[(0,Z.jsxs)("div",{className:"flex items-center justify-between mb-8",children:[(0,Z.jsxs)("p",{className:"text-sm text-muted-foreground",children:["Showing ",(0,Z.jsx)("strong",{children:d?x:f})," models",!d&&b>0&&(0,Z.jsxs)(Z.Fragment,{children:[" · ",b," legacy/upcoming hidden"]})]}),(0,Z.jsxs)("button",{onClick:()=>g(!d),className:"inline-flex items-center gap-2 rounded-lg border border-border bg-background px-3 py-1.5 text-sm font-medium hover:bg-muted transition",children:[(0,Z.jsx)(u,{className:"h-3.5 w-3.5"}),d?o:s]})]}),h.map(e=>(0,Z.jsx)(S,{family:e,models:e.resolvedModels,onNavigate:p,chatBaseUrl:i,requestAccessUrl:r,featuredIds:l},e.id))]})}function R({size:e=64,color:a="white",animate:t=!0,loop:n=!1,asLoader:i=!1,className:r=""}){let l=Math.random().toString(36).slice(2,7),s=i?{animation:`zenEnsoSpin-${l} 1.2s linear infinite`}:{};return(0,Z.jsxs)("span",{className:`inline-flex items-center justify-center ${r}`,style:{width:e,height:e},"aria-label":"Zen LM",children:[(0,Z.jsx)("style",{children:`
        @keyframes zenEnsoDraw-${l} {
          to { stroke-dashoffset: 0; }
        }
        @keyframes zenEnsoSpin-${l} {
          to { transform: rotate(360deg); }
        }
        .zen-enso-stroke-${l} {
          stroke-dasharray: 1200;
          stroke-dashoffset: ${t?"1200":"0"};
          animation: ${t?`zenEnsoDraw-${l} ${n?"1.35s":"1.25s"} cubic-bezier(.2,.9,.25,1) ${n?"infinite":"1"} forwards`:"none"};
        }
      `}),(0,Z.jsx)("svg",{viewBox:"0 0 512 512",fill:"none",xmlns:"http://www.w3.org/2000/svg",width:e,height:e,style:s,children:(0,Z.jsx)("path",{className:`zen-enso-stroke-${l}`,d:"M256 74 C154 74 78 160 78 258 C78 352 150 432 250 438 C345 444 434 374 438 276 C441 210 406 150 348 118 C305 94 280 86 256 74",stroke:a,strokeWidth:"26",strokeLinecap:"round",strokeLinejoin:"round"})})]})}e.s(["ModelCard",()=>B,"ModelFamilySection",()=>S,"ModelLibrary",()=>T,"ModelTable",()=>A,"ZenEnso",()=>R],5337)},58171,91846,82874,e=>{"use strict";var a=[{id:"zen4",name:"Zen4",fullName:"Zen4 — Flagship",description:"Flagship MoE model for complex reasoning and multi-domain tasks.",generation:"zen4",tier:"ultra max",category:"flagship",modalities:["text","code","math"],spec:{params:"744B",activeParams:"40B",context:202e3,arch:"MoE"},pricing:{input:3,output:9.6,cacheRead:null,cacheWrite:null},features:["202K context window","Flagship intelligence","100+ languages"],status:"available",huggingface:"https://huggingface.co/zenlm/zen4",github:"https://github.com/zenlm/zen4",aliases:[]},{id:"zen4-pro",name:"Zen4 Pro",fullName:"Zen4 Pro — High Capability",description:"Efficient MoE model for demanding workloads with strong reasoning at production-grade cost.",generation:"zen4",tier:"ultra",category:"flagship",modalities:["text","code","math"],spec:{params:"80B",activeParams:"3B",context:131e3,arch:"MoE"},pricing:{input:2.7,output:2.7,cacheRead:null,cacheWrite:null},features:["131K context window","MoE architecture"],status:"available",huggingface:"https://huggingface.co/zenlm/zen4-pro",github:"https://github.com/zenlm/zen4-pro",aliases:[]},{id:"zen4-max",name:"Zen4 Max",fullName:"Zen4 Max — Maximum Intelligence",description:"Most capable model for complex reasoning, analysis, and agentic tasks. 1M token context window.",generation:"zen4",tier:"ultra max",category:"flagship",modalities:["text","code","math"],spec:{params:"N/A",activeParams:null,context:1e6,arch:"Dense"},pricing:{input:3.6,output:3.6,cacheRead:null,cacheWrite:null},features:["1M context window","Maximum intelligence","Agentic coding"],status:"available",huggingface:null,github:null,aliases:["zen-max"]},{id:"zen4.1",name:"Zen4.1",fullName:"Zen4.1 — Extended Context",description:"High-performance 1M context model for long-document analysis, large codebase reasoning, and agentic workflows. Best balance of intelligence and cost at million-token scale.",generation:"zen4",tier:"ultra",category:"flagship",modalities:["text","code","math"],spec:{params:"N/A",activeParams:null,context:1e6,arch:"Dense"},pricing:{input:3.6,output:3.6,cacheRead:null,cacheWrite:null},features:["1M context window","Agentic coding","Long-document analysis","Cost efficient"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen4-mini",name:"Zen4 Mini",fullName:"Zen4 Mini — Fast & Efficient",description:"Ultra-fast lightweight model optimized for speed and cost efficiency. Ideal for free tier.",generation:"zen4",tier:"pro",category:"flagship",modalities:["text","code"],spec:{params:"N/A",activeParams:null,context:128e3,arch:"Dense"},pricing:{input:.6,output:.6,cacheRead:null,cacheWrite:null},features:["128K context window","Ultra-fast inference","Free tier"],status:"available",huggingface:"https://huggingface.co/zenlm/zen4-mini",github:"https://github.com/zenlm/zen4-mini",aliases:[]},{id:"zen4-ultra",name:"Zen4 Ultra",fullName:"Zen4 Ultra — Maximum Reasoning",description:"Maximum reasoning capability with extended chain-of-thought on MoE architecture.",generation:"zen4",tier:"ultra max",category:"flagship",modalities:["text","code","math"],spec:{params:"744B",activeParams:"40B",context:262e3,arch:"MoE + CoT"},pricing:{input:3,output:9.6,cacheRead:null,cacheWrite:null},features:["262K context window","Deep reasoning","Chain-of-thought"],status:"available",huggingface:"https://huggingface.co/zenlm/zen4-ultra",github:"https://github.com/zenlm/zen4-ultra",aliases:[]},{id:"zen4-thinking",name:"Zen4 Thinking",fullName:"Zen4 Thinking — Deep Reasoning",description:"Dedicated reasoning model with explicit chain-of-thought capabilities.",generation:"zen4",tier:"pro max",category:"flagship",modalities:["text","code","math"],spec:{params:"80B",activeParams:"3B",context:131e3,arch:"MoE + CoT"},pricing:{input:2.7,output:2.7,cacheRead:null,cacheWrite:null},features:["131K context window","Chain-of-thought"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen4-coder",name:"Zen4 Coder",fullName:"Zen4 Coder — Code Generation",description:"Code-specialized MoE model for generation, review, debugging, and agentic programming.",generation:"zen4",tier:"ultra",category:"code",modalities:["text","code"],spec:{params:"480B",activeParams:"35B",context:163e3,arch:"MoE"},pricing:{input:3.6,output:3.6,cacheRead:null,cacheWrite:null},features:["163K context window","All major languages"],status:"available",huggingface:"https://huggingface.co/zenlm/zen4-coder",github:"https://github.com/zenlm/zen4-coder",aliases:[]},{id:"zen4-coder-flash",name:"Zen4 Coder Flash",fullName:"Zen4 Coder Flash — Fast Code",description:"Lightweight code model optimized for speed and inline completions.",generation:"zen4",tier:"pro max",category:"code",modalities:["text","code"],spec:{params:"30B",activeParams:"3B",context:262e3,arch:"MoE"},pricing:{input:1.5,output:1.5,cacheRead:null,cacheWrite:null},features:["262K context window","Fast inference"],status:"available",huggingface:"https://huggingface.co/zenlm/zen4-coder-flash",github:"https://github.com/zenlm/zen4-coder-flash",aliases:[]},{id:"zen4-coder-pro",name:"Zen4 Coder Pro",fullName:"Zen4 Coder Pro — Premium Code",description:"Full-precision BF16 code model for maximum accuracy on complex codebases.",generation:"zen4",tier:"ultra max",category:"code",modalities:["text","code"],spec:{params:"480B",activeParams:null,context:131e3,arch:"Dense BF16"},pricing:{input:4.5,output:4.5,cacheRead:null,cacheWrite:null},features:["131K context window","BF16 full precision"],status:"available",huggingface:"https://huggingface.co/zenlm/zen4-coder-pro",github:"https://github.com/zenlm/zen4-coder-pro",aliases:[]},{id:"zen3-omni",name:"Zen3 Omni",fullName:"Zen3 Omni — Hypermodal",description:"Multimodal model supporting text, vision, audio, and structured output.",generation:"zen3",tier:"pro max",category:"vision",modalities:["text","vision","code"],spec:{params:"~200B",activeParams:null,context:202e3,arch:"Dense Multimodal"},pricing:{input:1.8,output:6.6,cacheRead:null,cacheWrite:null},features:["202K context window","Text + Vision + Audio"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-vl",name:"Zen3 VL",fullName:"Zen3 VL — Vision-Language",description:"Vision-language model for image understanding and visual reasoning.",generation:"zen3",tier:"pro max",category:"vision",modalities:["text","vision"],spec:{params:"30B",activeParams:"3B",context:262e3,arch:"MoE Vision-Language"},pricing:{input:.45,output:1.8,cacheRead:null,cacheWrite:null},features:["262K context window","Vision + Language"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-nano",name:"Zen3 Nano",fullName:"Zen3 Nano — Edge",description:"Ultra-lightweight model for edge deployment and low-latency tasks. Available on free tier.",generation:"zen3",tier:"pro",category:"flagship",modalities:["text","code"],spec:{params:"8B",activeParams:null,context:128e3,arch:"Dense"},pricing:{input:.3,output:.3,cacheRead:null,cacheWrite:null},features:["128K context window","8B parameters","Free tier"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-guard",name:"Zen3 Guard",fullName:"Zen3 Guard — Content Safety",description:"Content safety classifier for moderation and guardrails. 9 safety categories, 119 languages.",generation:"zen3",tier:"pro",category:"safety",modalities:["text","safety"],spec:{params:"4B",activeParams:null,context:65e3,arch:"Dense"},pricing:{input:.3,output:.3,cacheRead:null,cacheWrite:null},features:["65K context window","Safety classifier","119 languages"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-embedding",name:"Zen3 Embedding",fullName:"Zen3 Embedding — Text Embeddings",description:"High-quality text embeddings for RAG, search, and classification.",generation:"zen3",tier:"pro max",category:"embedding",modalities:["text","embedding"],spec:{params:"3072 dimensions",activeParams:null,context:8e3,arch:"Embedding"},pricing:{input:.39,output:.39,cacheRead:null,cacheWrite:null},features:["8K context window","3072 dimensions"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-embedding-medium",name:"Zen3 Embedding Medium",fullName:"Zen3 Embedding Medium",description:"Balanced embedding model for cost-effective retrieval workloads.",generation:"zen3",tier:"pro",category:"embedding",modalities:["text","embedding"],spec:{params:"4B",activeParams:null,context:4e4,arch:"Embedding"},pricing:null,features:["40K context window","4B parameters"],status:"available",huggingface:"https://huggingface.co/zenlm/zen3-embedding-medium",github:null,aliases:[]},{id:"zen3-embedding-small",name:"Zen3 Embedding Small",fullName:"Zen3 Embedding Small",description:"Lightweight embedding model for high-throughput, low-cost applications.",generation:"zen3",tier:"pro",category:"embedding",modalities:["text","embedding"],spec:{params:"0.6B",activeParams:null,context:32e3,arch:"Embedding"},pricing:null,features:["32K context window","0.6B parameters"],status:"available",huggingface:"https://huggingface.co/zenlm/zen3-embedding-small",github:null,aliases:[]},{id:"zen3-reranker",name:"Zen3 Reranker",fullName:"Zen3 Reranker",description:"High-quality reranker for improving retrieval accuracy in RAG pipelines.",generation:"zen3",tier:"pro max",category:"embedding",modalities:["text","embedding"],spec:{params:"8B",activeParams:null,context:4e4,arch:"Reranker"},pricing:null,features:["40K context window","8B parameters"],status:"available",huggingface:"https://huggingface.co/zenlm/zen3-reranker",github:null,aliases:[]},{id:"zen3-reranker-medium",name:"Zen3 Reranker Medium",fullName:"Zen3 Reranker Medium",description:"Balanced reranker for cost-effective retrieval quality improvement.",generation:"zen3",tier:"pro",category:"embedding",modalities:["text","embedding"],spec:{params:"4B",activeParams:null,context:4e4,arch:"Reranker"},pricing:null,features:["40K context window","4B parameters"],status:"available",huggingface:"https://huggingface.co/zenlm/zen3-reranker-medium",github:null,aliases:[]},{id:"zen3-reranker-small",name:"Zen3 Reranker Small",fullName:"Zen3 Reranker Small",description:"Lightweight reranker for high-throughput reranking at minimal cost.",generation:"zen3",tier:"pro",category:"embedding",modalities:["text","embedding"],spec:{params:"0.6B",activeParams:null,context:4e4,arch:"Reranker"},pricing:null,features:["40K context window","0.6B parameters"],status:"available",huggingface:"https://huggingface.co/zenlm/zen3-reranker-small",github:null,aliases:[]},{id:"zen3-image",name:"Zen3 Image",fullName:"Zen3 Image",description:"Best general-purpose image generation.",generation:"zen3",tier:"pro max",category:"vision",modalities:["vision"],spec:{params:"N/A",activeParams:null,context:0,arch:"Diffusion"},pricing:null,features:["Text-to-image","Image editing"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-image-max",name:"Zen3 Image Max",fullName:"Zen3 Image Max",description:"Maximum quality image generation for professional creative work.",generation:"zen3",tier:"ultra max",category:"vision",modalities:["vision"],spec:{params:"N/A",activeParams:null,context:0,arch:"Diffusion"},pricing:null,features:["Text-to-image","Maximum quality"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-image-dev",name:"Zen3 Image Dev",fullName:"Zen3 Image Dev",description:"Development model for experimentation and iteration.",generation:"zen3",tier:"pro",category:"vision",modalities:["vision"],spec:{params:"N/A",activeParams:null,context:0,arch:"Diffusion"},pricing:null,features:["Text-to-image","Development"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-image-fast",name:"Zen3 Image Fast",fullName:"Zen3 Image Fast",description:"Fastest image model for real-time generation.",generation:"zen3",tier:"pro",category:"vision",modalities:["vision"],spec:{params:"N/A",activeParams:null,context:0,arch:"Diffusion"},pricing:null,features:["Text-to-image","Ultra-fast"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-image-sdxl",name:"Zen3 Image SDXL",fullName:"Zen3 Image SDXL",description:"High-resolution image generation at 1024px.",generation:"zen3",tier:"pro",category:"vision",modalities:["vision"],spec:{params:"N/A",activeParams:null,context:0,arch:"Diffusion"},pricing:null,features:["Text-to-image","1024px"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-image-playground",name:"Zen3 Image Playground",fullName:"Zen3 Image Playground",description:"Aesthetic model for artistic image generation.",generation:"zen3",tier:"pro",category:"vision",modalities:["vision"],spec:{params:"N/A",activeParams:null,context:0,arch:"Diffusion"},pricing:null,features:["Text-to-image","Aesthetic"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-image-ssd",name:"Zen3 Image SSD",fullName:"Zen3 Image SSD",description:"Fastest diffusion model for real-time generation.",generation:"zen3",tier:"pro",category:"vision",modalities:["vision"],spec:{params:"1B",activeParams:null,context:0,arch:"Diffusion"},pricing:null,features:["Text-to-image","Fastest"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-image-jp",name:"Zen3 Image JP",fullName:"Zen3 Image JP",description:"Japanese-specialized image generation model.",generation:"zen3",tier:"pro",category:"vision",modalities:["vision"],spec:{params:"N/A",activeParams:null,context:0,arch:"Diffusion"},pricing:null,features:["Text-to-image","Japanese"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-audio",name:"Zen3 Audio",fullName:"Zen3 Audio",description:"Best quality speech-to-text transcription. 100+ languages.",generation:"zen3",tier:"pro max",category:"audio",modalities:["audio","text"],spec:{params:"1.5B",activeParams:null,context:0,arch:"ASR"},pricing:null,features:["Multi-language","Best accuracy","100+ languages"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-audio-fast",name:"Zen3 Audio Fast",fullName:"Zen3 Audio Fast",description:"Fastest speech-to-text transcription for high-throughput workloads.",generation:"zen3",tier:"pro",category:"audio",modalities:["audio","text"],spec:{params:"809M",activeParams:null,context:0,arch:"ASR"},pricing:null,features:["Multi-language","Fastest","Batch optimized"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-asr",name:"Zen3 ASR",fullName:"Zen3 ASR",description:"Real-time streaming speech recognition for live transcription and voice agents.",generation:"zen3",tier:"pro max",category:"audio",modalities:["audio","text"],spec:{params:"N/A",activeParams:null,context:0,arch:"Streaming ASR"},pricing:null,features:["Streaming","Real-time","Sub-500ms latency"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-asr-v1",name:"Zen3 ASR v1",fullName:"Zen3 ASR v1",description:"First-generation streaming ASR for legacy compatibility.",generation:"zen3",tier:"pro",category:"audio",modalities:["audio","text"],spec:{params:"N/A",activeParams:null,context:0,arch:"Streaming ASR"},pricing:null,features:["Streaming","Legacy"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-tts",name:"Zen3 TTS",fullName:"Zen3 TTS",description:"High-quality text-to-speech with natural prosody. 40+ voices, 8 languages.",generation:"zen3",tier:"pro max",category:"audio",modalities:["audio","text"],spec:{params:"82M",activeParams:null,context:0,arch:"TTS"},pricing:null,features:["40+ voices","8 languages","Natural prosody"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-tts-hd",name:"Zen3 TTS HD",fullName:"Zen3 TTS HD",description:"Maximum fidelity text-to-speech for broadcast-quality audio production.",generation:"zen3",tier:"ultra max",category:"audio",modalities:["audio","text"],spec:{params:"N/A",activeParams:null,context:0,arch:"TTS HD"},pricing:null,features:["HD quality","Broadcast-grade","48kHz output"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen3-tts-fast",name:"Zen3 TTS Fast",fullName:"Zen3 TTS Fast",description:"Low-latency text-to-speech for real-time voice agents and interactive applications.",generation:"zen3",tier:"pro",category:"audio",modalities:["audio","text"],spec:{params:"82M",activeParams:null,context:0,arch:"TTS"},pricing:null,features:["Low latency","Real-time","Voice agents"],status:"available",huggingface:null,github:null,aliases:[]},{id:"zen5",name:"Zen5",fullName:"Zen5 — Next Generation",description:"Next-generation agentic frontier model trained on 10B+ tokens of real-world tool use, multi-step reasoning, and production workflows. 1M+ token context with native chain-of-thought.",generation:"zen5",tier:"ultra max",category:"flagship",modalities:["text","code","math"],spec:{params:"TBA",activeParams:null,context:1048576,arch:"MoDE + CoT"},pricing:null,features:["1M+ context window","Agentic-trained","Native CoT","Tool use","Multimodal native"],status:"contact-sales",huggingface:null,github:null,aliases:[]},{id:"zen5-pro",name:"Zen5 Pro",fullName:"Zen5 Pro — Advanced",description:"High-throughput agentic model for demanding production workloads. Trained on real-world development patterns with deep chain-of-thought reasoning.",generation:"zen5",tier:"ultra",category:"flagship",modalities:["text","code","math"],spec:{params:"TBA",activeParams:null,context:524288,arch:"MoDE + CoT"},pricing:null,features:["512K context window","Agentic-trained","Native CoT","Production optimized"],status:"contact-sales",huggingface:null,github:null,aliases:[]},{id:"zen5-max",name:"Zen5 Max",fullName:"Zen5 Max — Extended",description:"Maximum context agentic model for document-scale analysis. Trained on 10B+ tokens of real-world workflows with extended chain-of-thought.",generation:"zen5",tier:"ultra max",category:"flagship",modalities:["text","code","math"],spec:{params:"TBA",activeParams:null,context:2097152,arch:"MoDE + CoT"},pricing:null,features:["2M context window","Agentic-trained","Extended CoT","Document-scale"],status:"contact-sales",huggingface:null,github:null,aliases:[]},{id:"zen5-ultra",name:"Zen5 Ultra",fullName:"Zen5 Ultra — Deep Reasoning",description:"Deepest reasoning model in the Zen family. Multi-pass chain-of-thought with self-verification.",generation:"zen5",tier:"ultra max",category:"flagship",modalities:["text","code","math"],spec:{params:"TBA",activeParams:null,context:1048576,arch:"MoDE + Deep CoT"},pricing:null,features:["1M context window","Agentic-trained","Deep CoT","Self-verification"],status:"contact-sales",huggingface:null,github:null,aliases:[]},{id:"zen5-mini",name:"Zen5 Mini",fullName:"Zen5 Mini — Efficient",description:"Efficient agentic model delivering zen5-class intelligence at a fraction of the cost.",generation:"zen5",tier:"pro",category:"flagship",modalities:["text","code","math"],spec:{params:"TBA",activeParams:null,context:262144,arch:"MoDE + CoT"},pricing:null,features:["256K context window","Agentic-trained","Native CoT","Cost efficient"],status:"contact-sales",huggingface:null,github:null,aliases:[]},{id:"zen-nano",name:"Zen Nano",fullName:"Zen Nano — 0.6B Edge",description:"Ultra-lightweight LLM for edge and mobile deployment.",generation:"foundation",tier:"pro",category:"foundation",modalities:["text","code","math"],spec:{params:"0.6B",activeParams:null,context:32e3,arch:"Dense"},pricing:null,features:["32K context","44K tokens/sec","0.4–1.2GB memory"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-nano-0.6b",github:null,aliases:[]},{id:"zen-eco",name:"Zen Eco",fullName:"Zen Eco — 4B Efficient",description:"Efficient 4B model for general-purpose tasks.",generation:"foundation",tier:"pro",category:"foundation",modalities:["text","code","math"],spec:{params:"4B",activeParams:null,context:32e3,arch:"Dense"},pricing:null,features:["32K context","33K tokens/sec","2–8GB memory"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-eco-4b",github:null,aliases:[]},{id:"zen",name:"Zen",fullName:"Zen — 8-32B Standard",description:"Standard model available in 8B and 32B variants.",generation:"foundation",tier:"pro",category:"foundation",modalities:["text","code","math"],spec:{params:"8–32B",activeParams:null,context:32e3,arch:"Dense"},pricing:null,features:["32K context","28K tokens/sec","4–64GB memory"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-8b",github:null,aliases:[]},{id:"zen-pro",name:"Zen Pro",fullName:"Zen Pro — 32B Professional",description:"Professional-grade 32B dense model for demanding workloads.",generation:"foundation",tier:"pro max",category:"foundation",modalities:["text","code","math"],spec:{params:"32B",activeParams:null,context:32e3,arch:"Dense"},pricing:null,features:["32K context","19K tokens/sec","16–64GB memory"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-pro-32b",github:null,aliases:[]},{id:"zen-max",name:"Zen Max",fullName:"Zen Max — 235B MoE",description:"High-capability MoE model with 235B parameters.",generation:"foundation",tier:"ultra",category:"foundation",modalities:["text","code","math"],spec:{params:"235B",activeParams:"22B",context:131e3,arch:"MoE"},pricing:null,features:["131K context","14K tokens/sec","48–128GB memory"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-max",github:"https://github.com/zenlm/zen-max",aliases:[]},{id:"zen-next",name:"Zen Next",fullName:"Zen Next — Preview",description:"Next-generation preview model with cutting-edge capabilities.",generation:"foundation",tier:"ultra max",category:"foundation",modalities:["text","code","math"],spec:{params:"TBD",activeParams:null,context:256e3,arch:"Dense"},pricing:null,features:["256K context","Preview"],status:"preview",huggingface:null,github:null,aliases:[]},{id:"zen-coder",name:"Zen Coder",fullName:"Zen Coder — Code Generation",description:"Baseline code model for generation and completions.",generation:"foundation",tier:"pro max",category:"code",modalities:["text","code"],spec:{params:"32B",activeParams:null,context:131e3,arch:"Dense"},pricing:null,features:["131K context","Multi-language"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-coder",github:null,aliases:[]},{id:"zen-coder-flash",name:"Zen Coder Flash",fullName:"Zen Coder Flash — Fast Code",description:"Fast code model for inline completions and suggestions.",generation:"foundation",tier:"pro",category:"code",modalities:["text","code"],spec:{params:"7B",activeParams:null,context:32e3,arch:"Dense"},pricing:null,features:["32K context","Low latency"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-coder-flash",github:null,aliases:[]},{id:"zen-code",name:"Zen Code",fullName:"Zen Code — Legacy Code",description:"Legacy code model (superseded by Zen4 Coder series).",generation:"foundation",tier:"pro",category:"code",modalities:["text","code"],spec:{params:"14B",activeParams:null,context:32e3,arch:"Dense"},pricing:null,features:["32K context"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-code",github:null,aliases:[]},{id:"zen-vl",name:"Zen VL",fullName:"Zen VL — Vision-Language",description:"Multi-modal vision-language model for image understanding.",generation:"foundation",tier:"pro max",category:"vision",modalities:["text","vision"],spec:{params:"32B",activeParams:null,context:32e3,arch:"Dense Multimodal"},pricing:null,features:["32K context","Image understanding"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-vl",github:null,aliases:[]},{id:"zen-omni",name:"Zen Omni",fullName:"Zen Omni — Multimodal",description:"Hypermodal model combining text, vision, audio, and code.",generation:"foundation",tier:"ultra",category:"vision",modalities:["text","vision","audio","code"],spec:{params:"72B",activeParams:null,context:131e3,arch:"Dense Multimodal"},pricing:null,features:["131K context","Multimodal"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-omni",github:null,aliases:[]},{id:"zen-guard",name:"Zen Guard",fullName:"Zen Guard — Content Safety",description:"Content safety and moderation classifier.",generation:"foundation",tier:"pro",category:"safety",modalities:["text","safety"],spec:{params:"8B",activeParams:null,context:32e3,arch:"Dense"},pricing:null,features:["Content moderation","Guardrails"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-guard",github:null,aliases:[]},{id:"zen-embedding",name:"Zen Embedding",fullName:"Zen Embedding — Text Embeddings",description:"Foundation embedding model for search and retrieval.",generation:"foundation",tier:"pro",category:"embedding",modalities:["text","embedding"],spec:{params:"3072 dimensions",activeParams:null,context:8e3,arch:"Embedding"},pricing:null,features:["3072 dimensions","Cosine similarity"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-embedding",github:null,aliases:[]},{id:"zen-reranker",name:"Zen Reranker",fullName:"Zen Reranker — Search Reranking",description:"Cross-encoder reranker for search result quality.",generation:"foundation",tier:"pro",category:"embedding",modalities:["text","embedding"],spec:{params:"568M",activeParams:null,context:8e3,arch:"Reranker"},pricing:null,features:["Cross-encoder","Search reranking"],status:"available",huggingface:"https://huggingface.co/zenlm/zen-reranker",github:null,aliases:[]},{id:"zen-agent",name:"Zen Agent",fullName:"Zen Agent — Agentic AI",description:"Agent-optimized model for multi-step tool use and planning.",generation:"foundation",tier:"ultra",category:"agents",modalities:["text","code","agents"],spec:{params:"32B",activeParams:null,context:131e3,arch:"Dense"},pricing:null,features:["Tool use","Multi-step planning"],status:"preview",huggingface:null,github:null,aliases:[]}];a.filter(e=>null!==e.pricing),a.filter(e=>null!==e.huggingface),a.filter(e=>"zen4"===e.generation),a.filter(e=>"zen3"===e.generation),a.filter(e=>"zen5"===e.generation),a.filter(e=>"foundation"===e.generation),a.flatMap(e=>[[e.id,e],...e.aliases.map(a=>[a,e])]),e.s(["allModels",()=>a],91846);var t=[{id:"zen5",name:"Zen 5",description:"Next-generation agentic models with native chain-of-thought.",icon:"Rocket",models:["zen5","zen5-pro","zen5-max","zen5-ultra","zen5-mini"]},{id:"zen4",name:"Zen 4",description:"Latest generation production models with MoDE architecture.",icon:"Sparkles",models:["zen4-max","zen4.1","zen4","zen4-ultra","zen4-pro","zen4-thinking","zen4-mini"]},{id:"code",name:"Code",description:"Specialized models for code generation, review, and debugging.",icon:"Code",models:["zen4-coder","zen4-coder-flash","zen4-coder-pro","zen-coder","zen-coder-flash","zen-code"]},{id:"zen3",name:"Zen 3",description:"Previous generation API models — language, vision, multimodal, and safety.",icon:"Eye",models:["zen3-omni","zen3-vl","zen3-nano","zen3-guard"]},{id:"embedding",name:"Embedding & Retrieval",description:"Text embeddings and search reranking via API.",icon:"Search",models:["zen3-embedding","zen3-embedding-medium","zen3-embedding-small","zen3-reranker","zen3-reranker-medium","zen3-reranker-small","zen-embedding","zen-reranker"]},{id:"image",name:"Image Generation",description:"Text-to-image generation via API.",icon:"Image",models:["zen3-image","zen3-image-max","zen3-image-dev","zen3-image-fast","zen3-image-sdxl","zen3-image-playground","zen3-image-ssd","zen3-image-jp"]},{id:"audio",name:"Audio & Speech",description:"Speech-to-text, text-to-speech, and streaming ASR.",icon:"Mic",models:["zen3-audio","zen3-audio-fast","zen3-asr","zen3-asr-v1","zen3-tts","zen3-tts-hd","zen3-tts-fast"]},{id:"foundation",name:"Foundation",description:"General-purpose open-weight models from 0.6B to 235B parameters.",icon:"Brain",models:["zen-nano","zen-eco","zen","zen-pro","zen-max","zen-next"]},{id:"vision",name:"Vision (Open Weights)",description:"Vision-language and multimodal open-weight models.",icon:"Eye",models:["zen-vl","zen-omni"]},{id:"safety",name:"Safety",description:"Content moderation and safety guardrail models.",icon:"Shield",models:["zen3-guard","zen-guard"]},{id:"agents",name:"Agents",description:"Agent-optimized models for tool use and planning.",icon:"Network",models:["zen-agent"]}];e.s(["families",()=>t],82874),e.s([],58171)}]);