<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Research | Zen LM</title><meta name=keywords content><meta name=description content="Zen LM — Frontier open models from Hanzo AI and Zoo Labs Foundation"><meta name=author content="Zen LM Team"><link rel=canonical href=https://zenlm.org/tags/research/><link crossorigin=anonymous href=/assets/css/stylesheet.6c0865a4bc8dbcbd27d78777eb33b404568f7fbf3185cca7b978e5275a4dd049.css integrity="sha256-bAhlpLyNvL0n14d36zO0BFaPf78xhcynuXjlJ1pN0Ek=" rel="preload stylesheet" as=style><link rel=icon href=https://zenlm.org/favicon.png><link rel=apple-touch-icon href=https://zenlm.org/favicon.png><link rel=manifest href=https://zenlm.org/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate type=application/rss+xml href=https://zenlm.org/tags/research/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script><meta property="og:title" content="Research"><meta property="og:description" content="Zen LM — Frontier open models from Hanzo AI and Zoo Labs Foundation"><meta property="og:type" content="website"><meta property="og:url" content="https://zenlm.org/tags/research/"><meta property="og:image" content="https://zenlm.org/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Zen LM"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://zenlm.org/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Research"><meta name=twitter:description content="Zen LM — Frontier open models from Hanzo AI and Zoo Labs Foundation"></head><body class=list id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="Zen LM (Alt + H)"><img src=https://zenlm.org/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://zeekay.blog title=zeekay><span>zeekay</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://hanzo.blog title=hanzo.blog><span>hanzo.blog</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://hanzo.ai/chat title="Try Zen Chat"><span>Try Zen Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://blog.zoo.ngo title="zoo blog"><span>zoo blog</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero><h1 class=post-title>Research</h1></div></div><main class=main><article class="post-entry tag-entry"><header class=entry-header><h2>GT-QLoRA: Uncensoring Trillion-Parameter MoE Models</h2></header><div class=entry-content><p>ZEN4-ULTRA TRAINER ZEN4-ULTRA WEIGHTS ZEN4-ULTRA GGUF
Standard abliteration works on dense models. It fails on Mixture-of-Experts. This post explains why, and how Gate-Targeted QLoRA (GT-QLoRA) — the technique we developed for zen4-ultra — addresses the fundamental architectural mismatch.
This is a technical post about a hard problem. We are not publishing this because we have solved it cleanly. We are publishing it because the failure mode of naive approaches is subtle and poorly documented, and other researchers building on MoE architectures need to understand it....</p></div><footer class=entry-footer><span title='2026-02-28 13:00:00 -0800 -0800'>February 28, 2026</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;1599 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to GT-QLoRA: Uncensoring Trillion-Parameter MoE Models" href=https://zenlm.org/blog/gt-qlora-moe-abliteration/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Drop-Upcycling and the Birth of Zen MoDE Architecture</h2></header><div class=entry-content><p>DROP-UPCYCLING PAPER ZEN MODELS ZEN CODE
Mixture of Experts (MoE) is the architecture that makes trillion-parameter models economically viable. By routing each token through a small subset of expert networks rather than the full parameter set, MoE achieves large-model quality at dense-model inference cost. The problem: training an MoE from scratch is expensive. You are paying for both the scale and the specialization overhead.
Drop-Upcycling is a technique that converts a trained dense checkpoint into an MoE at roughly 1/4 the training cost of building the MoE from scratch....</p></div><footer class=entry-footer><span title='2026-02-28 12:00:00 -0800 -0800'>February 28, 2026</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1443 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to Drop-Upcycling and the Birth of Zen MoDE Architecture" href=https://zenlm.org/blog/drop-upcycling-zen-mode/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>BitDelta: 1-Bit Behavioral Compression Across the Zen Model Family</h2></header><div class=entry-content><p>BITDELTA PAPER MONOSOUP PAPER K-MERGE PAPER ZEN MODELS
The Zen model family has a deployment problem that is not immediately obvious from the outside. We publish 14+ distinct model variants — from zen-nano at 0.6B parameters to zen4-ultra at 1.04T. Each variant carries fine-tuned behavioral characteristics: different personas, different task specializations, different safety postures. In a naive serving architecture, each variant is a separate set of weights. Loading all of them onto a GPU cluster is economically impossible....</p></div><footer class=entry-footer><span title='2026-02-28 11:00:00 -0800 -0800'>February 28, 2026</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1345 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to BitDelta: 1-Bit Behavioral Compression Across the Zen Model Family" href=https://zenlm.org/blog/bitdelta-behavioral-compression/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>SuRe + OPCM: Production-Grade Continual Learning for Open Models</h2></header><div class=entry-content><p>OPLoRA PAPER SuRe PAPER OPCM PAPER YOUTU-AGENT PAPER
Every production LLM faces the same brutal constraint: the moment you start adapting a model on new data, it begins forgetting what it already knew. This is catastrophic forgetting — and it is not a theoretical concern. It is the reason most “continually updated” models in production are quietly replaced wholesale every few months rather than genuinely updated in place.
For the Zen model family, wholesale replacement is not acceptable....</p></div><footer class=entry-footer><span title='2026-02-28 10:00:00 -0800 -0800'>February 28, 2026</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;1602 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to SuRe + OPCM: Production-Grade Continual Learning for Open Models" href=https://zenlm.org/blog/continual-learning-sure-opcm/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Proof of AI: Verifiable Machine Learning on Chain</h2></header><div class=entry-content><p>When an AI system makes a prediction, how do you know it actually ran the model it claims? In centralized systems, you trust the operator. Decentralized AI needs cryptographic proof.
Today we introduce Proof of AI (PoAI), a framework for verifiable machine learning inference.
The Trust Problem Consider a decentralized AI service:
User submits input and payment Compute provider runs inference Provider returns output User receives result What prevents the provider from:...</p></div><footer class=entry-footer><span title='2023-06-26 09:00:00 -0800 -0800'>June 26, 2023</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;614 words&nbsp;·&nbsp;Zach Kelling</footer><a class=entry-link aria-label="post link to Proof of AI: Verifiable Machine Learning on Chain" href=https://zenlm.org/blog/proof-of-ai/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://zenlm.org/tags/research/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2026 <a href=https://zenlm.org/>Zen LM</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script></body></html>