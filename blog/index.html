<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta http-equiv=refresh content="5; url=https://qwen.ai/research"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Blog | Qwen</title><meta name=keywords content><meta name=description content="Blog - Qwen"><meta name=author content="Qwen Team"><link rel=canonical href=https://qwenlm.github.io/blog/><link crossorigin=anonymous href=/assets/css/stylesheet.6c0865a4bc8dbcbd27d78777eb33b404568f7fbf3185cca7b978e5275a4dd049.css integrity="sha256-bAhlpLyNvL0n14d36zO0BFaPf78xhcynuXjlJ1pN0Ek=" rel="preload stylesheet" as=style><link rel=icon href=https://qwenlm.github.io/favicon.png><link rel=apple-touch-icon href=https://qwenlm.github.io/favicon.png><link rel=manifest href=https://qwenlm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate type=application/rss+xml href=https://qwenlm.github.io/blog/index.xml><link rel=alternate hreflang=en href=https://qwenlm.github.io/blog/><link rel=alternate hreflang=zh href=https://qwenlm.github.io/zh/blog/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script><meta property="og:title" content="Blog"><meta property="og:description" content="Qwen"><meta property="og:type" content="website"><meta property="og:url" content="https://qwenlm.github.io/blog/"><meta property="og:image" content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Blog"><meta name=twitter:description content="Qwen"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://qwenlm.github.io/blog/"}]}</script></head><body class=list id=top><script>const hasHeaderBg=!0</script><style>.modal-overlay{position:fixed;top:0;left:0;width:100%;height:100%;background-color:rgba(0,0,0,.5);display:flex;align-items:center;z-index:1000;animation:fadeIn .3s ease-in-out}.modal-container{margin-left:auto;margin-right:auto;background-color:var(--theme);border-radius:8px;box-shadow:0 4px 20px rgba(0,0,0,.15);width:90%;max-width:420px;height:fit-content;padding:30px;text-align:center;position:relative;animation:slideIn .4s ease-out}.modal-container a{color:var(--hero2)}.modal-icon{width:70px;height:70px;background-color:#f0f7ff;border-radius:50%;display:flex;align-items:center;justify-content:center;margin:0 auto 20px;color:#1a73e8;font-size:30px}.modal-title{font-size:1.5rem;font-weight:600;color:var(--primary);margin:0 0 15px}.modal-message{font-size:1rem;color:var(--secondary);line-height:1.5;margin:0 0 25px}.countdown{font-size:1.2rem;color:#666;margin:20px 0;font-weight:500}.modal-buttons{display:flex;justify-content:center;gap:15px;margin-top:25px}.modal-buttons .btn{padding:6px 16px;border-radius:8px;font-size:1.2rem;font-weight:500;cursor:pointer;transition:all .3s ease;border:none}.btn-primary{background-color:#1a73e8;color:#fff}.btn-primary:hover{background-color:#1557b0}.btn-secondary{background-color:#f1f3f4;color:#333}.btn-secondary:hover{background-color:#e0e0e0}@keyframes fadeIn{from{opacity:0}to{opacity:1}}@keyframes slideIn{from{opacity:0;transform:translateY(-50px)}to{opacity:1;transform:translateY(0)}}@media(max-width:480px){.modal-container{max-width:95%;width:calc(95vw - 40px);padding:20px}}</style><div class=modal-overlay><div class=modal-container><div class=modal-icon><svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"/></svg></div><h2 class=modal-title>We have a new blog at <a href=https://qwen.ai/research>qwen.ai</a>!</h2><p class=modal-message>This page will automatically redirect in <span class=countdown id=countdown>5</span> seconds.</p><p class=modal-message>If you are not redirected automatically, please click the button below.</p><div class=modal-buttons><button class="btn btn-primary" onclick=redirectToPage()>Go Now</button></div></div></div><script>let countdown=5;const countdownElement=document.getElementById("countdown"),timer=setInterval(()=>{countdown--,countdownElement.textContent=countdown,countdown<=0&&clearInterval(timer)},1e3);function stayHere(){document.querySelector(".modal-overlay").style.display="none"}function redirectToPage(){window.location.href="https://qwen.ai/research"}</script><header class=header><div class="nav-container nav-background"><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><img src=https://qwenlm.github.io/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span class=active>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://chat.qwen.ai title="Try Qwen Chat"><span>Try Qwen Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero-background style="background:linear-gradient(-225deg,#2CD8D5 0%,#6B8DD6 48%,#8E37D7 100%)"></div><div class="hero text-light"><h1 class=post-title>Blog<sup class=title-translation>&nbsp;&nbsp;[<ul class=i18n_list><li><a href=https://qwenlm.github.io/zh/blog/>简体中文</a></li></ul>]</sup></h1></div></div><main class=main><article class=post-entry><header class=entry-header><h2>GT-QLoRA: Uncensoring Trillion-Parameter MoE Models</h2></header><div class=entry-content><p>ZEN4-ULTRA TRAINER ZEN4-ULTRA WEIGHTS ZEN4-ULTRA GGUF
Standard abliteration works on dense models. It fails on Mixture-of-Experts. This post explains why, and how Gate-Targeted QLoRA (GT-QLoRA) — the technique we developed for zen4-ultra — addresses the fundamental architectural mismatch.
This is a technical post about a hard problem. We are not publishing this because we have solved it cleanly. We are publishing it because the failure mode of naive approaches is subtle and poorly documented, and other researchers building on MoE architectures need to understand it....</p></div><footer class=entry-footer><span title='2026-02-28 13:00:00 -0800 -0800'>February 28, 2026</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;1599 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to GT-QLoRA: Uncensoring Trillion-Parameter MoE Models" href=https://qwenlm.github.io/blog/gt-qlora-moe-abliteration/></a></article><article class=post-entry><header class=entry-header><h2>Drop-Upcycling and the Birth of Zen MoDE Architecture</h2></header><div class=entry-content><p>DROP-UPCYCLING PAPER ZEN MODELS ZEN CODE
Mixture of Experts (MoE) is the architecture that makes trillion-parameter models economically viable. By routing each token through a small subset of expert networks rather than the full parameter set, MoE achieves large-model quality at dense-model inference cost. The problem: training an MoE from scratch is expensive. You are paying for both the scale and the specialization overhead.
Drop-Upcycling is a technique that converts a trained dense checkpoint into an MoE at roughly 1/4 the training cost of building the MoE from scratch....</p></div><footer class=entry-footer><span title='2026-02-28 12:00:00 -0800 -0800'>February 28, 2026</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1443 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Drop-Upcycling and the Birth of Zen MoDE Architecture" href=https://qwenlm.github.io/blog/drop-upcycling-zen-mode/></a></article><article class=post-entry><header class=entry-header><h2>BitDelta: 1-Bit Behavioral Compression Across the Zen Model Family</h2></header><div class=entry-content><p>BITDELTA PAPER MONOSOUP PAPER K-MERGE PAPER ZEN MODELS
The Zen model family has a deployment problem that is not immediately obvious from the outside. We publish 14+ distinct model variants — from zen-nano at 0.6B parameters to zen4-ultra at 1.04T. Each variant carries fine-tuned behavioral characteristics: different personas, different task specializations, different safety postures. In a naive serving architecture, each variant is a separate set of weights. Loading all of them onto a GPU cluster is economically impossible....</p></div><footer class=entry-footer><span title='2026-02-28 11:00:00 -0800 -0800'>February 28, 2026</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1345 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to BitDelta: 1-Bit Behavioral Compression Across the Zen Model Family" href=https://qwenlm.github.io/blog/bitdelta-behavioral-compression/></a></article><article class=post-entry><header class=entry-header><h2>SuRe + OPCM: Production-Grade Continual Learning for Open Models</h2></header><div class=entry-content><p>OPLoRA PAPER SuRe PAPER OPCM PAPER YOUTU-AGENT PAPER
Every production LLM faces the same brutal constraint: the moment you start adapting a model on new data, it begins forgetting what it already knew. This is catastrophic forgetting — and it is not a theoretical concern. It is the reason most “continually updated” models in production are quietly replaced wholesale every few months rather than genuinely updated in place.
For the Zen model family, wholesale replacement is not acceptable....</p></div><footer class=entry-footer><span title='2026-02-28 10:00:00 -0800 -0800'>February 28, 2026</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;1602 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to SuRe + OPCM: Production-Grade Continual Learning for Open Models" href=https://qwenlm.github.io/blog/continual-learning-sure-opcm/></a></article><article class=post-entry><header class=entry-header><h2>Qwen3Guard: Real-time Safety for Your Token Stream</h2></header><div class=entry-content><p>Tech Report GitHub Hugging Face ModelScope DISCORD
Introduction We are excited to introduce Qwen3Guard, the first safety guardrail model in the Qwen family. Built upon the powerful Qwen3 foundation models and fine-tuned specifically for safety classificatoin, Qwen3Guard ensures responsible AI interactions by delivering precise safety detection for both prompts and responses, complete with risk levels and categorized classifications for accurate moderation.
Qwen3Guard achieves state-of-the-art performance on major safety benchmarks, demonstrating strong capabilities in both prompt and response classification tasks across English, Chinese, and multilingual environments....</p></div><footer class=entry-footer><span title='2025-09-23 04:00:00 +0800 +0800'>September 23, 2025</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1470 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen3Guard: Real-time Safety for Your Token Stream" href=https://qwenlm.github.io/blog/qwen3guard/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://qwenlm.github.io/blog/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2026 <a href=https://qwenlm.github.io/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script></body></html>