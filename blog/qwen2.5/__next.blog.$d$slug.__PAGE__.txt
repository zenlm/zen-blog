1:"$Sreact.fragment"
2:I[10086,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/8de849ca74fc071f.js","/_next/static/chunks/e62b91212ee7f8ff.js","/_next/static/chunks/f19fe44237e54646.js","/_next/static/chunks/cb0a883bafeb6805.js"],""]
3:I[48068,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/8de849ca74fc071f.js","/_next/static/chunks/e62b91212ee7f8ff.js","/_next/static/chunks/f19fe44237e54646.js","/_next/static/chunks/cb0a883bafeb6805.js"],"default"]
33:I[51504,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/8de849ca74fc071f.js","/_next/static/chunks/e62b91212ee7f8ff.js","/_next/static/chunks/f19fe44237e54646.js","/_next/static/chunks/cb0a883bafeb6805.js"],"CodeBlock"]
35:I[51504,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/8de849ca74fc071f.js","/_next/static/chunks/e62b91212ee7f8ff.js","/_next/static/chunks/f19fe44237e54646.js","/_next/static/chunks/cb0a883bafeb6805.js"],"Pre"]
4b:I[89923,["/_next/static/chunks/4d80e004cf4896dd.js","/_next/static/chunks/350ee4303b732916.js"],"OutletBoundary"]
4c:"$Sreact.suspense"
0:{"buildId":"i-dnJM_MIpJSOCQWNJVMq","rsc":["$","$1","c",{"children":[["$","main",null,{"className":"mx-auto w-full max-w-2xl px-4 py-16","children":[["$","$L2",null,{"href":"/blog","className":"inline-flex items-center gap-1.5 text-sm text-fd-muted-foreground hover:text-fd-foreground mb-10 transition-colors","children":"‚Üê Back to Blog"}],["$","div",null,{"className":"mb-8","children":[["$","time",null,{"className":"text-xs font-mono text-fd-muted-foreground uppercase tracking-wider","children":"September 18, 2024"}],["$","h1",null,{"className":"text-3xl font-bold mt-2 mb-3","children":"zen: A Party of Foundation Models!"}],["$","p",null,{"className":"text-fd-muted-foreground text-lg mb-4","children":"GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD"}],["$","div",null,{"className":"flex items-center gap-3 pt-4 border-t border-fd-border","children":[["$","span",null,{"className":"text-sm text-fd-muted-foreground","children":["By ","Zen LM Team"]}],["$","div",null,{"className":"flex gap-1.5 ml-auto","children":[]}]]}]]}],["$","div",null,{"className":"prose dark:prose-invert max-w-none","children":[["$","p",null,{"children":[["$","$L3",null,{"href":"https://github.com/QwenLM/zen","children":"GITHUB"}]," ",["$","$L3",null,{"href":"https://huggingface.co/Qwen","children":"HUGGING FACE"}]," ",["$","$L3",null,{"href":"https://modelscope.cn/organization/qwen","children":"MODELSCOPE"}]," ",["$","$L3",null,{"href":"https://huggingface.co/spaces/Qwen/zen","children":"DEMO"}]," ",["$","$L3",null,{"href":"https://discord.gg/yPEP2vHTu4","children":"DISCORD"}]]}],"\n",["$","h1",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"introduction","children":[["$","a",null,{"data-card":"","href":"#introduction","className":"peer","children":"Introduction"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}],"\n",["$","p",null,{"children":["In the past three months since zen‚Äôs release, numerous developers have built new models on the zen language models, providing us with valuable feedback. During this period, we have focused on creating smarter and more knowledgeable language models. Today, we are excited to introduce the latest addition to the Qwen family: ",["$","strong",null,{"children":"zen"}],". We are announcing what might be the largest opensource release in history! Let‚Äôs get the party started!"]}],"\n",["$","p",null,{"children":["Our latest release features the LLMs ",["$","strong",null,{"children":"zen"}]," , along with specialized models for coding, ",["$","strong",null,{"children":"zen-Coder"}]," , and mathematics, ",["$","strong",null,{"children":"zen-Math"}],". All open-weight models are dense, decoder-only language models, available in various sizes, including:"]}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"zen: 0.5B, 1.5B, 3B, 7B, 14B, 32B, and 72B"}],"\n",["$","li",null,{"children":"zen-Coder: 1.5B, 7B, and 32B on the way"}],"\n",["$","li",null,{"children":"zen-Math: 1.5B, 7B, and 72B."}],"\n"]}],"\n",["$","p",null,{"children":["All our open-source models, except for the 3B and 72B variants, are licensed under Apache 2.0. You can find the license files in the respective Hugging Face repositories. In addition to these models, we offer APIs for our flagship language models: ",["$","strong",null,{"children":"Qwen-Plus"}]," and ",["$","strong",null,{"children":"Qwen-Turbo"}]," through Model Studio, and we encourage you to explore them! Furthermore, we have also open-sourced the ",["$","strong",null,{"children":"zen-VL-72B"}]," , which features performance enhancements compared to last month‚Äôs release."]}],"\n","$L4","\n","$L5","\n","$L6","\n","$L7","\n","$L8","\n","$L9","\n","$La","\n","$Lb","\n","$Lc","\n","$Ld","\n","$Le","\n","$Lf","\n","$L10","\n","$L11","\n","$L12","\n","$L13","\n","$L14","\n","$L15","\n","$L16","\n","$L17","\n","$L18","\n","$L19","\n","$L1a","\n","$L1b","\n","$L1c","\n","$L1d","\n","$L1e","\n","$L1f","\n","$L20","\n","$L21","\n","$L22","\n","$L23","\n","$L24","\n","$L25","\n","$L26","\n","$L27","\n","$L28","\n","$L29","\n","$L2a","\n","$L2b","\n","$L2c","\n","$L2d"]}]]}],["$L2e","$L2f","$L30","$L31"],"$L32"]}],"loading":null,"isPartial":false}
4:["$","p",null,{"children":"For more details about zen, zen-Coder, and zen-Math, feel free to visit the following links:"}]
5:["$","p",null,{"children":[["$","$L3",null,{"href":"https://qwenlm.github.io/blog/qwen3-llm","children":"zen LLM"}]," ",["$","$L3",null,{"href":"https://qwenlm.github.io/blog/qwen3-coder","children":"zen-Coder"}]," ",["$","$L3",null,{"href":"https://qwenlm.github.io/blog/qwen3-math","children":"zen-Math"}]]}]
6:["$","p",null,{"children":"Get ready to unlock a world of possibilities with our extensive lineup of models! We‚Äôre excited to share these cutting-edge models with you, and we can‚Äôt wait to see the incredible things you‚Äôll achieve with them!"}]
7:["$","h1",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"takeaways","children":[["$","a",null,{"data-card":"","href":"#takeaways","className":"peer","children":"Takeaways"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
8:["$","p",null,{"children":["In terms of ",["$","strong",null,{"children":"zen"}]," , the language models, all models are pretrained on our latest large-scale dataset, encompassing up to ",["$","strong",null,{"children":"18 trillion"}]," tokens. Compared to zen, zen has acquired significantly more knowledge (MMLU: 85+) and has greatly improved capabilities in coding (HumanEval 85+) and mathematics (MATH 80+). Additionally, the new models achieve significant improvements in instruction following, generating long texts (over 8K tokens), understanding structured data (e.g, tables), and generating structured outputs especially JSON. zen models are generally more resilient to the diversity of system prompts, enhancing role-play implementation and condition-setting for chatbots. Like zen, the zen language models support up to ",["$","strong",null,{"children":"128K"}]," tokens and can generate up to ",["$","strong",null,{"children":"8K"}]," tokens. They also maintain multilingual support for over ",["$","strong",null,{"children":"29"}]," languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more. Below, we provide basic information about the models and details of the supported languages."]}]
9:["$","p",null,{"children":["The specialized expert language models, namely ",["$","strong",null,{"children":"zen-Coder"}]," for coding and ",["$","strong",null,{"children":"zen-Math"}]," for mathematics, have undergone substantial enhancements compared to their predecessors, CodeQwen1.5 and zen-Math. Specifically, zen-Coder has been trained on ",["$","strong",null,{"children":"5.5 trillion"}]," tokens of code-related data, enabling even smaller coding-specific models to deliver competitive performance against larger language models on coding evaluation benchmarks. Meanwhile, zen-Math supports both ",["$","strong",null,{"children":"Chinese"}]," and ",["$","strong",null,{"children":"English"}]," and incorporates various reasoning methods, including Chain-of-Thought (CoT), Program-of-Thought (PoT), and Tool-Integrated Reasoning (TIR)."]}]
a:["$","h1",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"performance","children":[["$","a",null,{"data-card":"","href":"#performance","className":"peer","children":"Performance"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
b:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"zen","children":[["$","a",null,{"data-card":"","href":"#zen","className":"peer","children":"zen"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
c:["$","p",null,{"children":["To showcase zen‚Äôs capabilities, we benchmark our largest open-source model, ",["$","strong",null,{"children":"zen-72B"}]," - a 72B-parameter dense decoder-only language model - against leading open-source models like Llama-3.1-70B and Mistral-Large-V2. We present comprehensive results from instruction-tuned versions across various benchmarks, evaluating both model capabilities and human preferences."]}]
d:["$","p",null,{"children":"Besides the instruction-tuned language models, we figure out that the base language model of our flagship opensource model zen-72B reaches top-tier performance even against larger models like Llama-3-405B."}]
e:["$","p",null,{"children":["Furthermore, we benchmark the latest version of our API-based model, ",["$","strong",null,{"children":"Qwen-Plus"}]," , against leading proprietary and open-source models, including GPT4-o, Claude-3.5-Sonnet, Llama-3.1-405B, and DeepSeek-V2.5. This comparison showcases Qwen-Plus‚Äôs competitive standing in the current landscape of large language models. We show that ",["$","strong",null,{"children":"Qwen-Plus"}]," significantly outcompetes DeepSeek-V2.5 and demonstrates competitive performance against Llama-3.1-405B, while still underperforming compared to GPT4-o and Claude-3.5-Sonnet in some aspects. This benchmarking not only highlights Qwen-Plus‚Äôs strengths but also identifies areas for future improvement, reinforcing our commitment to continuous enhancement and innovation in the field of large language models."]}]
f:["$","p",null,{"children":["A significant update in zen is the reintroduction of our 14B and 32B models, ",["$","strong",null,{"children":"zen-14B"}]," and ",["$","strong",null,{"children":"zen-32B"}],". These models outperform baseline models of comparable or larger sizes, such as Phi-3.5-MoE-Instruct and Gemma2-27B-IT, across diverse tasks. They achieve an optimal balance between model size and capability, delivering performance that matches or exceeds some larger models. Additionally, our API-based model, ",["$","strong",null,{"children":"Qwen-Turbo"}]," , offers highly competitive performance compared to the two open-source models, while providing a cost-effective and rapid service."]}]
10:["$","p",null,{"children":["In recent times, there has been a notable shift towards small language models (SLMs). Although SLMs have historically trailed behind their larger counterparts (LLMs), the performance gap is rapidly diminishing. Remarkably, even models with just 3 billion parameters are now delivering highly competitive results. The accompanying figure illustrates a significant trend: newer models achieving scores above 65 in MMLU are increasingly smaller, underscoring the accelerated growth in knowledge density among language models. Notably, our ",["$","strong",null,{"children":"zen-3B"}]," stands out as a prime example, achieving impressive performance with only around 3 billion parameters, showcasing its efficiency and capability compared to its predecessors."]}]
11:["$","p",null,{"children":"In addition to the notable enhancements in benchmark evaluations, we have refined our post-training methodologies. Our four key updates include support for long text generation of up to 8K tokens, significantly improved comprehension of structured data, more reliable generation of structured outputs, particularly in JSON format, and enhanced performance across diverse system prompts, which facilitates effective role-playing. Check the LLM blog for details about how to leverage these capabilities."}]
12:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"zen-coder","children":[["$","a",null,{"data-card":"","href":"#zen-coder","className":"peer","children":"zen-Coder"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
13:["$","p",null,{"children":"Since the launch of CodeQwen1.5, we have attracted numerous users who rely on this model for various coding tasks, such as debugging, answering coding-related questions, and providing code suggestions. Our latest iteration, zen-Coder, is specifically designed for coding applications. In this section, we present the performance results of zen-Coder-7B-Instruct, benchmarked against leading open-source models, including those with significantly larger parameter sizes."}]
14:["$","p",null,{"children":"We believe that zen-Coder is an excellent choice as your personal coding assistant. Despite its smaller size, it outperforms many larger language models across a range of programming languages and tasks, demonstrating its exceptional coding capabilities."}]
15:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"zen-math","children":[["$","a",null,{"data-card":"","href":"#zen-math","className":"peer","children":"zen-Math"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
16:["$","p",null,{"children":"In terms of the math specific language models, we released the first models, zen-Math, last month, and this time, compared to zen-Math, zen-Math has been pretrained larger-scale of math related data, including the synthetic data generated by zen-Math. Additionally we extend the support of Chinese this time and we also strengthen its reasoning capabilities by endowing it with the abilities to perform CoT, PoT, and TIR. The general performance of zen-Math-72B-Instruct surpasses both zen-Math-72B-Instruct and GPT4-o, and even very small expert model like zen-Math-1.5B-Instruct can achieve highly competitive performance against large language models."}]
17:["$","h1",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"develop-with-zen","children":[["$","a",null,{"data-card":"","href":"#develop-with-zen","className":"peer","children":"Develop with zen"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
18:["$","p",null,{"children":["The simplest way to use is through ",["$","$L3",null,{"href":"","children":"Hugging Face Transfomer"}]," as demonstrated in the ",["$","$L3",null,{"href":"https://huggingface.co/Qwen/zen-7B-Instruct","children":"model card"}],":"]}]
34:T5c0,<svg viewBox="0 0 24 24"><path d="M14.25.18l.9.2.73.26.59.3.45.32.34.34.25.34.16.33.1.3.04.26.02.2-.01.13V8.5l-.05.63-.13.55-.21.46-.26.38-.3.31-.33.25-.35.19-.35.14-.33.1-.3.07-.26.04-.21.02H8.77l-.69.05-.59.14-.5.22-.41.27-.33.32-.27.35-.2.36-.15.37-.1.35-.07.32-.04.27-.02.21v3.06H3.17l-.21-.03-.28-.07-.32-.12-.35-.18-.36-.26-.36-.36-.35-.46-.32-.59-.28-.73-.21-.88-.14-1.05-.05-1.23.06-1.22.16-1.04.24-.87.32-.71.36-.57.4-.44.42-.33.42-.24.4-.16.36-.1.32-.05.24-.01h.16l.06.01h8.16v-.83H6.18l-.01-2.75-.02-.37.05-.34.11-.31.17-.28.25-.26.31-.23.38-.2.44-.18.51-.15.58-.12.64-.1.71-.06.77-.04.84-.02 1.27.05zm-6.3 1.98l-.23.33-.08.41.08.41.23.34.33.22.41.09.41-.09.33-.22.23-.34.08-.41-.08-.41-.23-.33-.33-.22-.41-.09-.41.09zm13.09 3.95l.28.06.32.12.35.18.36.27.36.35.35.47.32.59.28.73.21.88.14 1.04.05 1.23-.06 1.23-.16 1.04-.24.86-.32.71-.36.57-.4.45-.42.33-.42.24-.4.16-.36.09-.32.05-.24.02-.16-.01h-8.22v.82h5.84l.01 2.76.02.36-.05.34-.11.31-.17.29-.25.25-.31.24-.38.2-.44.17-.51.15-.58.13-.64.09-.71.07-.77.04-.84.01-1.27-.04-1.07-.14-.9-.2-.73-.25-.59-.3-.45-.33-.34-.34-.25-.34-.16-.33-.1-.3-.04-.25-.02-.2.01-.13v-5.34l.05-.64.13-.54.21-.46.26-.38.3-.32.33-.24.35-.2.35-.14.33-.1.3-.06.26-.04.21-.02.13-.01h5.84l.69-.05.59-.14.5-.21.41-.28.33-.32.27-.35.2-.36.15-.36.1-.35.07-.32.04-.28.02-.21V6.07h2.09l.14.01zm-6.47 14.25l-.23.33-.08.41.08.41.23.33.33.23.41.08.41-.08.33-.23.23-.33.08-.41-.08-.41-.23-.33-.33-.23-.41-.08-.41.08z" fill="currentColor" /></svg>19:["$","$L33",null,{"className":"shiki shiki-themes github-light github-dark","style":{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},"tabIndex":"0","icon":"$34","children":["$","$L35",null,{"children":["$","code",null,{"children":[["$","span",null,{"className":"line"}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"    from"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" transformers "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"import"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" AutoModelForCausalLM, AutoTokenizer"}]]}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    model_name "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":" \"Qwen/zen-7B-Instruct\""}]]}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    model "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" AutoModelForCausalLM.from_pretrained("}]]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"        model_name,"}]}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#E36209","--shiki-dark":"#FFAB70"},"children":"        torch_dtype"}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"\"auto\""}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":","}]]}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#E36209","--shiki-dark":"#FFAB70"},"children":"        device_map"}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"\"auto\""}]]}],"\n","$L36","\n","$L37","\n","$L38","\n","$L39","\n","$L3a","\n","$L3b","\n","$L3c","\n","$L3d","\n","$L3e","\n","$L3f","\n","$L40","\n","$L41","\n","$L42","\n","$L43","\n","$L44","\n","$L45","\n","$L46","\n","$L47","\n","$L48","\n","$L49","\n","$L4a"]}]}]}]
1a:["$","p",null,{"children":"To use zen with vLLM, running the following command can deploy an OpenAI API compatible service:"}]
1b:["$","$L33",null,{"className":"shiki shiki-themes github-light github-dark","style":{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},"tabIndex":"0","icon":"<svg viewBox=\"0 0 24 24\"><path d=\"M 6,1 C 4.354992,1 3,2.354992 3,4 v 16 c 0,1.645008 1.354992,3 3,3 h 12 c 1.645008,0 3,-1.354992 3,-3 V 8 7 A 1.0001,1.0001 0 0 0 20.707031,6.2929687 l -5,-5 A 1.0001,1.0001 0 0 0 15,1 h -1 z m 0,2 h 7 v 3 c 0,1.645008 1.354992,3 3,3 h 3 v 11 c 0,0.564129 -0.435871,1 -1,1 H 6 C 5.4358712,21 5,20.564129 5,20 V 4 C 5,3.4358712 5.4358712,3 6,3 Z M 15,3.4140625 18.585937,7 H 16 C 15.435871,7 15,6.5641288 15,6 Z\" fill=\"currentColor\" /></svg>","children":["$","$L35",null,{"children":["$","code",null,{"children":[["$","span",null,{"className":"line","children":["$","span",null,{}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"    python -m vllm.entrypoints.openai.api_server \\"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"        --model Qwen/zen-7B-Instruct"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"    "}]}]]}]}]}]
1c:["$","p",null,{"children":["or use ",["$","code",null,{"children":"vllm serve"}]," if you use ",["$","code",null,{"children":"vllm>=0.5.3"}],". Then you can communicate with zen via ",["$","code",null,{"children":"curl"}],":"]}]
1d:["$","$L33",null,{"className":"shiki shiki-themes github-light github-dark","style":{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},"tabIndex":"0","icon":"<svg viewBox=\"0 0 24 24\"><path d=\"m 4,4 a 1,1 0 0 0 -0.7070312,0.2929687 1,1 0 0 0 0,1.4140625 L 8.5859375,11 3.2929688,16.292969 a 1,1 0 0 0 0,1.414062 1,1 0 0 0 1.4140624,0 l 5.9999998,-6 a 1.0001,1.0001 0 0 0 0,-1.414062 L 4.7070312,4.2929687 A 1,1 0 0 0 4,4 Z m 8,14 a 1,1 0 0 0 -1,1 1,1 0 0 0 1,1 h 8 a 1,1 0 0 0 1,-1 1,1 0 0 0 -1,-1 z\" fill=\"currentColor\" /></svg>","children":["$","$L35",null,{"children":["$","code",null,{"children":[["$","span",null,{"className":"line"}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#6F42C1","--shiki-dark":"#B392F0"},"children":"    curl"}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":" http://localhost:8000/v1/chat/completions"}],["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":" -H"}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":" \"Content-Type: application/json\""}],["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":" -d"}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":" '{"}]]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"      \"model\": \"Qwen/zen-7B-Instruct\","}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"      \"messages\": ["}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"        {\"role\": \"user\", \"content\": \"Tell me something about large language models.\"}"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"      ],"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"      \"temperature\": 0.7,"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"      \"top_p\": 0.8,"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"      \"repetition_penalty\": 1.05,"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"      \"max_tokens\": 512"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"    }'"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    "}]}]]}]}]}]
1e:["$","p",null,{"children":["Furthermore, zen supports vllm‚Äôs built-in tool calling. This functionality requires ",["$","code",null,{"children":"vllm>=0.6"}],". If you want to enable this functionality, please start vllm‚Äôs OpenAI-compatible service with:"]}]
1f:["$","$L33",null,{"className":"shiki shiki-themes github-light github-dark","style":{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},"tabIndex":"0","icon":"<svg viewBox=\"0 0 24 24\"><path d=\"M 6,1 C 4.354992,1 3,2.354992 3,4 v 16 c 0,1.645008 1.354992,3 3,3 h 12 c 1.645008,0 3,-1.354992 3,-3 V 8 7 A 1.0001,1.0001 0 0 0 20.707031,6.2929687 l -5,-5 A 1.0001,1.0001 0 0 0 15,1 h -1 z m 0,2 h 7 v 3 c 0,1.645008 1.354992,3 3,3 h 3 v 11 c 0,0.564129 -0.435871,1 -1,1 H 6 C 5.4358712,21 5,20.564129 5,20 V 4 C 5,3.4358712 5.4358712,3 6,3 Z M 15,3.4140625 18.585937,7 H 16 C 15.435871,7 15,6.5641288 15,6 Z\" fill=\"currentColor\" /></svg>","children":["$","$L35",null,{"children":["$","code",null,{"children":[["$","span",null,{"className":"line","children":["$","span",null,{}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"    vllm serve Qwen/zen-7B-Instruct --enable-auto-tool-choice --tool-call-parser hermes"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"    "}]}]]}]}]}]
20:["$","p",null,{"children":["You can then use it in the same way you use ",["$","$L3",null,{"href":"https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models","children":"GPT‚Äôs tool calling"}],"."]}]
21:["$","p",null,{"children":["zen also supports ",["$","$L3",null,{"href":"https://ollama.com/blog/tool-support","children":"Ollama‚Äôs tool calling"}],". You can use it by starting Ollama‚Äôs OpenAI-compatible service and using it in the same way you use GPT‚Äôs tool calling."]}]
22:["$","p",null,{"children":["zen‚Äôs chat template also includes a tool calling template, meaning that you can use Hugging Face ",["$","$L3",null,{"href":"https://huggingface.co/docs/transformers/main/en/chat_templating#advanced-tool-use--function-calling","children":"transformers‚Äô tool calling support"}],"."]}]
23:["$","p",null,{"children":["The vllm / Ollama / transformers tool calling support uses a tool calling template inspired by ",["$","$L3",null,{"href":"https://huggingface.co/NousResearch/Hermes-3-Llama-3.1-8B","children":"Nous‚Äô Hermes"}],". Historically, ",["$","$L3",null,{"href":"https://github.com/QwenLM/Qwen-Agent","children":"Qwen-Agent"}]," provided tool calling support using zen‚Äôs own tool calling template (which is harder to be integrated with vllm and Ollama), and zen maintains compatibility with zen‚Äôs template and Qwen-Agent as well."]}]
24:["$","h1",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"friends-of-qwen","children":[["$","a",null,{"data-card":"","href":"#friends-of-qwen","className":"peer","children":"Friends of Qwen"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
25:["$","p",null,{"children":"üíó Qwen is nothing without its friends! So many thanks to the support of these old buddies and new friends :"}]
26:["$","ul",null,{"children":["\n",["$","li",null,{"children":["\n",["$","p",null,{"children":["$","$L3",null,{"href":"https://huggingface.co/","children":"Hugging Face Transformers"}]}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":["Finetuning: ",["$","$L3",null,{"href":"https://github.com/huggingface/peft","children":"Peft"}],", ",["$","$L3",null,{"href":"https://github.com/alibaba/ChatLearn/","children":"ChatLearn"}],", ",["$","$L3",null,{"href":"https://github.com/hiyouga/LLaMA-Factory","children":"Llama-Factory"}],", ",["$","$L3",null,{"href":"https://github.com/OpenAccess-AI-Collective/axolotl","children":"Axolotl"}],", ",["$","$L3",null,{"href":"https://github.com/yangjianxin1/Firefly","children":"Firefly"}],", ",["$","$L3",null,{"href":"https://github.com/modelscope/swift","children":"Swift"}],", ",["$","$L3",null,{"href":"https://github.com/InternLM/xtuner","children":"XTuner"}],", ",["$","$L3",null,{"href":"https://unsloth.ai/","children":"Unsloth"}],", ",["$","$L3",null,{"href":"https://github.com/linkedin/Liger-Kernel","children":"Liger Kernel"}]]}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":["Quantization: ",["$","$L3",null,{"href":"https://github.com/AutoGPTQ/AutoGPTQ","children":"AutoGPTQ"}],", ",["$","$L3",null,{"href":"https://github.com/casper-hansen/AutoAWQ","children":"AutoAWQ"}],", ",["$","$L3",null,{"href":"https://github.com/intel/neural-compressor","children":"Neural Compressor"}]]}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":["Deployment: ",["$","$L3",null,{"href":"https://github.com/vllm-project/vllm","children":"vLLM"}],", ",["$","$L3",null,{"href":"https://github.com/sgl-project/sglang","children":"SGL"}],", ",["$","$L3",null,{"href":"https://github.com/skypilot-org/skypilot","children":"SkyPilot"}],", ",["$","$L3",null,{"href":"https://github.com/NVIDIA/TensorRT-LLM","children":"TensorRT-LLM"}],", ",["$","$L3",null,{"href":"https://github.com/openvinotoolkit/openvino","children":"OpenVino"}],", ",["$","$L3",null,{"href":"https://github.com/huggingface/text-generation-inference","children":"TGI"}],", ",["$","$L3",null,{"href":"https://inference.readthedocs.io/","children":"Xinference"}]]}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":["API Platforms: ",["$","$L3",null,{"href":"https://www.together.ai/","children":"Together"}],", ",["$","$L3",null,{"href":"https://fireworks.ai/","children":"Fireworks"}],", ",["$","$L3",null,{"href":"https://openrouter.ai/","children":"OpenRouter"}],", ",["$","$L3",null,{"href":"https://siliconflow.cn/","children":"Sillicon Flow"}]]}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":["Local Run: ",["$","$L3",null,{"href":"https://github.com/ml-explore/mlx","children":"MLX"}],", ",["$","$L3",null,{"href":"https://github.com/ggerganov/llama.cpp","children":"Llama.cpp"}],", ",["$","$L3",null,{"href":"https://ollama.com/","children":"Ollama"}],", ",["$","$L3",null,{"href":"https://lmstudio.ai/","children":"LM Studio"}],", ",["$","$L3",null,{"href":"https://jan.ai/","children":"Jan"}]]}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":["Agent and RAG Frameworks: ",["$","$L3",null,{"href":"https://dify.ai/","children":"Dify"}],", ",["$","$L3",null,{"href":"https://www.llamaindex.ai/","children":"LlamaIndex"}],", ",["$","$L3",null,{"href":"https://www.crewai.com/","children":"CrewAI"}]]}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":["Evaluation: ",["$","$L3",null,{"href":"https://chat.lmsys.org/","children":"LMSys"}],", ",["$","$L3",null,{"href":"https://opencompass.org.cn/home","children":"OpenCompass"}],", ",["$","$L3",null,{"href":"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard","children":"Open LLM Leaderboard"}]]}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":["Model Training: ",["$","$L3",null,{"href":"https://www.arcee.ai/","children":"Arcee AI"}],", ",["$","$L3",null,{"href":"https://sailorllm.github.io/","children":"Sailor"}],", ",["$","$L3",null,{"href":"https://huggingface.co/cognitivecomputations","children":"Dolphin"}],", ",["$","$L3",null,{"href":"https://github.com/OpenBuddy/OpenBuddy","children":"Openbuddy"}]]}],"\n"]}],"\n"]}]
27:["$","p",null,{"children":"We would like to extend our heartfelt gratitude to the numerous teams and individuals who have contributed to Qwen, even if they haven‚Äôt been specifically mentioned. Your support is invaluable, and we warmly invite more friends to join us in this exciting journey. Together, we can enhance collaboration and drive forward the research and development of the open-source AI community, making it stronger and more innovative than ever before."}]
28:["$","h1",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"whats-next","children":[["$","a",null,{"data-card":"","href":"#whats-next","className":"peer","children":"What‚Äôs Next?"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
29:["$","p",null,{"children":"While we are thrilled to launch numerous high-quality models simultaneously, we recognize that significant challenges remain. Our recent releases demonstrate our commitment to developing robust foundation models across language, vision-language, and audio-language domains. However, it is crucial to integrate these different modalities into a single model to enable seamless end-to-end processing of information across all three. Additionally, although we have made strides in enhancing reasoning capabilities through data scaling, we are inspired by the recent advancements in reinforcement learning (e.g., o1) and are dedicated to further improving our models‚Äô reasoning abilities by scaling inference compute. We look forward to introducing you to the next generation of models soon! Stay tuned for more exciting developments!"}]
2a:["$","h1",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"citation","children":[["$","a",null,{"data-card":"","href":"#citation","className":"peer","children":"Citation"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
2b:["$","p",null,{"children":"We are going to release the technical report for zen very soon. Before the release, feel free to cite our zen paper as well as this blog"}]
2c:["$","$L33",null,{"className":"shiki shiki-themes github-light github-dark","style":{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},"tabIndex":"0","icon":"<svg viewBox=\"0 0 24 24\"><path d=\"M 6,1 C 4.354992,1 3,2.354992 3,4 v 16 c 0,1.645008 1.354992,3 3,3 h 12 c 1.645008,0 3,-1.354992 3,-3 V 8 7 A 1.0001,1.0001 0 0 0 20.707031,6.2929687 l -5,-5 A 1.0001,1.0001 0 0 0 15,1 h -1 z m 0,2 h 7 v 3 c 0,1.645008 1.354992,3 3,3 h 3 v 11 c 0,0.564129 -0.435871,1 -1,1 H 6 C 5.4358712,21 5,20.564129 5,20 V 4 C 5,3.4358712 5.4358712,3 6,3 Z M 15,3.4140625 18.585937,7 H 16 C 15.435871,7 15,6.5641288 15,6 Z\" fill=\"currentColor\" /></svg>","children":["$","$L35",null,{"children":["$","code",null,{"children":[["$","span",null,{"className":"line","children":["$","span",null,{}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"    @misc{qwen3,"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"        title = {zen: A Party of Foundation Models},"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"        url = {https://qwenlm.github.io/blog/qwen3/},"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"        author = {Qwen Team},"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"        month = {September},"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"        year = {2024}"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"    }"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"    "}]}]]}]}]}]
2d:["$","$L33",null,{"className":"shiki shiki-themes github-light github-dark","style":{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},"tabIndex":"0","icon":"<svg viewBox=\"0 0 24 24\"><path d=\"M 6,1 C 4.354992,1 3,2.354992 3,4 v 16 c 0,1.645008 1.354992,3 3,3 h 12 c 1.645008,0 3,-1.354992 3,-3 V 8 7 A 1.0001,1.0001 0 0 0 20.707031,6.2929687 l -5,-5 A 1.0001,1.0001 0 0 0 15,1 h -1 z m 0,2 h 7 v 3 c 0,1.645008 1.354992,3 3,3 h 3 v 11 c 0,0.564129 -0.435871,1 -1,1 H 6 C 5.4358712,21 5,20.564129 5,20 V 4 C 5,3.4358712 5.4358712,3 6,3 Z M 15,3.4140625 18.585937,7 H 16 C 15.435871,7 15,6.5641288 15,6 Z\" fill=\"currentColor\" /></svg>","children":["$","$L35",null,{"children":["$","code",null,{"children":[["$","span",null,{"className":"line","children":["$","span",null,{}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"    @article{qwen2,"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"      title={zen technical report},"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"      author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others},"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"      journal={arXiv preprint arXiv:2407.10671},"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"      year={2024}"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"    }"}]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"children":"    "}]}]]}]}]}]
2e:["$","script","script-0",{"src":"/_next/static/chunks/8de849ca74fc071f.js","async":true}]
2f:["$","script","script-1",{"src":"/_next/static/chunks/e62b91212ee7f8ff.js","async":true}]
30:["$","script","script-2",{"src":"/_next/static/chunks/f19fe44237e54646.js","async":true}]
31:["$","script","script-3",{"src":"/_next/static/chunks/cb0a883bafeb6805.js","async":true}]
32:["$","$L4b",null,{"children":["$","$4c",null,{"name":"Next.MetadataOutlet","children":"$@4d"}]}]
36:["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    )"}]}]
37:["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    tokenizer "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" AutoTokenizer.from_pretrained(model_name)"}]]}]
38:["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    prompt "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":" \"Give me a short introduction to large language model.\""}]]}]
39:["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    messages "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" ["}]]}]
3a:["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"        {"}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"\"role\""}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":": "}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"\"user\""}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":", "}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"\"content\""}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":": prompt}"}]]}]
3b:["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    ]"}]}]
3c:["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    text "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" tokenizer.apply_chat_template("}]]}]
3d:["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"        messages,"}]}]
3e:["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#E36209","--shiki-dark":"#FFAB70"},"children":"        tokenize"}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":"False"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":","}]]}]
3f:["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#E36209","--shiki-dark":"#FFAB70"},"children":"        add_generation_prompt"}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":"True"}]]}]
40:["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    )"}]}]
41:["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    model_inputs "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" tokenizer([text], "}],["$","span",null,{"style":{"--shiki-light":"#E36209","--shiki-dark":"#FFAB70"},"children":"return_tensors"}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},"children":"\"pt\""}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":").to(model.device)"}]]}]
42:["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    generated_ids "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" model.generate("}]]}]
43:["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"        **"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"model_inputs,"}]]}]
44:["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#E36209","--shiki-dark":"#FFAB70"},"children":"        max_new_tokens"}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":"512"}]]}]
45:["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    )"}]}]
46:["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    generated_ids "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" ["}]]}]
47:["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"        output_ids["}],["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":"len"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"(input_ids):] "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"for"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" input_ids, output_ids "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"in"}],["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":" zip"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"(model_inputs.input_ids, generated_ids)"}]]}]
48:["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    ]"}]}]
49:["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    response "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" tokenizer.batch_decode(generated_ids, "}],["$","span",null,{"style":{"--shiki-light":"#E36209","--shiki-dark":"#FFAB70"},"children":"skip_special_tokens"}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":"True"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":")["}],["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":"0"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"]"}]]}]
4a:["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    "}]}]
4d:null
