1:"$Sreact.fragment"
2:I[10086,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/36bfed0236ce2cf2.js","/_next/static/chunks/e62b91212ee7f8ff.js","/_next/static/chunks/2a98816c7d26bf58.js","/_next/static/chunks/cb0a883bafeb6805.js"],""]
39:I[51504,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/36bfed0236ce2cf2.js","/_next/static/chunks/e62b91212ee7f8ff.js","/_next/static/chunks/2a98816c7d26bf58.js","/_next/static/chunks/cb0a883bafeb6805.js"],"CodeBlock"]
3b:I[51504,["/_next/static/chunks/59d0ad1b64f8544e.js","/_next/static/chunks/36bfed0236ce2cf2.js","/_next/static/chunks/e62b91212ee7f8ff.js","/_next/static/chunks/2a98816c7d26bf58.js","/_next/static/chunks/cb0a883bafeb6805.js"],"Pre"]
43:I[89923,["/_next/static/chunks/4d80e004cf4896dd.js","/_next/static/chunks/350ee4303b732916.js"],"OutletBoundary"]
44:"$Sreact.suspense"
0:{"buildId":"o_J3cFnAZ1mdL_cv2bxKY","rsc":["$","$1","c",{"children":[["$","main",null,{"className":"mx-auto w-full max-w-2xl px-4 py-16","children":[["$","$L2",null,{"href":"/blog","className":"inline-flex items-center gap-1.5 text-sm text-fd-muted-foreground hover:text-fd-foreground mb-10 transition-colors","children":"← Back to Blog"}],["$","div",null,{"className":"mb-8","children":[["$","time",null,{"className":"text-xs font-mono text-fd-muted-foreground uppercase tracking-wider","children":"September 18, 2022"}],["$","h1",null,{"className":"text-3xl font-bold mt-2 mb-3","children":"GRPO: Group Relative Policy Optimization"}],["$","p",null,{"className":"text-fd-muted-foreground text-lg mb-4","children":"Introducing GRPO, a new approach to reinforcement learning from human feedback that improves sample efficiency and alignment stability."}],["$","div",null,{"className":"flex items-center gap-3 pt-4 border-t border-fd-border","children":[["$","span",null,{"className":"text-sm text-fd-muted-foreground","children":["By ","Zach Kelling"]}],["$","div",null,{"className":"flex gap-1.5 ml-auto","children":[["$","span","Research",{"className":"text-[10px] font-mono uppercase tracking-wider bg-fd-muted text-fd-muted-foreground px-1.5 py-0.5 rounded","children":"Research"}],["$","span","Alignment",{"className":"text-[10px] font-mono uppercase tracking-wider bg-fd-muted text-fd-muted-foreground px-1.5 py-0.5 rounded","children":"Alignment"}],["$","span","Training",{"className":"text-[10px] font-mono uppercase tracking-wider bg-fd-muted text-fd-muted-foreground px-1.5 py-0.5 rounded","children":"Training"}]]}]]}]]}],["$","div",null,{"className":"prose dark:prose-invert max-w-none","children":[["$","p",null,{"children":"Reinforcement learning from human feedback (RLHF) has become central to aligning language models with human preferences. But current methods like PPO are sample-inefficient and unstable. Today we introduce Group Relative Policy Optimization (GRPO), a new approach that addresses these limitations."}],"\n",["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"the-rlhf-challenge","children":[["$","a",null,{"data-card":"","href":"#the-rlhf-challenge","className":"peer","children":"The RLHF Challenge"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}],"\n",["$","p",null,{"children":"Standard RLHF follows three steps:"}],"\n",["$","ol",null,{"children":["\n",["$","li",null,{"children":"Train a reward model on human preference data"}],"\n",["$","li",null,{"children":"Use the reward model to provide training signal"}],"\n",["$","li",null,{"children":"Optimize the policy with reinforcement learning (typically PPO)"}],"\n"]}],"\n",["$","p",null,{"children":"Step 3 is problematic. PPO requires careful hyperparameter tuning, extensive sampling, and still often produces unstable training dynamics."}],"\n",["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"key-insight-relative-comparisons","children":[["$","a",null,{"data-card":"","href":"#key-insight-relative-comparisons","className":"peer","children":"Key Insight: Relative Comparisons"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":["$L3","$L4","$undefined"]}]]}],"\n","$L5","\n","$L6","\n","$L7","\n","$L8","\n","$L9","\n","$La","\n","$Lb","\n","$Lc","\n","$Ld","\n","$Le","\n","$Lf","\n","$L10","\n","$L11","\n","$L12","\n","$L13","\n","$L14","\n","$L15","\n","$L16","\n","$L17","\n","$L18","\n","$L19","\n","$L1a","\n","$L1b","\n","$L1c","\n","$L1d","\n","$L1e","\n","$L1f","\n","$L20","\n","$L21","\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","$L22","\n","$L23","\n","$L24","\n","$L25","\n","$L26","\n","$L27","\n","$L28","\n","$L29","\n","$L2a","\n","$L2b","\n","$L2c","\n","$L2d","\n","$L2e","\n","$L2f","\n","$L30","\n","$L31","\n","$L32","\n","$L33"]}]]}],["$L34","$L35","$L36","$L37"],"$L38"]}],"loading":null,"isPartial":false}
3:["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}]
4:["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}]
5:["$","p",null,{"children":"Humans naturally make relative judgments. “Response A is better than B” comes more easily than “Response A scores 7.3.” Yet reward models output absolute scores that discard this relational structure."}]
6:["$","p",null,{"children":"GRPO preserves relative comparisons throughout training."}]
7:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"the-grpo-algorithm","children":[["$","a",null,{"data-card":"","href":"#the-grpo-algorithm","className":"peer","children":"The GRPO Algorithm"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
8:["$","p",null,{"children":"Instead of optimizing absolute rewards, GRPO optimizes within groups of sampled responses."}]
9:["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"sampling","children":[["$","a",null,{"data-card":"","href":"#sampling","className":"peer","children":"Sampling"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
a:["$","p",null,{"children":"For each prompt $x$, sample a group of $k$ responses:"}]
b:["$","p",null,{"children":["$","code",null,{"children":"G = \\{y_1, y_2, …, y_k\\} \\sim \\pi_\\theta(y|x)"}]}]
c:["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"ranking","children":[["$","a",null,{"data-card":"","href":"#ranking","className":"peer","children":"Ranking"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
d:["$","p",null,{"children":"Rank responses within the group using the reward model:"}]
e:["$","p",null,{"children":[["$","code",null,{"children":"r_i = R(x, y_i)"}]," ",["$","code",null,{"children":"\\text\\{rank\\}(y_i) = |\\{j : r_j > r_i\\}| + 1"}]]}]
f:["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"relative-advantage","children":[["$","a",null,{"data-card":"","href":"#relative-advantage","className":"peer","children":"Relative Advantage"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
10:["$","p",null,{"children":"Compute advantages relative to the group:"}]
11:["$","p",null,{"children":["$","code",null,{"children":"A_i = \\frac\\{r_i - \\mu_G\\}\\{\\sigma_G\\}"}]}]
12:["$","p",null,{"children":"where $\\mu_G$ and $\\sigma_G$ are the group mean and standard deviation."}]
13:["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"policy-update","children":[["$","a",null,{"data-card":"","href":"#policy-update","className":"peer","children":"Policy Update"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
14:["$","p",null,{"children":"Update the policy to increase probability of high-ranked responses:"}]
15:["$","p",null,{"children":["$","code",null,{"children":"\\mathcal\\{L\\}(\\theta) = -\\mathbb\\{E\\}_\\{y \\sim G\\}\\left[\\min\\left(\\frac\\{\\pi_ \\theta(y|x)\\}\\{\\pi_\\{\\text\\{old\\}\\}(y|x)\\} A, \\text\\{clip\\}\\left(\\frac\\{\\pi_\\theta(y|x)\\}\\{\\pi_\\{\\text\\{old\\}\\}(y|x)\\}, 1-\\epsilon, 1+\\epsilon\\right) A\\right)\\right]"}]}]
16:["$","p",null,{"children":"The clipping stabilizes training, similar to PPO, but the relative advantages provide better signal."}]
17:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"why-grpo-works","children":[["$","a",null,{"data-card":"","href":"#why-grpo-works","className":"peer","children":"Why GRPO Works"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
18:["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"robust-to-reward-scale","children":[["$","a",null,{"data-card":"","href":"#robust-to-reward-scale","className":"peer","children":"Robust to Reward Scale"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
19:["$","p",null,{"children":"Absolute reward values vary across prompts and reward model calibration. Normalization within groups removes this sensitivity."}]
1a:["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"better-gradient-signal","children":[["$","a",null,{"data-card":"","href":"#better-gradient-signal","className":"peer","children":"Better Gradient Signal"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
1b:["$","p",null,{"children":"Groups provide multiple comparison points per prompt. This reduces variance and improves sample efficiency."}]
1c:["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"natural-curriculum","children":[["$","a",null,{"data-card":"","href":"#natural-curriculum","className":"peer","children":"Natural Curriculum"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
1d:["$","p",null,{"children":"Hard prompts where all responses score poorly still provide useful gradients. The best-in-group response gets positive advantage even if absolute rewards are low."}]
1e:["$","h3",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"reduced-reward-hacking","children":[["$","a",null,{"data-card":"","href":"#reduced-reward-hacking","className":"peer","children":"Reduced Reward Hacking"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
1f:["$","p",null,{"children":"Optimizing relative rankings is harder to game than optimizing absolute scores. The model must genuinely improve, not find reward model exploits."}]
20:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"experimental-results","children":[["$","a",null,{"data-card":"","href":"#experimental-results","className":"peer","children":"Experimental Results"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
21:["$","p",null,{"children":"We compared GRPO to PPO on alignment benchmarks:"}]
22:["$","div",null,{"className":"relative overflow-auto prose-no-margin my-6","children":["$","table",null,{"children":[["$","thead",null,{"children":["$","tr",null,{"children":[["$","th",null,{"children":"Method"}],["$","th",null,{"children":"Helpfulness"}],["$","th",null,{"children":"Harmlessness"}],["$","th",null,{"children":"Honesty"}],["$","th",null,{"children":"Samples Required"}]]}]}],["$","tbody",null,{"children":[["$","tr",null,{"children":[["$","td",null,{"children":"PPO"}],["$","td",null,{"children":"78.2"}],["$","td",null,{"children":"82.1"}],["$","td",null,{"children":"75.4"}],["$","td",null,{"children":"100K"}]]}],["$","tr",null,{"children":[["$","td",null,{"children":"GRPO"}],["$","td",null,{"children":"81.7"}],["$","td",null,{"children":"84.3"}],["$","td",null,{"children":"79.1"}],["$","td",null,{"children":"35K"}]]}]]}]]}]}]
23:["$","p",null,{"children":"GRPO achieves better alignment with 3x fewer samples."}]
24:["$","p",null,{"children":"Training dynamics also improve significantly:"}]
25:["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"Stability"}]," : GRPO loss curves show less variance"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Convergence"}]," : Reaches final performance 2x faster"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Robustness"}]," : Less sensitive to learning rate choice"]}],"\n"]}]
26:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"implementation-details","children":[["$","a",null,{"data-card":"","href":"#implementation-details","className":"peer","children":"Implementation Details"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
27:["$","p",null,{"children":"Key hyperparameters:"}]
28:["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"Group size"}]," ($k$): 8-16 works well"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Clipping"}]," ($\\epsilon$): 0.1-0.2"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"KL penalty"}]," : Lower than PPO (0.01 vs 0.1)"]}],"\n"]}]
29:["$","p",null,{"children":"The larger group size compared to PPO’s typical 2-response setup is essential. More comparisons mean better gradient estimates."}]
2a:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"code-release","children":[["$","a",null,{"data-card":"","href":"#code-release","className":"peer","children":"Code Release"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
2b:["$","p",null,{"children":"We’re releasing our GRPO implementation integrated with the Zen training framework:"}]
3a:T5c0,<svg viewBox="0 0 24 24"><path d="M14.25.18l.9.2.73.26.59.3.45.32.34.34.25.34.16.33.1.3.04.26.02.2-.01.13V8.5l-.05.63-.13.55-.21.46-.26.38-.3.31-.33.25-.35.19-.35.14-.33.1-.3.07-.26.04-.21.02H8.77l-.69.05-.59.14-.5.22-.41.27-.33.32-.27.35-.2.36-.15.37-.1.35-.07.32-.04.27-.02.21v3.06H3.17l-.21-.03-.28-.07-.32-.12-.35-.18-.36-.26-.36-.36-.35-.46-.32-.59-.28-.73-.21-.88-.14-1.05-.05-1.23.06-1.22.16-1.04.24-.87.32-.71.36-.57.4-.44.42-.33.42-.24.4-.16.36-.1.32-.05.24-.01h.16l.06.01h8.16v-.83H6.18l-.01-2.75-.02-.37.05-.34.11-.31.17-.28.25-.26.31-.23.38-.2.44-.18.51-.15.58-.12.64-.1.71-.06.77-.04.84-.02 1.27.05zm-6.3 1.98l-.23.33-.08.41.08.41.23.34.33.22.41.09.41-.09.33-.22.23-.34.08-.41-.08-.41-.23-.33-.33-.22-.41-.09-.41.09zm13.09 3.95l.28.06.32.12.35.18.36.27.36.35.35.47.32.59.28.73.21.88.14 1.04.05 1.23-.06 1.23-.16 1.04-.24.86-.32.71-.36.57-.4.45-.42.33-.42.24-.4.16-.36.09-.32.05-.24.02-.16-.01h-8.22v.82h5.84l.01 2.76.02.36-.05.34-.11.31-.17.29-.25.25-.31.24-.38.2-.44.17-.51.15-.58.13-.64.09-.71.07-.77.04-.84.01-1.27-.04-1.07-.14-.9-.2-.73-.25-.59-.3-.45-.33-.34-.34-.25-.34-.16-.33-.1-.3-.04-.25-.02-.2.01-.13v-5.34l.05-.64.13-.54.21-.46.26-.38.3-.32.33-.24.35-.2.35-.14.33-.1.3-.06.26-.04.21-.02.13-.01h5.84l.69-.05.59-.14.5-.21.41-.28.33-.32.27-.35.2-.36.15-.36.1-.35.07-.32.04-.28.02-.21V6.07h2.09l.14.01zm-6.47 14.25l-.23.33-.08.41.08.41.23.33.33.23.41.08.41-.08.33-.23.23-.33.08-.41-.08-.41-.23-.33-.33-.23-.41-.08-.41.08z" fill="currentColor" /></svg>2c:["$","$L39",null,{"className":"shiki shiki-themes github-light github-dark","style":{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},"tabIndex":"0","icon":"$3a","children":["$","$L3b",null,{"children":["$","code",null,{"children":[["$","span",null,{"className":"line"}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"    from"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" zen.alignment "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"import"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" GRPOTrainer"}]]}],"\n",["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    "}]}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    trainer "}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":" GRPOTrainer("}]]}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#E36209","--shiki-dark":"#FFAB70"},"children":"        model"}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"model,"}]]}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#E36209","--shiki-dark":"#FFAB70"},"children":"        reward_model"}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"reward_model,"}]]}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#E36209","--shiki-dark":"#FFAB70"},"children":"        group_size"}],["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}],["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":"12"}],["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":","}]]}],"\n",["$","span",null,{"className":"line","children":[["$","span",null,{"style":{"--shiki-light":"#E36209","--shiki-dark":"#FFAB70"},"children":"        clip_epsilon"}],"$L3c","$L3d","$L3e"]}],"\n","$L3f","\n","$L40","\n","$L41","\n","$L42"]}]}]}]
2d:["$","p",null,{"children":"Full documentation and examples at github.com/zoo-labs/zen-align."}]
2e:["$","h2",null,{"className":"flex scroll-m-28 flex-row items-center gap-2","id":"whats-next","children":[["$","a",null,{"data-card":"","href":"#whats-next","className":"peer","children":"What’s Next"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-link size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100","aria-hidden":true,"children":[["$","path","1cjeqo",{"d":"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"}],["$","path","19qd67",{"d":"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"}],"$undefined"]}]]}]
2f:["$","p",null,{"children":"GRPO opens several research directions:"}]
30:["$","ul",null,{"children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"Multi-objective GRPO"}]," : Separate groups for different alignment dimensions"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Online preference learning"}]," : Update reward model during training"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Constitutional GRPO"}]," : Use principles instead of learned rewards"]}],"\n"]}]
31:["$","p",null,{"children":"Alignment is the central challenge of AI development. GRPO is one step toward making it more reliable."}]
32:["$","hr",null,{}]
33:["$","p",null,{"children":["$","em",null,{"children":"Zach Kelling is a co-founder of Zoo Labs Foundation."}]}]
34:["$","script","script-0",{"src":"/_next/static/chunks/36bfed0236ce2cf2.js","async":true}]
35:["$","script","script-1",{"src":"/_next/static/chunks/e62b91212ee7f8ff.js","async":true}]
36:["$","script","script-2",{"src":"/_next/static/chunks/2a98816c7d26bf58.js","async":true}]
37:["$","script","script-3",{"src":"/_next/static/chunks/cb0a883bafeb6805.js","async":true}]
38:["$","$L43",null,{"children":["$","$44",null,{"name":"Next.MetadataOutlet","children":"$@45"}]}]
3c:["$","span",null,{"style":{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},"children":"="}]
3d:["$","span",null,{"style":{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},"children":"0.15"}]
3e:["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":","}]
3f:["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    )"}]}]
40:["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    "}]}]
41:["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    trainer.train(prompts)"}]}]
42:["$","span",null,{"className":"line","children":["$","span",null,{"style":{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},"children":"    "}]}]
45:null
