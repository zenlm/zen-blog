<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta http-equiv=refresh content="5; url=https://qwen.ai/research"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Blog | Qwen</title><meta name=keywords content><meta name=description content="Blog - Qwen"><meta name=author content="Qwen Team"><link rel=canonical href=https://qwenlm.github.io/blog/><link crossorigin=anonymous href=/assets/css/stylesheet.6c0865a4bc8dbcbd27d78777eb33b404568f7fbf3185cca7b978e5275a4dd049.css integrity="sha256-bAhlpLyNvL0n14d36zO0BFaPf78xhcynuXjlJ1pN0Ek=" rel="preload stylesheet" as=style><link rel=icon href=https://qwenlm.github.io/favicon.png><link rel=apple-touch-icon href=https://qwenlm.github.io/favicon.png><link rel=manifest href=https://qwenlm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate type=application/rss+xml href=https://qwenlm.github.io/blog/index.xml><link rel=alternate hreflang=en href=https://qwenlm.github.io/blog/><link rel=alternate hreflang=zh href=https://qwenlm.github.io/zh/blog/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script><meta property="og:title" content="Blog"><meta property="og:description" content="Qwen"><meta property="og:type" content="website"><meta property="og:url" content="https://qwenlm.github.io/blog/"><meta property="og:image" content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Blog"><meta name=twitter:description content="Qwen"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://qwenlm.github.io/blog/"}]}</script></head><body class=list id=top><script>const hasHeaderBg=!0</script><style>.modal-overlay{position:fixed;top:0;left:0;width:100%;height:100%;background-color:rgba(0,0,0,.5);display:flex;align-items:center;z-index:1000;animation:fadeIn .3s ease-in-out}.modal-container{margin-left:auto;margin-right:auto;background-color:var(--theme);border-radius:8px;box-shadow:0 4px 20px rgba(0,0,0,.15);width:90%;max-width:420px;height:fit-content;padding:30px;text-align:center;position:relative;animation:slideIn .4s ease-out}.modal-container a{color:var(--hero2)}.modal-icon{width:70px;height:70px;background-color:#f0f7ff;border-radius:50%;display:flex;align-items:center;justify-content:center;margin:0 auto 20px;color:#1a73e8;font-size:30px}.modal-title{font-size:1.5rem;font-weight:600;color:var(--primary);margin:0 0 15px}.modal-message{font-size:1rem;color:var(--secondary);line-height:1.5;margin:0 0 25px}.countdown{font-size:1.2rem;color:#666;margin:20px 0;font-weight:500}.modal-buttons{display:flex;justify-content:center;gap:15px;margin-top:25px}.modal-buttons .btn{padding:6px 16px;border-radius:8px;font-size:1.2rem;font-weight:500;cursor:pointer;transition:all .3s ease;border:none}.btn-primary{background-color:#1a73e8;color:#fff}.btn-primary:hover{background-color:#1557b0}.btn-secondary{background-color:#f1f3f4;color:#333}.btn-secondary:hover{background-color:#e0e0e0}@keyframes fadeIn{from{opacity:0}to{opacity:1}}@keyframes slideIn{from{opacity:0;transform:translateY(-50px)}to{opacity:1;transform:translateY(0)}}@media(max-width:480px){.modal-container{max-width:95%;width:calc(95vw - 40px);padding:20px}}</style><div class=modal-overlay><div class=modal-container><div class=modal-icon><svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"/></svg></div><h2 class=modal-title>We have a new blog at <a href=https://qwen.ai/research>qwen.ai</a>!</h2><p class=modal-message>This page will automatically redirect in <span class=countdown id=countdown>5</span> seconds.</p><p class=modal-message>If you are not redirected automatically, please click the button below.</p><div class=modal-buttons><button class="btn btn-primary" onclick=redirectToPage()>Go Now</button></div></div></div><script>let countdown=5;const countdownElement=document.getElementById("countdown"),timer=setInterval(()=>{countdown--,countdownElement.textContent=countdown,countdown<=0&&clearInterval(timer)},1e3);function stayHere(){document.querySelector(".modal-overlay").style.display="none"}function redirectToPage(){window.location.href="https://qwen.ai/research"}</script><header class=header><div class="nav-container nav-background"><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><img src=https://qwenlm.github.io/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span class=active>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://chat.qwen.ai title="Try Qwen Chat"><span>Try Qwen Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero-background style="background:linear-gradient(-225deg,#2CD8D5 0%,#6B8DD6 48%,#8E37D7 100%)"></div><div class="hero text-light"><h1 class=post-title>Blog<sup class=title-translation>&nbsp;&nbsp;[<ul class=i18n_list><li><a href=https://qwenlm.github.io/zh/blog/>简体中文</a></li></ul>]</sup></h1></div></div><main class=main><article class=post-entry><header class=entry-header><h2>Introducing Qwen</h2></header><div class=entry-content><p>4 months after our first release of Qwen-7B, which is the starting point of our opensource journey of large language models (LLM), we now provide an introduction to the Qwen series to give you a whole picture of our work as well as our objectives. Below are important links to our opensource projects and community.
PAPER GITHUB HUGGING FACE MODELSCOPE DISCORD
Additionally, we have WeChat groups for chatting and we invite you to join the groups through the provided link in our GitHub readme....</p></div><footer class=entry-footer><span title='2024-01-23 22:13:29 +0800 +0800'>January 23, 2024</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1115 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Introducing Qwen" href=https://qwenlm.github.io/blog/qwen/></a></article><article class=post-entry><header class=entry-header><h2>OFA: Towards Building a One-For-All Model</h2></header><div class=entry-content><p>2022 is a year of generalist models! With the bloom of multimodal pretraining, especially the unified model, we have witnessed the opportunity to building a generalist model that is capable of processing tasks of different modalities or multi-modalities! Thus, we propose OFA1, namely One-For-All, a unified multimodal pretrained model that unifies understanding and generation tasks concerning modalities into a single framework, and we pretrain OFA with the instruction-based multitask-pretraining that endows it with multiple capabilities....</p></div><footer class=entry-footer><span title='2022-11-14 16:01:41 +0800 +0800'>November 14, 2022</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;1876 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to OFA: Towards Building a One-For-All Model" href=https://qwenlm.github.io/blog/ofa/></a></article><article class=post-entry><header class=entry-header><h2>Zen 3.0: The Next Generation of Open AI</h2></header><div class=entry-content><p>Today we release Zen 3.0, our third-generation language model family. Zen 3 represents a step change in what open models can do.
Model Family Zen 3 comes in several sizes:
Model Parameters Context Training Tokens Zen-3-8B 8.1B 128K 15T Zen-3-32B 32.5B 128K 12T Zen-3-72B 72.3B 128K 10T Zen-3-MoE 141B (24B active) 128K 14T All models use the same architecture with scaled dimensions. All are released under Apache 2.0.
Architecture Highlights Extended Context All Zen 3 models support 128K token context natively:...</p></div><footer class=entry-footer><span title='2025-01-13 09:00:00 -0800 -0800'>January 13, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;787 words&nbsp;·&nbsp;Zach Kelling</footer><a class=entry-link aria-label="post link to Zen 3.0: The Next Generation of Open AI" href=https://qwenlm.github.io/blog/zen-3/></a></article><article class=post-entry><header class=entry-header><h2>The Future of Open AI</h2></header><div class=entry-content><p>Four years into Zen’s development, it’s worth stepping back to assess where we are and where we’re going. Open AI development has made remarkable progress. It also faces significant challenges. Here’s my honest assessment.
What We’ve Achieved Competitive Models Open models now match or exceed proprietary alternatives in many domains:
Coding: Open models lead on HumanEval and MBPP Reasoning: Competitive on GSM8K and MATH General knowledge: Within 5% on MMLU Multilingual: Often superior for non-English languages The capability gap that seemed insurmountable in 2021 has largely closed for models under 100B parameters....</p></div><footer class=entry-footer><span title='2024-11-11 09:00:00 -0800 -0800'>November 11, 2024</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;692 words&nbsp;·&nbsp;Zach Kelling</footer><a class=entry-link aria-label="post link to The Future of Open AI" href=https://qwenlm.github.io/blog/future-of-open-ai/></a></article><article class=post-entry><header class=entry-header><h2>Decentralized Compute for AI Training</h2></header><div class=entry-content><p>Training large AI models requires significant compute resources. These resources are concentrated in a few hyperscalers, creating bottlenecks and single points of control. Today we announce the Zoo Compute Network, a decentralized alternative.
The Compute Concentration Problem Current AI training is dominated by:
Cloud providers: AWS, GCP, Azure control most AI-grade compute Hardware scarcity: H100s have year-long waitlists High costs: Training GPT-4 class models costs $100M+ Geographic concentration: Most clusters are in a few regions This concentration creates risks:...</p></div><footer class=entry-footer><span title='2024-08-05 10:00:00 -0800 -0800'>August 5, 2024</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;812 words&nbsp;·&nbsp;Zach Kelling</footer><a class=entry-link aria-label="post link to Decentralized Compute for AI Training" href=https://qwenlm.github.io/blog/decentralized-compute/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://qwenlm.github.io/blog/page/8/>«&nbsp;Prev&nbsp;</a>
<a class=next href=https://qwenlm.github.io/blog/page/10/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2026 <a href=https://qwenlm.github.io/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script></body></html>