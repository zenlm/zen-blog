<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Blog | Zen LM</title><meta name=keywords content><meta name=description content="Blog - Zen LM"><meta name=author content="Zen LM Team"><link rel=canonical href=https://zenlm.org/blog/><link crossorigin=anonymous href=/assets/css/stylesheet.6c0865a4bc8dbcbd27d78777eb33b404568f7fbf3185cca7b978e5275a4dd049.css integrity="sha256-bAhlpLyNvL0n14d36zO0BFaPf78xhcynuXjlJ1pN0Ek=" rel="preload stylesheet" as=style><link rel=icon href=https://zenlm.org/favicon.png><link rel=apple-touch-icon href=https://zenlm.org/favicon.png><link rel=manifest href=https://zenlm.org/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate type=application/rss+xml href=https://zenlm.org/blog/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script><meta property="og:title" content="Blog"><meta property="og:description" content="Zen LM — Frontier open models from Hanzo AI and Zoo Labs Foundation"><meta property="og:type" content="website"><meta property="og:url" content="https://zenlm.org/blog/"><meta property="og:image" content="https://zenlm.org/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Zen LM"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://zenlm.org/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Blog"><meta name=twitter:description content="Zen LM — Frontier open models from Hanzo AI and Zoo Labs Foundation"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://zenlm.org/blog/"}]}</script></head><body class=list id=top><script>const hasHeaderBg=!0</script><header class=header><div class="nav-container nav-background"><nav class=nav><div class=logo><a href=/ accesskey=h title="Zen LM (Alt + H)"><img src=https://zenlm.org/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span class=active>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://zeekay.blog title=zeekay><span>zeekay</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://hanzo.blog title=hanzo.blog><span>hanzo.blog</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://hanzo.ai/chat title="Try Zen Chat"><span>Try Zen Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://blog.zoo.ngo title="zoo blog"><span>zoo blog</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero-background style="background:linear-gradient(-225deg,#2CD8D5 0%,#6B8DD6 48%,#8E37D7 100%)"></div><div class="hero text-light"><h1 class=post-title>Blog</h1></div></div><main class=main><article class=post-entry><header class=entry-header><h2>Zen MoDE: Mixture of Distilled Experts</h2></header><div class=entry-content><p>GITHUB HUGGING FACE
All Zen models are built on Zen MoDE: Mixture of Distilled Experts. This post explains the architecture, why we chose it, and how distillation and expert routing interact to deliver frontier capability at practical inference cost.
The Core Problem There is a fundamental tension in large model design:
More parameters → better capability More parameters → higher inference cost Dense scaling laws are well established. Doubling parameters roughly halves perplexity (with sufficient data), but doubles inference FLOP....</p></div><footer class=entry-footer><span title='2026-01-16 09:00:00 -0800 -0800'>January 16, 2026</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;814 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to Zen MoDE: Mixture of Distilled Experts" href=https://zenlm.org/blog/zen-mode-architecture/></a></article><article class=post-entry><header class=entry-header><h2>Introducing Zen LM: Open Frontier Models from Hanzo AI and Zoo Labs</h2></header><div class=entry-content><p>GITHUB HUGGING FACE TRY ZEN CHAT
Today we are announcing Zen LM — a family of open frontier models co-developed by Hanzo AI and Zoo Labs Foundation. This release marks the public launch of the Zen model catalog: 94+ models spanning text, vision, audio, and code, all built on our Zen MoDE (Mixture of Distilled Experts) architecture.
Why We Built It Modern AI infrastructure concentrates capability in a small number of proprietary systems....</p></div><footer class=entry-footer><span title='2026-01-15 09:00:00 -0800 -0800'>January 15, 2026</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;562 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to Introducing Zen LM: Open Frontier Models from Hanzo AI and Zoo Labs" href=https://zenlm.org/blog/zen-lm-launch/></a></article><article class=post-entry><header class=entry-header><h2>Qwen3Guard: Real-time Safety for Your Token Stream</h2></header><div class=entry-content><p>Tech Report GitHub Hugging Face ModelScope DISCORD
Introduction We are excited to introduce Qwen3Guard, the first safety guardrail model in the Qwen family. Built upon the powerful Qwen3 foundation models and fine-tuned specifically for safety classificatoin, Qwen3Guard ensures responsible AI interactions by delivering precise safety detection for both prompts and responses, complete with risk levels and categorized classifications for accurate moderation.
Qwen3Guard achieves state-of-the-art performance on major safety benchmarks, demonstrating strong capabilities in both prompt and response classification tasks across English, Chinese, and multilingual environments....</p></div><footer class=entry-footer><span title='2025-09-23 04:00:00 +0800 +0800'>September 23, 2025</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1470 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to Qwen3Guard: Real-time Safety for Your Token Stream" href=https://zenlm.org/blog/qwen3guard/></a></article><article class=post-entry><header class=entry-header><h2>Qwen-Image-Edit: Image Editing with Higher Quality and Efficiency</h2></header><div class=entry-content><p>QWEN CHAT GITHUB HUGGING FACE MODELSCOPE DISCORD
We are excited to introduce Qwen-Image-Edit, the image editing version of Qwen-Image. Built upon our 20B Qwen-Image model, Qwen-Image-Edit successfully extends Qwen-Image’s unique text rendering capabilities to image editing tasks, enabling precise text editing. Furthermore, Qwen-Image-Edit simultaneously feeds the input image into zen-VL (for visual semantic control) and the VAE Encoder (for visual appearance control), achieving capabilities in both semantic and appearance editing....</p></div><footer class=entry-footer><span title='2025-08-19 01:30:00 +0800 +0800'>August 19, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;824 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to Qwen-Image-Edit: Image Editing with Higher Quality and Efficiency" href=https://zenlm.org/blog/qwen-image-edit/></a></article><article class=post-entry><header class=entry-header><h2>Qwen-Image: Crafting with Native Text Rendering</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
We are thrilled to release Qwen-Image, a 20B MMDiT image foundation model that achieves significant advances in complex text rendering and precise image editing. To try the latest model, feel free to visit Qwen Chat and choose “Image Generation”.
The key features include:
Superior Text Rendering: Qwen-Image excels at complex text rendering, including multi-line layouts, paragraph-level semantics, and fine-grained details. It supports both alphabetic languages (e....</p></div><footer class=entry-footer><span title='2025-08-04 22:08:30 +0800 +0800'>August 4, 2025</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1229 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to Qwen-Image: Crafting with Native Text Rendering" href=https://zenlm.org/blog/qwen-image/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://zenlm.org/blog/>«&nbsp;Prev&nbsp;</a>
<a class=next href=https://zenlm.org/blog/page/3/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2026 <a href=https://zenlm.org/>Zen LM</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script></body></html>