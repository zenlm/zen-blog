<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Zen4 Ultra: 480B Parameters, 1M Token Context | Zen LM</title><meta name=keywords content="Models,Zen4,Flagship"><meta name=description content="Zen4 Ultra is our most capable model: 480B total parameters, 35B active per token, 1M token context window. Benchmark results and use cases."><meta name=author content="Zen LM Team"><link rel=canonical href=https://zenlm.org/blog/zen4-ultra/><link crossorigin=anonymous href=/assets/css/stylesheet.6c0865a4bc8dbcbd27d78777eb33b404568f7fbf3185cca7b978e5275a4dd049.css integrity="sha256-bAhlpLyNvL0n14d36zO0BFaPf78xhcynuXjlJ1pN0Ek=" rel="preload stylesheet" as=style><link rel=icon href=https://zenlm.org/favicon.png><link rel=apple-touch-icon href=https://zenlm.org/favicon.png><link rel=manifest href=https://zenlm.org/site.webmanifest><meta name=theme-color content="#615CED"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><meta property="og:title" content="Zen4 Ultra: 480B Parameters, 1M Token Context"><meta property="og:description" content="Zen4 Ultra is our most capable model: 480B total parameters, 35B active per token, 1M token context window. Benchmark results and use cases."><meta property="og:type" content="article"><meta property="og:url" content="https://zenlm.org/blog/zen4-ultra/"><meta property="og:image" content="https://zenlm.org/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2026-01-20T09:00:00-08:00"><meta property="article:modified_time" content="2026-01-20T09:00:00-08:00"><meta property="og:site_name" content="Zen LM"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://zenlm.org/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Zen4 Ultra: 480B Parameters, 1M Token Context"><meta name=twitter:description content="Zen4 Ultra is our most capable model: 480B total parameters, 35B active per token, 1M token context window. Benchmark results and use cases."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://zenlm.org/blog/"},{"@type":"ListItem","position":2,"name":"Zen4 Ultra: 480B Parameters, 1M Token Context","item":"https://zenlm.org/blog/zen4-ultra/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Zen4 Ultra: 480B Parameters, 1M Token Context","name":"Zen4 Ultra: 480B Parameters, 1M Token Context","description":"Zen4 Ultra is our most capable model: 480B total parameters, 35B active per token, 1M token context window. Benchmark results and use cases.","keywords":["Models","Zen4","Flagship"],"articleBody":"GITHUB HUGGING FACE TRY ZEN CHAT\nZen4 Ultra is the most capable model in the Zen4 family. It is a Mixture of Distilled Experts model with 480B total parameters and 35B active parameters per forward pass. The native context window is 256K tokens, extending to 1M tokens with YaRN extrapolation.\nArchitecture Property Value Total parameters 480B Active parameters per token 35B Experts per layer 128 Top-k routing 8 Context window (native) 256K Context window (YaRN) 1M Vocabulary size 151,936 Attention heads 64 KV heads (GQA) 8 Layers 94 Benchmark Results General Reasoning Benchmark Zen4 Ultra Zen Max 72B MMLU 89.4 87.1 MMLU-Pro 75.2 71.8 ARC-Challenge 72.1 68.4 HellaSwag 92.3 90.1 Winogrande 87.6 85.2 Mathematics Benchmark Zen4 Ultra Zen Max 72B MATH 81.4 73.2 GSM8K 95.3 92.1 AMC 2023 62.4 54.7 AIME 2024 48.2 37.6 Code Benchmark Zen4 Ultra Zen Max 72B HumanEval 91.2 82.4 MBPP 87.6 81.3 LiveCodeBench 52.4 44.1 SWE-bench Verified 45.7 38.2 Long Context Task Score at 32K Score at 128K Score at 512K NIAH recall 99.1% 98.4% 94.7% Summarization 48.2 46.9 43.1 QA over long doc 74.3 71.2 64.8 Long-context performance remains strong through 512K tokens, with graceful degradation thereafter.\nMultilingual Evaluated on 30 languages across MMMLU:\nLanguage Group Score Latin script (high-resource) 86.4 Latin script (low-resource) 72.1 CJK 81.3 Arabic/Hebrew 76.8 Other non-Latin 68.2 Use Cases Complex Research and Analysis Zen4 Ultra excels at tasks requiring synthesis across long documents:\nAnalyzing regulatory filings spanning hundreds of pages Cross-referencing scientific literature for systematic reviews Multi-document legal analysis with citation tracking Financial model analysis with full spreadsheet context The 1M token context allows loading entire codebases, large document sets, or extended conversation histories without truncation.\nMulti-Step Reasoning For problems requiring planning and backtracking — competitive math, logic puzzles, complex software architecture decisions — Ultra’s depth provides measurable advantage over smaller models.\nAgentic Workflows Ultra’s function calling reliability is critical for long-running agent tasks:\nSWE-bench Verified: 45.7% (full-repo software engineering tasks) Tool selection accuracy: 94.2% on held-out tool-use evaluation Multi-turn instruction adherence: 91.8% Code Generation Near-human performance on competitive programming tasks. Generates complete, working implementations of complex algorithms in all major languages.\nRunning Zen4 Ultra Hugging Face + vLLM (recommended for production) from vllm import LLM, SamplingParams llm = LLM( model=\"hanzoai/zen4-ultra\", tensor_parallel_size=8, # 8x H100 80GB max_model_len=131072, ) outputs = llm.generate( [\"Explain the Zen MoDE architecture in detail.\"], SamplingParams(temperature=0.7, max_tokens=2048), ) Transformers from transformers import AutoModelForCausalLM, AutoTokenizer import torch model = AutoModelForCausalLM.from_pretrained( \"hanzoai/zen4-ultra\", torch_dtype=torch.bfloat16, device_map=\"auto\", ) tokenizer = AutoTokenizer.from_pretrained(\"hanzoai/zen4-ultra\") messages = [{\"role\": \"user\", \"content\": \"Solve: find all integer solutions to x^3 + y^3 = z^3.\"}] text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True) inputs = tokenizer(text, return_tensors=\"pt\").to(model.device) output = model.generate(**inputs, max_new_tokens=1024) print(tokenizer.decode(output[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)) Hardware Requirements Configuration VRAM Throughput 8x H100 80GB 640GB ~2,400 tok/s 16x A100 80GB 1280GB ~1,100 tok/s 32x A100 40GB 1280GB ~600 tok/s For cost-sensitive production use cases, Zen Max 72B delivers most of Ultra’s capability at a fraction of the compute.\nLicense Apache-2.0. Commercial use permitted. No royalty or usage fees.\nZen4 Ultra is available now on Hugging Face. For API access, see hanzo.ai.\n","wordCount":"506","inLanguage":"en","datePublished":"2026-01-20T09:00:00-08:00","dateModified":"2026-01-20T09:00:00-08:00","author":{"@type":"Person","name":"Zen LM Team"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://zenlm.org/blog/zen4-ultra/"},"publisher":{"@type":"Organization","name":"Zen LM","logo":{"@type":"ImageObject","url":"https://zenlm.org/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="Zen LM (Alt + H)"><img src=https://zenlm.org/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://zeekay.blog title=zeekay><span>zeekay</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://hanzo.blog title=hanzo.blog><span>hanzo.blog</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://hanzo.ai/chat title="Try Zen Chat"><span>Try Zen Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://blog.zoo.ngo title="zoo blog"><span>zoo blog</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero><h1 class=post-title>Zen4 Ultra: 480B Parameters, 1M Token Context</h1><div class=post-description>Zen4 Ultra is our most capable model: 480B total parameters, 35B active per token, 1M token context window. Benchmark results and use cases.</div><div class=post-meta><span title='2026-01-20 09:00:00 -0800 -0800'>January 20, 2026</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;506 words&nbsp;·&nbsp;Zen LM Team</div></div></div><main class=main><article class=post-single><div class=post-content><p><a href=https://github.com/hanzoai class="btn external" target=_blank>GITHUB</a>
<a href=https://huggingface.co/hanzoai/zen4-ultra class="btn external" target=_blank>HUGGING FACE</a>
<a href=https://hanzo.ai/chat class="btn external" target=_blank>TRY ZEN CHAT</a></p><p><strong>Zen4 Ultra</strong> is the most capable model in the Zen4 family. It is a Mixture of Distilled Experts model with 480B total parameters and 35B active parameters per forward pass. The native context window is 256K tokens, extending to 1M tokens with YaRN extrapolation.</p><h2 id=architecture>Architecture<a hidden class=anchor aria-hidden=true href=#architecture>#</a></h2><table><thead><tr><th>Property</th><th>Value</th></tr></thead><tbody><tr><td>Total parameters</td><td>480B</td></tr><tr><td>Active parameters per token</td><td>35B</td></tr><tr><td>Experts per layer</td><td>128</td></tr><tr><td>Top-k routing</td><td>8</td></tr><tr><td>Context window (native)</td><td>256K</td></tr><tr><td>Context window (YaRN)</td><td>1M</td></tr><tr><td>Vocabulary size</td><td>151,936</td></tr><tr><td>Attention heads</td><td>64</td></tr><tr><td>KV heads (GQA)</td><td>8</td></tr><tr><td>Layers</td><td>94</td></tr></tbody></table><h2 id=benchmark-results>Benchmark Results<a hidden class=anchor aria-hidden=true href=#benchmark-results>#</a></h2><h3 id=general-reasoning>General Reasoning<a hidden class=anchor aria-hidden=true href=#general-reasoning>#</a></h3><table><thead><tr><th>Benchmark</th><th>Zen4 Ultra</th><th>Zen Max 72B</th></tr></thead><tbody><tr><td>MMLU</td><td>89.4</td><td>87.1</td></tr><tr><td>MMLU-Pro</td><td>75.2</td><td>71.8</td></tr><tr><td>ARC-Challenge</td><td>72.1</td><td>68.4</td></tr><tr><td>HellaSwag</td><td>92.3</td><td>90.1</td></tr><tr><td>Winogrande</td><td>87.6</td><td>85.2</td></tr></tbody></table><h3 id=mathematics>Mathematics<a hidden class=anchor aria-hidden=true href=#mathematics>#</a></h3><table><thead><tr><th>Benchmark</th><th>Zen4 Ultra</th><th>Zen Max 72B</th></tr></thead><tbody><tr><td>MATH</td><td>81.4</td><td>73.2</td></tr><tr><td>GSM8K</td><td>95.3</td><td>92.1</td></tr><tr><td>AMC 2023</td><td>62.4</td><td>54.7</td></tr><tr><td>AIME 2024</td><td>48.2</td><td>37.6</td></tr></tbody></table><h3 id=code>Code<a hidden class=anchor aria-hidden=true href=#code>#</a></h3><table><thead><tr><th>Benchmark</th><th>Zen4 Ultra</th><th>Zen Max 72B</th></tr></thead><tbody><tr><td>HumanEval</td><td>91.2</td><td>82.4</td></tr><tr><td>MBPP</td><td>87.6</td><td>81.3</td></tr><tr><td>LiveCodeBench</td><td>52.4</td><td>44.1</td></tr><tr><td>SWE-bench Verified</td><td>45.7</td><td>38.2</td></tr></tbody></table><h3 id=long-context>Long Context<a hidden class=anchor aria-hidden=true href=#long-context>#</a></h3><table><thead><tr><th>Task</th><th>Score at 32K</th><th>Score at 128K</th><th>Score at 512K</th></tr></thead><tbody><tr><td>NIAH recall</td><td>99.1%</td><td>98.4%</td><td>94.7%</td></tr><tr><td>Summarization</td><td>48.2</td><td>46.9</td><td>43.1</td></tr><tr><td>QA over long doc</td><td>74.3</td><td>71.2</td><td>64.8</td></tr></tbody></table><p>Long-context performance remains strong through 512K tokens, with graceful degradation thereafter.</p><h3 id=multilingual>Multilingual<a hidden class=anchor aria-hidden=true href=#multilingual>#</a></h3><p>Evaluated on 30 languages across MMMLU:</p><table><thead><tr><th>Language Group</th><th>Score</th></tr></thead><tbody><tr><td>Latin script (high-resource)</td><td>86.4</td></tr><tr><td>Latin script (low-resource)</td><td>72.1</td></tr><tr><td>CJK</td><td>81.3</td></tr><tr><td>Arabic/Hebrew</td><td>76.8</td></tr><tr><td>Other non-Latin</td><td>68.2</td></tr></tbody></table><h2 id=use-cases>Use Cases<a hidden class=anchor aria-hidden=true href=#use-cases>#</a></h2><h3 id=complex-research-and-analysis>Complex Research and Analysis<a hidden class=anchor aria-hidden=true href=#complex-research-and-analysis>#</a></h3><p>Zen4 Ultra excels at tasks requiring synthesis across long documents:</p><ul><li>Analyzing regulatory filings spanning hundreds of pages</li><li>Cross-referencing scientific literature for systematic reviews</li><li>Multi-document legal analysis with citation tracking</li><li>Financial model analysis with full spreadsheet context</li></ul><p>The 1M token context allows loading entire codebases, large document sets, or extended conversation histories without truncation.</p><h3 id=multi-step-reasoning>Multi-Step Reasoning<a hidden class=anchor aria-hidden=true href=#multi-step-reasoning>#</a></h3><p>For problems requiring planning and backtracking — competitive math, logic puzzles, complex software architecture decisions — Ultra&rsquo;s depth provides measurable advantage over smaller models.</p><h3 id=agentic-workflows>Agentic Workflows<a hidden class=anchor aria-hidden=true href=#agentic-workflows>#</a></h3><p>Ultra&rsquo;s function calling reliability is critical for long-running agent tasks:</p><ul><li>SWE-bench Verified: 45.7% (full-repo software engineering tasks)</li><li>Tool selection accuracy: 94.2% on held-out tool-use evaluation</li><li>Multi-turn instruction adherence: 91.8%</li></ul><h3 id=code-generation>Code Generation<a hidden class=anchor aria-hidden=true href=#code-generation>#</a></h3><p>Near-human performance on competitive programming tasks. Generates complete, working implementations of complex algorithms in all major languages.</p><h2 id=running-zen4-ultra>Running Zen4 Ultra<a hidden class=anchor aria-hidden=true href=#running-zen4-ultra>#</a></h2><h3 id=hugging-face--vllm-recommended-for-production>Hugging Face + vLLM (recommended for production)<a hidden class=anchor aria-hidden=true href=#hugging-face--vllm-recommended-for-production>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>vllm</span> <span class=kn>import</span> <span class=n>LLM</span><span class=p>,</span> <span class=n>SamplingParams</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>llm</span> <span class=o>=</span> <span class=n>LLM</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=s2>&#34;hanzoai/zen4-ultra&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>tensor_parallel_size</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>   <span class=c1># 8x H100 80GB</span>
</span></span><span class=line><span class=cl>    <span class=n>max_model_len</span><span class=o>=</span><span class=mi>131072</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>outputs</span> <span class=o>=</span> <span class=n>llm</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=s2>&#34;Explain the Zen MoDE architecture in detail.&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>SamplingParams</span><span class=p>(</span><span class=n>temperature</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span> <span class=n>max_tokens</span><span class=o>=</span><span class=mi>2048</span><span class=p>),</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><h3 id=transformers>Transformers<a hidden class=anchor aria-hidden=true href=#transformers>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoModelForCausalLM</span><span class=p>,</span> <span class=n>AutoTokenizer</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;hanzoai/zen4-ultra&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;hanzoai/zen4-ultra&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>messages</span> <span class=o>=</span> <span class=p>[{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;Solve: find all integer solutions to x^3 + y^3 = z^3.&#34;</span><span class=p>}]</span>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>(</span><span class=n>messages</span><span class=p>,</span> <span class=n>tokenize</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>add_generation_prompt</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=p>(</span><span class=n>text</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>,</span> <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>1024</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>output</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=n>inputs</span><span class=o>.</span><span class=n>input_ids</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]:],</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>))</span>
</span></span></code></pre></div><h3 id=hardware-requirements>Hardware Requirements<a hidden class=anchor aria-hidden=true href=#hardware-requirements>#</a></h3><table><thead><tr><th>Configuration</th><th>VRAM</th><th>Throughput</th></tr></thead><tbody><tr><td>8x H100 80GB</td><td>640GB</td><td>~2,400 tok/s</td></tr><tr><td>16x A100 80GB</td><td>1280GB</td><td>~1,100 tok/s</td></tr><tr><td>32x A100 40GB</td><td>1280GB</td><td>~600 tok/s</td></tr></tbody></table><p>For cost-sensitive production use cases, <a href=/blog/zen-max/>Zen Max 72B</a> delivers most of Ultra&rsquo;s capability at a fraction of the compute.</p><h2 id=license>License<a hidden class=anchor aria-hidden=true href=#license>#</a></h2><p>Apache-2.0. Commercial use permitted. No royalty or usage fees.</p><hr><p><em>Zen4 Ultra is available now on <a href=https://huggingface.co/hanzoai/zen4-ultra>Hugging Face</a>. For API access, see <a href=https://hanzo.ai>hanzo.ai</a>.</em></p></div></article></main><footer class=footer><span>&copy; 2026 <a href=https://zenlm.org/>Zen LM</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>