<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta http-equiv=refresh content="5; url=https://qwen.ai/blog?id=continual-learning-sure-opcm"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>SuRe + OPCM: Production-Grade Continual Learning for Open Models | Qwen</title><meta name=keywords content="Research,Continual Learning,SuRe,OPCM,OPLoRA"><meta name=description content="Deep dive on Surprise-Driven Prioritized Replay (SuRe) and Orthogonal Projection Continual Merging (OPCM) — the two SOTA techniques we use for catastrophic-forgetting-free LLM adaptation in the Zen model family."><meta name=author content="Qwen Team"><link rel=canonical href=https://qwenlm.github.io/blog/continual-learning-sure-opcm/><link crossorigin=anonymous href=/assets/css/stylesheet.6c0865a4bc8dbcbd27d78777eb33b404568f7fbf3185cca7b978e5275a4dd049.css integrity="sha256-bAhlpLyNvL0n14d36zO0BFaPf78xhcynuXjlJ1pN0Ek=" rel="preload stylesheet" as=style><link rel=icon href=https://qwenlm.github.io/favicon.png><link rel=apple-touch-icon href=https://qwenlm.github.io/favicon.png><link rel=manifest href=https://qwenlm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate hreflang=en href=https://qwenlm.github.io/blog/continual-learning-sure-opcm/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><meta property="og:title" content="SuRe + OPCM: Production-Grade Continual Learning for Open Models"><meta property="og:description" content="Deep dive on Surprise-Driven Prioritized Replay (SuRe) and Orthogonal Projection Continual Merging (OPCM) — the two SOTA techniques we use for catastrophic-forgetting-free LLM adaptation in the Zen model family."><meta property="og:type" content="article"><meta property="og:url" content="https://qwenlm.github.io/blog/continual-learning-sure-opcm/"><meta property="og:image" content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2026-02-28T10:00:00-08:00"><meta property="article:modified_time" content="2026-02-28T10:00:00-08:00"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="SuRe + OPCM: Production-Grade Continual Learning for Open Models"><meta name=twitter:description content="Deep dive on Surprise-Driven Prioritized Replay (SuRe) and Orthogonal Projection Continual Merging (OPCM) — the two SOTA techniques we use for catastrophic-forgetting-free LLM adaptation in the Zen model family."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://qwenlm.github.io/blog/"},{"@type":"ListItem","position":2,"name":"SuRe + OPCM: Production-Grade Continual Learning for Open Models","item":"https://qwenlm.github.io/blog/continual-learning-sure-opcm/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"SuRe + OPCM: Production-Grade Continual Learning for Open Models","name":"SuRe \u002b OPCM: Production-Grade Continual Learning for Open Models","description":"Deep dive on Surprise-Driven Prioritized Replay (SuRe) and Orthogonal Projection Continual Merging (OPCM) — the two SOTA techniques we use for catastrophic-forgetting-free LLM adaptation in the Zen model family.","keywords":["Research","Continual Learning","SuRe","OPCM","OPLoRA"],"articleBody":"OPLoRA PAPER SuRe PAPER OPCM PAPER YOUTU-AGENT PAPER\nEvery production LLM faces the same brutal constraint: the moment you start adapting a model on new data, it begins forgetting what it already knew. This is catastrophic forgetting — and it is not a theoretical concern. It is the reason most “continually updated” models in production are quietly replaced wholesale every few months rather than genuinely updated in place.\nFor the Zen model family, wholesale replacement is not acceptable. We ship models that users build workflows around. Breaking behavioral continuity is a product failure, not just a research inconvenience. This post describes the four-technique stack we have assembled to solve this: OPLoRA, SuRe, OPCM, and Youtu-Agent.\nThe Plasticity-Stability Dilemma The core tension is simple. A model that adapts quickly to new distributions (high plasticity) tends to overwrite representations needed for old tasks (low stability). A model frozen to preserve old capabilities cannot learn anything new. Both extremes are useless in production.\nFor LLMs specifically, the problem is compounded by scale. You cannot afford to retrain the full model on a joint corpus every time new data arrives — at 480B parameters that is measured in millions of dollars per update. Fine-tuning on new data alone causes forgetting. Replay of old data is expensive and raises data-licensing questions. The field has known this problem for decades but only recently produced techniques that work at LLM scale.\nWe use four papers from late 2024 / early 2025, each addressing a different layer of the problem.\nOPLoRA: Orthogonal Parameter Updates Paper: arXiv:2510.13003\nThe simplest insight in continual learning is that not all parameter directions are equally important. The top singular vectors of the base model’s weight matrices encode the most “load-bearing” representations — the ones responsible for broad capabilities. Fine-tuning along those directions is how forgetting happens.\nOPLoRA adds a projection step after each LoRA update. Let Δ = BA be the standard low-rank update (B ∈ ℝ^{d×r}, A ∈ ℝ^{r×k}). Before applying this update, we project it onto the orthogonal complement of the base model’s top singular subspace:\nΔ_orth = Δ - V_k V_k^T Δ where V_k are the top-k right singular vectors of the pretrained weight matrix W₀. The result: updates flow only through directions that the base model does not heavily use. New knowledge accumulates in the null space of the existing representation.\nimport torch def oplora_project(delta: torch.Tensor, base_weight: torch.Tensor, k: int = 64) -\u003e torch.Tensor: \"\"\"Project LoRA update onto orthogonal complement of base weight top-k subspace.\"\"\" # Compute top-k right singular vectors of base weight _, _, Vt = torch.linalg.svd(base_weight, full_matrices=False) V_k = Vt[:k].T # shape: (d_out, k) # Project delta onto orthogonal complement projection = V_k @ (V_k.T @ delta) return delta - projection class OPLoRALayer(torch.nn.Module): def __init__(self, base_weight: torch.Tensor, rank: int = 16, k: int = 64): super().__init__() d_out, d_in = base_weight.shape self.base_weight = base_weight self.k = k self.lora_A = torch.nn.Parameter(torch.randn(rank, d_in) * 0.01) self.lora_B = torch.nn.Parameter(torch.zeros(d_out, rank)) # Cache top-k right singular vectors with torch.no_grad(): _, _, Vt = torch.linalg.svd(base_weight, full_matrices=False) self.register_buffer('V_k', Vt[:k].T) def forward(self, x: torch.Tensor) -\u003e torch.Tensor: delta = self.lora_B @ self.lora_A delta_orth = delta - self.V_k @ (self.V_k.T @ delta) return x @ (self.base_weight + delta_orth).T The k hyperparameter controls the trade-off: larger k preserves more of the base model but leaves less room for new knowledge. We use k=64 for most Zen fine-tuning passes.\nSuRe: Surprise-Driven Prioritized Replay Paper: arXiv:2511.22367\nReplay-based continual learning maintains a buffer of old examples and mixes them into each training batch. The problem is buffer efficiency: most buffered examples are easy for the current model and contribute nothing. SuRe fixes this with surprise-based prioritization.\nThe surprise score for a token sequence x_t is simply the negative log-likelihood under the current model:\nr_t = -log p_θ(x_t | x_{","wordCount":"1602","inLanguage":"en","datePublished":"2026-02-28T10:00:00-08:00","dateModified":"2026-02-28T10:00:00-08:00","author":{"@type":"Person","name":"Qwen Team"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://qwenlm.github.io/blog/continual-learning-sure-opcm/"},"publisher":{"@type":"Organization","name":"Qwen","logo":{"@type":"ImageObject","url":"https://qwenlm.github.io/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!1</script><style>.modal-overlay{position:fixed;top:0;left:0;width:100%;height:100%;background-color:rgba(0,0,0,.5);display:flex;align-items:center;z-index:1000;animation:fadeIn .3s ease-in-out}.modal-container{margin-left:auto;margin-right:auto;background-color:var(--theme);border-radius:8px;box-shadow:0 4px 20px rgba(0,0,0,.15);width:90%;max-width:420px;height:fit-content;padding:30px;text-align:center;position:relative;animation:slideIn .4s ease-out}.modal-container a{color:var(--hero2)}.modal-icon{width:70px;height:70px;background-color:#f0f7ff;border-radius:50%;display:flex;align-items:center;justify-content:center;margin:0 auto 20px;color:#1a73e8;font-size:30px}.modal-title{font-size:1.5rem;font-weight:600;color:var(--primary);margin:0 0 15px}.modal-message{font-size:1rem;color:var(--secondary);line-height:1.5;margin:0 0 25px}.countdown{font-size:1.2rem;color:#666;margin:20px 0;font-weight:500}.modal-buttons{display:flex;justify-content:center;gap:15px;margin-top:25px}.modal-buttons .btn{padding:6px 16px;border-radius:8px;font-size:1.2rem;font-weight:500;cursor:pointer;transition:all .3s ease;border:none}.btn-primary{background-color:#1a73e8;color:#fff}.btn-primary:hover{background-color:#1557b0}.btn-secondary{background-color:#f1f3f4;color:#333}.btn-secondary:hover{background-color:#e0e0e0}@keyframes fadeIn{from{opacity:0}to{opacity:1}}@keyframes slideIn{from{opacity:0;transform:translateY(-50px)}to{opacity:1;transform:translateY(0)}}@media(max-width:480px){.modal-container{max-width:95%;width:calc(95vw - 40px);padding:20px}}</style><div class=modal-overlay><div class=modal-container><div class=modal-icon><svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"/></svg></div><h2 class=modal-title>We have a new blog!<br>View this page at <a href="https://qwen.ai/blog?id=continual-learning-sure-opcm">qwen.ai</a>.</h2><p class=modal-message>This page will automatically redirect in <span class=countdown id=countdown>5</span> seconds.</p><p class=modal-message>If you are not redirected automatically, please click the button below.</p><div class=modal-buttons><button class="btn btn-primary" onclick=redirectToPage()>Go Now</button></div></div></div><script>let countdown=5;const countdownElement=document.getElementById("countdown"),timer=setInterval(()=>{countdown--,countdownElement.textContent=countdown,countdown<=0&&clearInterval(timer)},1e3);function stayHere(){document.querySelector(".modal-overlay").style.display="none"}function redirectToPage(){window.location.href="https://qwen.ai/blog?id=continual-learning-sure-opcm"}</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><img src=https://qwenlm.github.io/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://chat.qwen.ai title="Try Qwen Chat"><span>Try Qwen Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero><h1 class=post-title>SuRe + OPCM: Production-Grade Continual Learning for Open Models</h1><div class=post-description>Deep dive on Surprise-Driven Prioritized Replay (SuRe) and Orthogonal Projection Continual Merging (OPCM) — the two SOTA techniques we use for catastrophic-forgetting-free LLM adaptation in the Zen model family.</div><div class=post-meta><span title='2026-02-28 10:00:00 -0800 -0800'>February 28, 2026</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;1602 words&nbsp;·&nbsp;Qwen Team</div></div></div><main class=main><article class=post-single><div class=post-content><p><a href=https://arxiv.org/abs/2510.13003 class="btn external" target=_blank>OPLoRA PAPER</a>
<a href=https://arxiv.org/abs/2511.22367 class="btn external" target=_blank>SuRe PAPER</a>
<a href=https://arxiv.org/abs/2501.09522 class="btn external" target=_blank>OPCM PAPER</a>
<a href=https://arxiv.org/abs/2512.24615 class="btn external" target=_blank>YOUTU-AGENT PAPER</a></p><p>Every production LLM faces the same brutal constraint: the moment you start adapting a model on new data, it begins forgetting what it already knew. This is catastrophic forgetting — and it is not a theoretical concern. It is the reason most &ldquo;continually updated&rdquo; models in production are quietly replaced wholesale every few months rather than genuinely updated in place.</p><p>For the Zen model family, wholesale replacement is not acceptable. We ship models that users build workflows around. Breaking behavioral continuity is a product failure, not just a research inconvenience. This post describes the four-technique stack we have assembled to solve this: <strong>OPLoRA</strong>, <strong>SuRe</strong>, <strong>OPCM</strong>, and <strong>Youtu-Agent</strong>.</p><h2 id=the-plasticity-stability-dilemma>The Plasticity-Stability Dilemma<a hidden class=anchor aria-hidden=true href=#the-plasticity-stability-dilemma>#</a></h2><p>The core tension is simple. A model that adapts quickly to new distributions (high plasticity) tends to overwrite representations needed for old tasks (low stability). A model frozen to preserve old capabilities cannot learn anything new. Both extremes are useless in production.</p><p>For LLMs specifically, the problem is compounded by scale. You cannot afford to retrain the full model on a joint corpus every time new data arrives — at 480B parameters that is measured in millions of dollars per update. Fine-tuning on new data alone causes forgetting. Replay of old data is expensive and raises data-licensing questions. The field has known this problem for decades but only recently produced techniques that work at LLM scale.</p><p>We use four papers from late 2024 / early 2025, each addressing a different layer of the problem.</p><h2 id=oplora-orthogonal-parameter-updates>OPLoRA: Orthogonal Parameter Updates<a hidden class=anchor aria-hidden=true href=#oplora-orthogonal-parameter-updates>#</a></h2><p><strong>Paper</strong>: arXiv:2510.13003</p><p>The simplest insight in continual learning is that not all parameter directions are equally important. The top singular vectors of the base model&rsquo;s weight matrices encode the most &ldquo;load-bearing&rdquo; representations — the ones responsible for broad capabilities. Fine-tuning along those directions is how forgetting happens.</p><p>OPLoRA adds a projection step after each LoRA update. Let <code>Δ = BA</code> be the standard low-rank update (B ∈ ℝ^{d×r}, A ∈ ℝ^{r×k}). Before applying this update, we project it onto the orthogonal complement of the base model&rsquo;s top singular subspace:</p><pre tabindex=0><code>Δ_orth = Δ - V_k V_k^T Δ
</code></pre><p>where <code>V_k</code> are the top-k right singular vectors of the pretrained weight matrix W₀. The result: updates flow only through directions that the base model does not heavily use. New knowledge accumulates in the null space of the existing representation.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>oplora_project</span><span class=p>(</span><span class=n>delta</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>base_weight</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>k</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>64</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Project LoRA update onto orthogonal complement of base weight top-k subspace.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># Compute top-k right singular vectors of base weight</span>
</span></span><span class=line><span class=cl>    <span class=n>_</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>Vt</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>svd</span><span class=p>(</span><span class=n>base_weight</span><span class=p>,</span> <span class=n>full_matrices</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>V_k</span> <span class=o>=</span> <span class=n>Vt</span><span class=p>[:</span><span class=n>k</span><span class=p>]</span><span class=o>.</span><span class=n>T</span>  <span class=c1># shape: (d_out, k)</span>
</span></span><span class=line><span class=cl>    <span class=c1># Project delta onto orthogonal complement</span>
</span></span><span class=line><span class=cl>    <span class=n>projection</span> <span class=o>=</span> <span class=n>V_k</span> <span class=o>@</span> <span class=p>(</span><span class=n>V_k</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>delta</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>delta</span> <span class=o>-</span> <span class=n>projection</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>OPLoRALayer</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>base_weight</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>rank</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>16</span><span class=p>,</span> <span class=n>k</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>64</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>d_out</span><span class=p>,</span> <span class=n>d_in</span> <span class=o>=</span> <span class=n>base_weight</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>base_weight</span> <span class=o>=</span> <span class=n>base_weight</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>k</span> <span class=o>=</span> <span class=n>k</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>lora_A</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>rank</span><span class=p>,</span> <span class=n>d_in</span><span class=p>)</span> <span class=o>*</span> <span class=mf>0.01</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>lora_B</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>d_out</span><span class=p>,</span> <span class=n>rank</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=c1># Cache top-k right singular vectors</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>_</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>Vt</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>svd</span><span class=p>(</span><span class=n>base_weight</span><span class=p>,</span> <span class=n>full_matrices</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>register_buffer</span><span class=p>(</span><span class=s1>&#39;V_k&#39;</span><span class=p>,</span> <span class=n>Vt</span><span class=p>[:</span><span class=n>k</span><span class=p>]</span><span class=o>.</span><span class=n>T</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>delta</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>lora_B</span> <span class=o>@</span> <span class=bp>self</span><span class=o>.</span><span class=n>lora_A</span>
</span></span><span class=line><span class=cl>        <span class=n>delta_orth</span> <span class=o>=</span> <span class=n>delta</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>V_k</span> <span class=o>@</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>V_k</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>delta</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span> <span class=o>@</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>base_weight</span> <span class=o>+</span> <span class=n>delta_orth</span><span class=p>)</span><span class=o>.</span><span class=n>T</span>
</span></span></code></pre></div><p>The k hyperparameter controls the trade-off: larger k preserves more of the base model but leaves less room for new knowledge. We use k=64 for most Zen fine-tuning passes.</p><h2 id=sure-surprise-driven-prioritized-replay>SuRe: Surprise-Driven Prioritized Replay<a hidden class=anchor aria-hidden=true href=#sure-surprise-driven-prioritized-replay>#</a></h2><p><strong>Paper</strong>: arXiv:2511.22367</p><p>Replay-based continual learning maintains a buffer of old examples and mixes them into each training batch. The problem is buffer efficiency: most buffered examples are easy for the current model and contribute nothing. SuRe fixes this with surprise-based prioritization.</p><p>The surprise score for a token sequence x_t is simply the negative log-likelihood under the current model:</p><pre tabindex=0><code>r_t = -log p_θ(x_t | x_{&lt;t})
</code></pre><p>High surprise means the current model is uncertain about this sequence — it is more likely to be a case where forgetting is occurring. SuRe preferentially replays high-surprise examples, maximizing the utility of a fixed replay budget.</p><p>Beyond replay prioritization, SuRe introduces a <strong>dual EMA</strong> (Exponential Moving Average) adapter structure:</p><ul><li><strong>Fast LoRA</strong> θ_f: high learning rate, adapts quickly to new data</li><li><strong>Slow LoRA</strong> θ_s: low learning rate, tracks long-run behavioral drift</li></ul><p>At merge time, the two adapters are combined:</p><pre tabindex=0><code>θ_merged = (1-α)θ_s + αθ_f
</code></pre><p>where α is a schedule parameter (typically 0.3). The slow adapter acts as a stability anchor while the fast adapter absorbs new signal. On the LNT (Learn-Not-To-Forget) benchmark, SuRe delivers +5 accuracy points over standard replay.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>heapq</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>collections</span> <span class=kn>import</span> <span class=n>deque</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>dataclasses</span> <span class=kn>import</span> <span class=n>dataclass</span><span class=p>,</span> <span class=n>field</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>List</span><span class=p>,</span> <span class=n>Tuple</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@dataclass</span><span class=p>(</span><span class=n>order</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ReplayItem</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>surprise</span><span class=p>:</span> <span class=nb>float</span>
</span></span><span class=line><span class=cl>    <span class=n>sequence</span><span class=p>:</span> <span class=nb>object</span> <span class=o>=</span> <span class=n>field</span><span class=p>(</span><span class=n>compare</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>SuReBuffer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>capacity</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>10_000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>capacity</span> <span class=o>=</span> <span class=n>capacity</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_heap</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>ReplayItem</span><span class=p>]</span> <span class=o>=</span> <span class=p>[]</span>  <span class=c1># min-heap (lowest surprise at top)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>add</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>sequence</span><span class=p>,</span> <span class=n>model</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>inputs</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=p>(</span><span class=n>sequence</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s1>&#39;pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span><span class=o>=</span><span class=n>inputs</span><span class=p>[</span><span class=s1>&#39;input_ids&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>            <span class=n>surprise</span> <span class=o>=</span> <span class=n>outputs</span><span class=o>.</span><span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>  <span class=c1># mean NLL = surprise score</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>item</span> <span class=o>=</span> <span class=n>ReplayItem</span><span class=p>(</span><span class=n>surprise</span><span class=o>=</span><span class=n>surprise</span><span class=p>,</span> <span class=n>sequence</span><span class=o>=</span><span class=n>sequence</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_heap</span><span class=p>)</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>capacity</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>heapq</span><span class=o>.</span><span class=n>heappush</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_heap</span><span class=p>,</span> <span class=n>item</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=n>surprise</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>_heap</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>surprise</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># Replace lowest-surprise item with this higher-surprise one</span>
</span></span><span class=line><span class=cl>            <span class=n>heapq</span><span class=o>.</span><span class=n>heapreplace</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_heap</span><span class=p>,</span> <span class=n>item</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>sample</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Sample n items, weighted toward high surprise.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>_heap</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>items</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_heap</span><span class=p>,</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=o>-</span><span class=n>x</span><span class=o>.</span><span class=n>surprise</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>[</span><span class=n>item</span><span class=o>.</span><span class=n>sequence</span> <span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>items</span><span class=p>[:</span><span class=n>n</span><span class=p>]]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>DualEMAAdapter</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>fast_lr</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>1e-3</span><span class=p>,</span> <span class=n>slow_lr</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>1e-5</span><span class=p>,</span> <span class=n>alpha</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.3</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fast_lr</span> <span class=o>=</span> <span class=n>fast_lr</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>slow_lr</span> <span class=o>=</span> <span class=n>slow_lr</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span> <span class=o>=</span> <span class=n>alpha</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>merge</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>theta_fast</span><span class=p>:</span> <span class=nb>dict</span><span class=p>,</span> <span class=n>theta_slow</span><span class=p>:</span> <span class=nb>dict</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>dict</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=n>k</span><span class=p>:</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>)</span> <span class=o>*</span> <span class=n>theta_slow</span><span class=p>[</span><span class=n>k</span><span class=p>]</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span> <span class=o>*</span> <span class=n>theta_fast</span><span class=p>[</span><span class=n>k</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=n>theta_fast</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span></code></pre></div><p>In practice we run SuRe with a buffer of 50K sequences, sampling 512 high-surprise examples per training batch alongside 512 new-data examples. The buffer is refreshed every 1K steps as model NLL scores shift.</p><h2 id=opcm-orthogonal-projection-continual-merging>OPCM: Orthogonal Projection Continual Merging<a hidden class=anchor aria-hidden=true href=#opcm-orthogonal-projection-continual-merging>#</a></h2><p><strong>Paper</strong>: arXiv:2501.09522</p><p>OPLoRA and SuRe handle forgetting during training. OPCM handles forgetting during <strong>merging</strong> — the step where multiple LoRA adapters trained on different task sequences are combined into a single weight delta.</p><p>Naive merging (simple average of adapter weights) produces interference between tasks. OPCM applies sequential orthogonal projection: when merging adapter k+1 into the accumulated projection matrix, it removes the component that interferes with previously merged adapters.</p><p>The update rule for the projection matrix P is:</p><pre tabindex=0><code>P_{k+1} = P_k - P_k φ_k^T (φ_k P_k φ_k^T)^{-1} φ_k P_k
</code></pre><p>where φ_k is the gradient direction (or adapter weight direction) of the k-th task. This is the standard Gram-Schmidt orthogonalization applied iteratively to the task gradient subspace.</p><p>The memory cost is O(|θ|) — a single projection matrix regardless of the number of tasks. This is a significant improvement over methods that cache full gradient histories. On sequential merge benchmarks, OPCM achieves 5-8% better retention than simultaneous averaging.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>OPCMStep</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;One step of Orthogonal Projection Continual Merging.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>param_dim</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># P starts as identity — first task goes through unchanged</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>P</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>eye</span><span class=p>(</span><span class=n>param_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>merge</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>phi</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        phi: task gradient direction (flattened), shape (d,)
</span></span></span><span class=line><span class=cl><span class=s2>        Returns: projected phi that is orthogonal to all previous tasks.
</span></span></span><span class=line><span class=cl><span class=s2>        Updates self.P for the next call.
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>phi_flat</span> <span class=o>=</span> <span class=n>phi</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>Pp</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>P</span> <span class=o>@</span> <span class=n>phi_flat</span>
</span></span><span class=line><span class=cl>        <span class=n>denom</span> <span class=o>=</span> <span class=n>phi_flat</span> <span class=o>@</span> <span class=n>Pp</span>  <span class=c1># scalar: φ P φ^T</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>denom</span><span class=o>.</span><span class=n>abs</span><span class=p>()</span> <span class=o>&lt;</span> <span class=mf>1e-8</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>Pp</span>  <span class=c1># already orthogonal</span>
</span></span><span class=line><span class=cl>        <span class=c1># Project P to remove this task&#39;s direction</span>
</span></span><span class=line><span class=cl>        <span class=n>outer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>outer</span><span class=p>(</span><span class=n>Pp</span><span class=p>,</span> <span class=n>Pp</span><span class=p>)</span> <span class=o>/</span> <span class=n>denom</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>P</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>P</span> <span class=o>-</span> <span class=n>outer</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>Pp</span>
</span></span></code></pre></div><p>The key insight is ordering: merge tasks from largest to smallest gradient norm. This ensures the most influential task anchors the subspace, and subsequent tasks fill in orthogonal directions.</p><h2 id=youtu-agent-training-free-grpo-at-inference-time>Youtu-Agent: Training-Free GRPO at Inference Time<a hidden class=anchor aria-hidden=true href=#youtu-agent-training-free-grpo-at-inference-time>#</a></h2><p><strong>Paper</strong>: arXiv:2512.24615</p><p>The three techniques above handle training-time continual learning. Youtu-Agent addresses a different but related problem: <strong>eval-time adaptation</strong> without any weight updates.</p><p>Standard GRPO (Group Relative Policy Optimization) requires gradient computation — you sample multiple completions, score them, and backpropagate the relative reward signal. Youtu-Agent replaces gradient updates with in-context example accumulation.</p><p>The mechanism: maintain an <strong>experience ledger</strong> of (prompt, completion, reward) triples. When a new prompt arrives, retrieve the highest-reward examples for similar prompts and include them in the context window. The model effectively performs few-shot adaptation on its own high-quality past outputs.</p><p>This is training-free GRPO: the policy &ldquo;improves&rdquo; through demonstration rather than parameter updates. On AIME 2024, Youtu-Agent delivers +2.7% accuracy with zero weight updates. The experience ledger is updated online as new completions are scored.</p><p>For Zen, we run Youtu-Agent as a lightweight inference-time layer: the ledger is stored in Redis, similarity search uses Zen Embedding (7680-dim), and retrieval adds ~15ms to inference latency.</p><h2 id=how-these-four-stack-for-zen>How These Four Stack for Zen<a hidden class=anchor aria-hidden=true href=#how-these-four-stack-for-zen>#</a></h2><p>The four techniques operate at different timescales and are composable:</p><pre tabindex=0><code>1. OPLoRA base training
   └─ All Zen fine-tuning uses OPLoRA projection
      Prevents overwriting base model subspace

2. SuRe replay (every training step)
   └─ High-surprise buffer examples mixed into batches
      Dual EMA adapters maintain plasticity-stability balance

3. OPCM periodic merge (every 1K-10K steps)
   └─ Sequential adapter merging with orthogonal projection
      Accumulated knowledge coexists without interference

4. Youtu-Agent at inference (online)
   └─ Experience ledger enables training-free behavioral adaptation
      Zero weight updates, ~15ms overhead
</code></pre><p>In production, layers 1-3 run during scheduled training passes (nightly for Zen nano/eco, weekly for larger models). Layer 4 is always active.</p><p>The combined result: Zen models accumulate behavioral improvements continuously without the forgetting catastrophes that plague naive fine-tuning. We have run this stack for three months on zen-nano with zero regressions on our standard capability benchmarks across 47 sequential fine-tuning events.</p><p>The code for all four components is available in the <a href=https://github.com/zenlm/zen-trainer>zen-trainer repository</a>.</p><hr><p><em>Zen LM is a joint initiative of Hanzo AI Inc. (Techstars &lsquo;17) and Zoo Labs Foundation (501c3).</em></p></div></article></main><footer class=footer><span>&copy; 2026 <a href=https://qwenlm.github.io/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>