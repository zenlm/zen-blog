<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Proof of AI: Verifiable Machine Learning on Chain | Zen LM</title><meta name=keywords content="Research,Blockchain,Verification"><meta name=description content="How we're bringing cryptographic verification to AI inference, enabling trustless machine learning."><meta name=author content="Zach Kelling"><link rel=canonical href=https://zenlm.org/blog/proof-of-ai/><link crossorigin=anonymous href=/assets/css/stylesheet.6c0865a4bc8dbcbd27d78777eb33b404568f7fbf3185cca7b978e5275a4dd049.css integrity="sha256-bAhlpLyNvL0n14d36zO0BFaPf78xhcynuXjlJ1pN0Ek=" rel="preload stylesheet" as=style><link rel=icon href=https://zenlm.org/favicon.png><link rel=apple-touch-icon href=https://zenlm.org/favicon.png><link rel=manifest href=https://zenlm.org/site.webmanifest><meta name=theme-color content="#615CED"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><meta property="og:title" content="Proof of AI: Verifiable Machine Learning on Chain"><meta property="og:description" content="How we're bringing cryptographic verification to AI inference, enabling trustless machine learning."><meta property="og:type" content="article"><meta property="og:url" content="https://zenlm.org/blog/proof-of-ai/"><meta property="og:image" content="https://zenlm.org/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2023-06-26T09:00:00-08:00"><meta property="article:modified_time" content="2023-06-26T09:00:00-08:00"><meta property="og:site_name" content="Zen LM"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://zenlm.org/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Proof of AI: Verifiable Machine Learning on Chain"><meta name=twitter:description content="How we're bringing cryptographic verification to AI inference, enabling trustless machine learning."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://zenlm.org/blog/"},{"@type":"ListItem","position":2,"name":"Proof of AI: Verifiable Machine Learning on Chain","item":"https://zenlm.org/blog/proof-of-ai/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Proof of AI: Verifiable Machine Learning on Chain","name":"Proof of AI: Verifiable Machine Learning on Chain","description":"How we're bringing cryptographic verification to AI inference, enabling trustless machine learning.","keywords":["Research","Blockchain","Verification"],"articleBody":"When an AI system makes a prediction, how do you know it actually ran the model it claims? In centralized systems, you trust the operator. Decentralized AI needs cryptographic proof.\nToday we introduce Proof of AI (PoAI), a framework for verifiable machine learning inference.\nThe Trust Problem Consider a decentralized AI service:\nUser submits input and payment Compute provider runs inference Provider returns output User receives result What prevents the provider from:\nRunning a cheaper, worse model? Returning cached results for new inputs? Fabricating outputs entirely? Traditional solutions require trusted hardware or reputation systems. PoAI provides cryptographic guarantees.\nProof of AI Overview PoAI generates succinct proofs that a specific model produced a specific output from a specific input. Verifiers can check proofs efficiently without re-running inference.\nProperties Soundness: Invalid computations cannot produce valid proofs Completeness: Valid computations always produce verifiable proofs Succinctness: Proof size is small relative to computation size Zero-knowledge (optional): Proofs reveal nothing beyond correctness Architecture Input -\u003e [Model Execution] -\u003e Output | v [Circuit] | v [Proof Generation] | v [Proof] -\u003e [Verifier] -\u003e Accept/Reject Technical Approach Model Compilation Neural networks compile to arithmetic circuits. Each operation becomes constraint equations:\nMatrix multiplication: $y = Wx + b$ becomes constraints on each element\nActivation functions: ReLU, GELU approximated by polynomial constraints\nNormalization: LayerNorm expressed as arithmetic over inputs\nOur compiler handles:\nLinear layers Attention mechanisms Feedforward blocks Embedding lookups Proof System We use a combination of techniques:\nSNARKs for succinct proofs of arithmetic circuits. Proof size is constant regardless of circuit size.\nFolding schemes to handle the repetitive structure of transformer layers efficiently.\nLookup arguments for non-arithmetic operations like embedding tables.\nOptimization Naive compilation produces impractical circuits. We optimize through:\nQuantization: INT8 models have 8x fewer constraints than FP32 Structured pruning: Remove entire attention heads, reducing circuit size Polynomial approximations: Replace transcendental functions with low-degree polynomials Batched verification: Amortize proof costs across multiple inferences Performance Proof Generation Model Size Parameters Proof Time GPU Memory Tiny 25M 12s 8GB Small 110M 89s 24GB Medium 350M 340s 48GB Proof generation is 100-1000x slower than inference. This is the primary limitation.\nVerification Model Size Verification Time Proof Size Tiny 15ms 1.2KB Small 18ms 1.4KB Medium 22ms 1.6KB Verification is fast and proof size is nearly constant. On-chain verification is practical.\nAccuracy Impact Quantization and polynomial approximations affect model accuracy:\nModel Original Accuracy PoAI-Compatible Degradation Classifier 94.2% 93.1% -1.1% Embeddings 0.847 (cosine) 0.831 -1.9% Generator 28.3 (perplexity) 29.1 +2.8% Acceptable for many applications.\nUse Cases Decentralized Inference Markets Users pay for inference, providers compete on price. PoAI ensures providers actually run the claimed model. No reputation bootstrapping needed.\nAI Oracles Smart contracts need off-chain data. AI models can provide predictions, classifications, or analyses. PoAI makes these oracles trustless.\nModel Verification When model weights are published, how do you verify they match claimed training? PoAI can prove that specific weights produce specific benchmark results.\nFederated Learning Verification In federated learning, participants claim to train on local data. PoAI can verify that gradient updates came from actual training, not fabrication.\nLimitations Current limitations we’re working to address:\nProof generation cost: Large models remain impractical Model constraints: Complex architectures (MoE, very deep) are challenging Floating point: Native FP support would reduce approximation errors Recursion: Autoregressive generation requires sequential proofs Roadmap Q3 2023: Release PoAI SDK for small models Q4 2023: Folding scheme improvements for 10x speedup Q1 2024: Support for models up to 1B parameters Q2 2024: Production deployment on Lux Network\nConclusion Verifiable AI is essential for decentralized systems. PoAI makes cryptographic verification practical for real models. The overhead is significant but decreasing.\nTrust, but verify. Now you can.\nZach Kelling is a co-founder of Zoo Labs Foundation.\n","wordCount":"614","inLanguage":"en","datePublished":"2023-06-26T09:00:00-08:00","dateModified":"2023-06-26T09:00:00-08:00","author":{"@type":"Person","name":"Zach Kelling"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://zenlm.org/blog/proof-of-ai/"},"publisher":{"@type":"Organization","name":"Zen LM","logo":{"@type":"ImageObject","url":"https://zenlm.org/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="Zen LM (Alt + H)"><img src=https://zenlm.org/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://zeekay.blog title=zeekay><span>zeekay</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://hanzo.blog title=hanzo.blog><span>hanzo.blog</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://hanzo.ai/chat title="Try Zen Chat"><span>Try Zen Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://blog.zoo.ngo title="zoo blog"><span>zoo blog</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero><h1 class=post-title>Proof of AI: Verifiable Machine Learning on Chain</h1><div class=post-description>How we're bringing cryptographic verification to AI inference, enabling trustless machine learning.</div><div class=post-meta><span title='2023-06-26 09:00:00 -0800 -0800'>June 26, 2023</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;614 words&nbsp;·&nbsp;Zach Kelling</div></div></div><main class=main><article class=post-single><div class=post-content><p>When an AI system makes a prediction, how do you know it actually ran the model it claims? In centralized systems, you trust the operator. Decentralized AI needs cryptographic proof.</p><p>Today we introduce Proof of AI (PoAI), a framework for verifiable machine learning inference.</p><h2 id=the-trust-problem>The Trust Problem<a hidden class=anchor aria-hidden=true href=#the-trust-problem>#</a></h2><p>Consider a decentralized AI service:</p><ol><li>User submits input and payment</li><li>Compute provider runs inference</li><li>Provider returns output</li><li>User receives result</li></ol><p>What prevents the provider from:</p><ul><li>Running a cheaper, worse model?</li><li>Returning cached results for new inputs?</li><li>Fabricating outputs entirely?</li></ul><p>Traditional solutions require trusted hardware or reputation systems. PoAI provides cryptographic guarantees.</p><h2 id=proof-of-ai-overview>Proof of AI Overview<a hidden class=anchor aria-hidden=true href=#proof-of-ai-overview>#</a></h2><p>PoAI generates succinct proofs that a specific model produced a specific output from a specific input. Verifiers can check proofs efficiently without re-running inference.</p><h3 id=properties>Properties<a hidden class=anchor aria-hidden=true href=#properties>#</a></h3><ul><li><strong>Soundness</strong>: Invalid computations cannot produce valid proofs</li><li><strong>Completeness</strong>: Valid computations always produce verifiable proofs</li><li><strong>Succinctness</strong>: Proof size is small relative to computation size</li><li><strong>Zero-knowledge</strong> (optional): Proofs reveal nothing beyond correctness</li></ul><h3 id=architecture>Architecture<a hidden class=anchor aria-hidden=true href=#architecture>#</a></h3><pre tabindex=0><code>Input -&gt; [Model Execution] -&gt; Output
              |
              v
         [Circuit]
              |
              v
    [Proof Generation]
              |
              v
          [Proof] -&gt; [Verifier] -&gt; Accept/Reject
</code></pre><h2 id=technical-approach>Technical Approach<a hidden class=anchor aria-hidden=true href=#technical-approach>#</a></h2><h3 id=model-compilation>Model Compilation<a hidden class=anchor aria-hidden=true href=#model-compilation>#</a></h3><p>Neural networks compile to arithmetic circuits. Each operation becomes constraint equations:</p><p><strong>Matrix multiplication</strong>: $y = Wx + b$ becomes constraints on each element</p><p><strong>Activation functions</strong>: ReLU, GELU approximated by polynomial constraints</p><p><strong>Normalization</strong>: LayerNorm expressed as arithmetic over inputs</p><p>Our compiler handles:</p><ul><li>Linear layers</li><li>Attention mechanisms</li><li>Feedforward blocks</li><li>Embedding lookups</li></ul><h3 id=proof-system>Proof System<a hidden class=anchor aria-hidden=true href=#proof-system>#</a></h3><p>We use a combination of techniques:</p><p><strong>SNARKs</strong> for succinct proofs of arithmetic circuits. Proof size is constant regardless of circuit size.</p><p><strong>Folding schemes</strong> to handle the repetitive structure of transformer layers efficiently.</p><p><strong>Lookup arguments</strong> for non-arithmetic operations like embedding tables.</p><h3 id=optimization>Optimization<a hidden class=anchor aria-hidden=true href=#optimization>#</a></h3><p>Naive compilation produces impractical circuits. We optimize through:</p><ol><li><strong>Quantization</strong>: INT8 models have 8x fewer constraints than FP32</li><li><strong>Structured pruning</strong>: Remove entire attention heads, reducing circuit size</li><li><strong>Polynomial approximations</strong>: Replace transcendental functions with low-degree polynomials</li><li><strong>Batched verification</strong>: Amortize proof costs across multiple inferences</li></ol><h2 id=performance>Performance<a hidden class=anchor aria-hidden=true href=#performance>#</a></h2><h3 id=proof-generation>Proof Generation<a hidden class=anchor aria-hidden=true href=#proof-generation>#</a></h3><table><thead><tr><th>Model Size</th><th>Parameters</th><th>Proof Time</th><th>GPU Memory</th></tr></thead><tbody><tr><td>Tiny</td><td>25M</td><td>12s</td><td>8GB</td></tr><tr><td>Small</td><td>110M</td><td>89s</td><td>24GB</td></tr><tr><td>Medium</td><td>350M</td><td>340s</td><td>48GB</td></tr></tbody></table><p>Proof generation is 100-1000x slower than inference. This is the primary limitation.</p><h3 id=verification>Verification<a hidden class=anchor aria-hidden=true href=#verification>#</a></h3><table><thead><tr><th>Model Size</th><th>Verification Time</th><th>Proof Size</th></tr></thead><tbody><tr><td>Tiny</td><td>15ms</td><td>1.2KB</td></tr><tr><td>Small</td><td>18ms</td><td>1.4KB</td></tr><tr><td>Medium</td><td>22ms</td><td>1.6KB</td></tr></tbody></table><p>Verification is fast and proof size is nearly constant. On-chain verification is practical.</p><h3 id=accuracy-impact>Accuracy Impact<a hidden class=anchor aria-hidden=true href=#accuracy-impact>#</a></h3><p>Quantization and polynomial approximations affect model accuracy:</p><table><thead><tr><th>Model</th><th>Original Accuracy</th><th>PoAI-Compatible</th><th>Degradation</th></tr></thead><tbody><tr><td>Classifier</td><td>94.2%</td><td>93.1%</td><td>-1.1%</td></tr><tr><td>Embeddings</td><td>0.847 (cosine)</td><td>0.831</td><td>-1.9%</td></tr><tr><td>Generator</td><td>28.3 (perplexity)</td><td>29.1</td><td>+2.8%</td></tr></tbody></table><p>Acceptable for many applications.</p><h2 id=use-cases>Use Cases<a hidden class=anchor aria-hidden=true href=#use-cases>#</a></h2><h3 id=decentralized-inference-markets>Decentralized Inference Markets<a hidden class=anchor aria-hidden=true href=#decentralized-inference-markets>#</a></h3><p>Users pay for inference, providers compete on price. PoAI ensures providers actually run the claimed model. No reputation bootstrapping needed.</p><h3 id=ai-oracles>AI Oracles<a hidden class=anchor aria-hidden=true href=#ai-oracles>#</a></h3><p>Smart contracts need off-chain data. AI models can provide predictions, classifications, or analyses. PoAI makes these oracles trustless.</p><h3 id=model-verification>Model Verification<a hidden class=anchor aria-hidden=true href=#model-verification>#</a></h3><p>When model weights are published, how do you verify they match claimed training? PoAI can prove that specific weights produce specific benchmark results.</p><h3 id=federated-learning-verification>Federated Learning Verification<a hidden class=anchor aria-hidden=true href=#federated-learning-verification>#</a></h3><p>In federated learning, participants claim to train on local data. PoAI can verify that gradient updates came from actual training, not fabrication.</p><h2 id=limitations>Limitations<a hidden class=anchor aria-hidden=true href=#limitations>#</a></h2><p>Current limitations we&rsquo;re working to address:</p><ol><li><strong>Proof generation cost</strong>: Large models remain impractical</li><li><strong>Model constraints</strong>: Complex architectures (MoE, very deep) are challenging</li><li><strong>Floating point</strong>: Native FP support would reduce approximation errors</li><li><strong>Recursion</strong>: Autoregressive generation requires sequential proofs</li></ol><h2 id=roadmap>Roadmap<a hidden class=anchor aria-hidden=true href=#roadmap>#</a></h2><p><strong>Q3 2023</strong>: Release PoAI SDK for small models
<strong>Q4 2023</strong>: Folding scheme improvements for 10x speedup
<strong>Q1 2024</strong>: Support for models up to 1B parameters
<strong>Q2 2024</strong>: Production deployment on Lux Network</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>Verifiable AI is essential for decentralized systems. PoAI makes cryptographic verification practical for real models. The overhead is significant but decreasing.</p><p>Trust, but verify. Now you can.</p><hr><p><em>Zach Kelling is a co-founder of Zoo Labs Foundation.</em></p></div></article></main><footer class=footer><span>&copy; 2026 <a href=https://zenlm.org/>Zen LM</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>