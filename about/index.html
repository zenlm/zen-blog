<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>About Us | Zen LM</title><meta name=keywords content><meta name=description content="Zen LM Team Zen LM is a joint initiative of Hanzo AI (Techstars &lsquo;17) and the Zoo Labs Foundation (501c3). We build and release open frontier models under the Zen model family — co-developed using the Zen MoDE (Mixture of Distilled Experts) architecture. Our goal is frontier capability with open weights, so any developer or researcher can run, fine-tune, and extend our models.
The Zen model catalog spans 600M to 480B parameters across text, vision, audio, and code modalities."><meta name=author content="Zen LM Team"><link rel=canonical href=https://zenlm.org/about/><link crossorigin=anonymous href=/assets/css/stylesheet.6c0865a4bc8dbcbd27d78777eb33b404568f7fbf3185cca7b978e5275a4dd049.css integrity="sha256-bAhlpLyNvL0n14d36zO0BFaPf78xhcynuXjlJ1pN0Ek=" rel="preload stylesheet" as=style><link rel=icon href=https://zenlm.org/favicon.png><link rel=apple-touch-icon href=https://zenlm.org/favicon.png><link rel=manifest href=https://zenlm.org/site.webmanifest><meta name=theme-color content="#615CED"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script><meta property="og:title" content="About Us"><meta property="og:description" content="Zen LM Team Zen LM is a joint initiative of Hanzo AI (Techstars &lsquo;17) and the Zoo Labs Foundation (501c3). We build and release open frontier models under the Zen model family — co-developed using the Zen MoDE (Mixture of Distilled Experts) architecture. Our goal is frontier capability with open weights, so any developer or researcher can run, fine-tune, and extend our models.
The Zen model catalog spans 600M to 480B parameters across text, vision, audio, and code modalities."><meta property="og:type" content="article"><meta property="og:url" content="https://zenlm.org/about/"><meta property="og:image" content="https://zenlm.org/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content><meta property="og:site_name" content="Zen LM"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://zenlm.org/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="About Us"><meta name=twitter:description content="Zen LM Team Zen LM is a joint initiative of Hanzo AI (Techstars &lsquo;17) and the Zoo Labs Foundation (501c3). We build and release open frontier models under the Zen model family — co-developed using the Zen MoDE (Mixture of Distilled Experts) architecture. Our goal is frontier capability with open weights, so any developer or researcher can run, fine-tune, and extend our models.
The Zen model catalog spans 600M to 480B parameters across text, vision, audio, and code modalities."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"About Us","item":"https://zenlm.org/about/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"About Us","name":"About Us","description":"Zen LM Team Zen LM is a joint initiative of Hanzo AI (Techstars \u0026lsquo;17) and the Zoo Labs Foundation (501c3). We build and release open frontier models under the Zen model family — co-developed using the Zen MoDE (Mixture of Distilled Experts) architecture. Our goal is frontier capability with open weights, so any developer or researcher can run, fine-tune, and extend our models.\nThe Zen model catalog spans 600M to 480B parameters across text, vision, audio, and code modalities.","keywords":[],"articleBody":"Zen LM Team Zen LM is a joint initiative of Hanzo AI (Techstars ‘17) and the Zoo Labs Foundation (501c3). We build and release open frontier models under the Zen model family — co-developed using the Zen MoDE (Mixture of Distilled Experts) architecture. Our goal is frontier capability with open weights, so any developer or researcher can run, fine-tune, and extend our models.\nThe Zen model catalog spans 600M to 480B parameters across text, vision, audio, and code modalities. All general-purpose Zen models are released under Apache-2.0.\nLinks Models GITHUB HUGGING FACE\nCommunity X DISCORD\nAPI HANZO AI ","wordCount":"98","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"Zen LM Team"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://zenlm.org/about/"},"publisher":{"@type":"Organization","name":"Zen LM","logo":{"@type":"ImageObject","url":"https://zenlm.org/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!0</script><header class=header><div class="nav-container nav-background"><nav class=nav><div class=logo><a href=/ accesskey=h title="Zen LM (Alt + H)"><img src=https://zenlm.org/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span class=active>About</span></a></li><li><a href=https://zeekay.blog title=zeekay><span>zeekay</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://hanzo.blog title=hanzo.blog><span>hanzo.blog</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://hanzo.ai/chat title="Try Zen Chat"><span>Try Zen Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://blog.zoo.ngo title="zoo blog"><span>zoo blog</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero-background style="background:linear-gradient(to top,#30cfd0 0%,#330867 100%)"></div><div class="hero text-light"><h1 class=post-title>About Us</h1></div></div><main class=main><article class=post-single><div class=post-content><h1 id=zen-lm-team>Zen LM Team<a hidden class=anchor aria-hidden=true href=#zen-lm-team>#</a></h1><p>Zen LM is a joint initiative of <strong>Hanzo AI</strong> (Techstars &lsquo;17) and the <strong>Zoo Labs Foundation</strong> (501c3). We build and release open frontier models under the Zen model family — co-developed using the Zen MoDE (Mixture of Distilled Experts) architecture. Our goal is frontier capability with open weights, so any developer or researcher can run, fine-tune, and extend our models.</p><p>The Zen model catalog spans 600M to 480B parameters across text, vision, audio, and code modalities. All general-purpose Zen models are released under Apache-2.0.</p><h2 id=links>Links<a hidden class=anchor aria-hidden=true href=#links>#</a></h2><h3 id=models>Models<a hidden class=anchor aria-hidden=true href=#models>#</a></h3><p><a href=https://github.com/hanzoai class="btn external" target=_blank>GITHUB</a>
<a href=https://huggingface.co/hanzoai class="btn external" target=_blank>HUGGING FACE</a></p><h3 id=community>Community<a hidden class=anchor aria-hidden=true href=#community>#</a></h3><p><a href=https://x.com/hanzoai class="btn external" target=_blank>X</a>
<a href=https://discord.gg/hanzoai class="btn external" target=_blank>DISCORD</a></p><h3 id=api>API<a hidden class=anchor aria-hidden=true href=#api>#</a></h3><a href=https://hanzo.ai class="btn external" target=_blank>HANZO AI</a></div></article></main><footer class=footer><span>&copy; 2026 <a href=https://zenlm.org/>Zen LM</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>