<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.106.0"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Zen LM</title><meta name=keywords content="Zen LM,Zen MoDE,open weights,large language models,machine learning,AI"><meta name=description content="Open frontier models from Hanzo AI and Zoo Labs Foundation."><meta name=author content="Zen LM Team"><link rel=canonical href=https://zenlm.org/><link crossorigin=anonymous href=/assets/css/stylesheet.6c0865a4bc8dbcbd27d78777eb33b404568f7fbf3185cca7b978e5275a4dd049.css integrity="sha256-bAhlpLyNvL0n14d36zO0BFaPf78xhcynuXjlJ1pN0Ek=" rel="preload stylesheet" as=style><link rel=icon href=https://zenlm.org/favicon.png><link rel=apple-touch-icon href=https://zenlm.org/favicon.png><link rel=manifest href=https://zenlm.org/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate type=application/json href=https://zenlm.org/index.json><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script><meta property="og:title" content="Zen LM"><meta property="og:description" content="Open frontier models from Hanzo AI and Zoo Labs Foundation."><meta property="og:type" content="website"><meta property="og:url" content="https://zenlm.org/"><meta property="og:image" content="https://zenlm.org/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Zen LM"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://zenlm.org/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Zen LM"><meta name=twitter:description content="Open frontier models from Hanzo AI and Zoo Labs Foundation."><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Zen LM","url":"https://zenlm.org/","description":"Zen LM — Frontier open models from Hanzo AI and Zoo Labs Foundation","thumbnailUrl":"https://zenlm.org/favicon.png","sameAs":[]}</script></head><body class=list id=top><script>const hasHeaderBg=!0</script><header class=header><div class="nav-container nav-background"><nav class=nav><div class=logo><a href=/ accesskey=h title="Zen LM (Alt + H)"><img src=https://zenlm.org/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://zeekay.blog title=zeekay><span>zeekay</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://hanzo.blog title=hanzo.blog><span>hanzo.blog</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://hanzo.ai/chat title="Try Zen Chat"><span>Try Zen Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://blog.zoo.ngo title="zoo blog"><span>zoo blog</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container style=min-height:100vh;display:flex;justify-content:center;background-color:#000><img class=hero-background style=opacity:0 onload="this.style.opacity=1" src=https://cdn.jsdelivr.net/gh/hanzoai/zen-blog@main/static/img/background.webp width=100%><div class=hero-gradient></div><div class=hero-blur></div><div class=mouse-hint><div class=mouse-point></div></div><style>body{-ms-overflow-style:none;scrollbar-width:none}body::-webkit-scrollbar{display:none}.mouse-hint{position:absolute;height:36px;width:24px;border:1px solid #fff;border-radius:12px;bottom:20%;left:50% - calc(12px);opacity:1;transition:opacity .3s;animation:1s ease-out 0s 1 slideBelow}.mouse-hint .mouse-point{height:4px;width:4px;background-color:#fff;position:absolute;left:50%;bottom:40%;border-radius:4px;transform-origin:50% 100%;transform:translate(-50%);animation:2.2s ease-in-out infinite jump;will-change:transform}@keyframes slideBelow{0%{transform:translateY(50px);opacity:0}100%{transform:translateX(0);opacity:1}}@keyframes jump{0%,20%,60%,to{transform:translate(-50%)translateY(0);height:4px;animation-timing-function:ease-in}40%,80%{transform:translate(-50%)translateY(8px);height:8px;animation-timing-function:ease-out}}</style><div class="hero text-light text-fade-in"><div class=hero-header><h1>Zen LM</h1></div><div class=hero-content>Open frontier models from Hanzo AI and Zoo Labs Foundation.</div><div class=hero-footer><div class=social-icons></div></div></div></div><main class="main home"><article class=post-entry><header class=entry-header><h2>GT-QLoRA: Uncensoring Trillion-Parameter MoE Models</h2></header><div class=entry-content><p>ZEN4-ULTRA TRAINER ZEN4-ULTRA WEIGHTS ZEN4-ULTRA GGUF
Standard abliteration works on dense models. It fails on Mixture-of-Experts. This post explains why, and how Gate-Targeted QLoRA (GT-QLoRA) — the technique we developed for zen4-ultra — addresses the fundamental architectural mismatch.
This is a technical post about a hard problem. We are not publishing this because we have solved it cleanly. We are publishing it because the failure mode of naive approaches is subtle and poorly documented, and other researchers building on MoE architectures need to understand it....</p></div><footer class=entry-footer><span title='2026-02-28 13:00:00 -0800 -0800'>February 28, 2026</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;1599 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to GT-QLoRA: Uncensoring Trillion-Parameter MoE Models" href=https://zenlm.org/blog/gt-qlora-moe-abliteration/></a></article><article class=post-entry><header class=entry-header><h2>Drop-Upcycling and the Birth of Zen MoDE Architecture</h2></header><div class=entry-content><p>DROP-UPCYCLING PAPER ZEN MODELS ZEN CODE
Mixture of Experts (MoE) is the architecture that makes trillion-parameter models economically viable. By routing each token through a small subset of expert networks rather than the full parameter set, MoE achieves large-model quality at dense-model inference cost. The problem: training an MoE from scratch is expensive. You are paying for both the scale and the specialization overhead.
Drop-Upcycling is a technique that converts a trained dense checkpoint into an MoE at roughly 1/4 the training cost of building the MoE from scratch....</p></div><footer class=entry-footer><span title='2026-02-28 12:00:00 -0800 -0800'>February 28, 2026</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1443 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to Drop-Upcycling and the Birth of Zen MoDE Architecture" href=https://zenlm.org/blog/drop-upcycling-zen-mode/></a></article><article class=post-entry><header class=entry-header><h2>BitDelta: 1-Bit Behavioral Compression Across the Zen Model Family</h2></header><div class=entry-content><p>BITDELTA PAPER MONOSOUP PAPER K-MERGE PAPER ZEN MODELS
The Zen model family has a deployment problem that is not immediately obvious from the outside. We publish 14+ distinct model variants — from zen-nano at 0.6B parameters to zen4-ultra at 1.04T. Each variant carries fine-tuned behavioral characteristics: different personas, different task specializations, different safety postures. In a naive serving architecture, each variant is a separate set of weights. Loading all of them onto a GPU cluster is economically impossible....</p></div><footer class=entry-footer><span title='2026-02-28 11:00:00 -0800 -0800'>February 28, 2026</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1345 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to BitDelta: 1-Bit Behavioral Compression Across the Zen Model Family" href=https://zenlm.org/blog/bitdelta-behavioral-compression/></a></article><article class=post-entry><header class=entry-header><h2>SuRe + OPCM: Production-Grade Continual Learning for Open Models</h2></header><div class=entry-content><p>OPLoRA PAPER SuRe PAPER OPCM PAPER YOUTU-AGENT PAPER
Every production LLM faces the same brutal constraint: the moment you start adapting a model on new data, it begins forgetting what it already knew. This is catastrophic forgetting — and it is not a theoretical concern. It is the reason most “continually updated” models in production are quietly replaced wholesale every few months rather than genuinely updated in place.
For the Zen model family, wholesale replacement is not acceptable....</p></div><footer class=entry-footer><span title='2026-02-28 10:00:00 -0800 -0800'>February 28, 2026</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;1602 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to SuRe + OPCM: Production-Grade Continual Learning for Open Models" href=https://zenlm.org/blog/continual-learning-sure-opcm/></a></article><article class=post-entry><header class=entry-header><h2>Zen4 Ultra: 480B Parameters, 1M Token Context</h2></header><div class=entry-content><p>GITHUB HUGGING FACE TRY ZEN CHAT
Zen4 Ultra is the most capable model in the Zen4 family. It is a Mixture of Distilled Experts model with 480B total parameters and 35B active parameters per forward pass. The native context window is 256K tokens, extending to 1M tokens with YaRN extrapolation.
Architecture Property Value Total parameters 480B Active parameters per token 35B Experts per layer 128 Top-k routing 8 Context window (native) 256K Context window (YaRN) 1M Vocabulary size 151,936 Attention heads 64 KV heads (GQA) 8 Layers 94 Benchmark Results General Reasoning Benchmark Zen4 Ultra Zen Max 72B MMLU 89....</p></div><footer class=entry-footer><span title='2026-01-20 09:00:00 -0800 -0800'>January 20, 2026</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;506 words&nbsp;·&nbsp;Zen LM Team</footer><a class=entry-link aria-label="post link to Zen4 Ultra: 480B Parameters, 1M Token Context" href=https://zenlm.org/blog/zen4-ultra/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://zenlm.org/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2026 <a href=https://zenlm.org/>Zen LM</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script></body></html>